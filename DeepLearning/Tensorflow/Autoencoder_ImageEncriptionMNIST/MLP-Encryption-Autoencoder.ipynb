{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.examples.tutorials.mnist as mnist\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source: http://yann.lecun.com/exdb/mnist/\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading files\n",
    "Data is already preprocessed, shuffled and normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting tensorflow/examples/tutorials/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting tensorflow/examples/tutorials/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting tensorflow/examples/tutorials/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting tensorflow/examples/tutorials/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset = mnist.input_data.read_data_sets('tensorflow/examples/tutorials/mnist', \n",
    "                                                one_hot=True, validation_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_for_autoencoder = mnist_dataset.train.images\n",
    "images_for_autoencoder_labels = mnist_dataset.train.labels.astype(np.float32)\n",
    "\n",
    "test_images = mnist_dataset.test.images\n",
    "test_images_labels = mnist_dataset.test.labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGES_NUM = images_for_autoencoder.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_digit(trainX, trainY, index):\n",
    "    image = trainX[index].reshape([IMAGE_WIDTH, IMAGE_HEIGHT])\n",
    "    label = trainY[index]\n",
    "    plt.title(\"Training data, index: {},  Label: {}\".format(index, label))\n",
    "    plt.imshow(image, cmap=\"gray_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: (60000, 784)\n",
      "Labels: (60000, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEICAYAAADsh6tqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ0uSVAxDS5JUjP8PbyzCVIDjO2YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113d7f9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Images: \" + str(images_for_autoencoder.shape))\n",
    "print(\"Labels: \" + str(images_for_autoencoder_labels.shape))\n",
    "show_digit(images_for_autoencoder, images_for_autoencoder_labels, np.random.randint(1, IMAGES_NUM + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset tensorflow graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, [None, IMAGE_WIDTH * IMAGE_HEIGHT], \"inputs\")\n",
    "targets_ = tf.placeholder(tf.float32, [None, IMAGE_WIDTH * IMAGE_HEIGHT], \"targets\")\n",
    "learning_rate_ = tf.placeholder(tf.float32, None, name=\"learning_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 28 * 28 MNIST image will be encoded into 'encoding_size' numbers\n",
    "encoder_logits = tf.layers.dense(inputs_, encoding_size, activation=None)\n",
    "encoded = tf.nn.relu(encoder_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'encoding_size' numbers will be decoded into normalized image\n",
    "decoder_logits = tf.layers.dense(encoded, IMAGE_WIDTH * IMAGE_HEIGHT, activation=None)\n",
    "decoded = activation=tf.nn.sigmoid(decoder_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_value = tf.nn.sigmoid_cross_entropy_with_logits(logits=decoder_logits, labels=targets_)\n",
    "cost_value = tf.reduce_mean(loss_value)\n",
    "\n",
    "# gradient descent optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 48\n",
    "num_batches = IMAGES_NUM // batch_size\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_mini_batches(data, labels, batch_size):\n",
    "    assert len(data) == len(labels)\n",
    "    \n",
    "    all_batches = list()\n",
    "    for i in range(0, len(data)):\n",
    "        all_batches.append((data[i], labels[i]))\n",
    "    random.shuffle(all_batches)\n",
    "        \n",
    "    mini_batches = list()\n",
    "    while len(all_batches) >= batch_size:\n",
    "        \n",
    "        data_batch = list()\n",
    "        labels_batch = list()\n",
    "        for j in range(0, batch_size):\n",
    "            data, labels = all_batches.pop()\n",
    "            data_batch.append(data)\n",
    "            labels_batch.append(labels)\n",
    "            \n",
    "        mini_batches.append((np.array(data_batch), np.array(labels_batch)))\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30... Training loss: 0.6928\n",
      "Epoch: 1/30... Training loss: 0.6899\n",
      "Epoch: 1/30... Training loss: 0.6865\n",
      "Epoch: 1/30... Training loss: 0.6831\n",
      "Epoch: 1/30... Training loss: 0.6796\n",
      "Epoch: 1/30... Training loss: 0.6754\n",
      "Epoch: 1/30... Training loss: 0.6722\n",
      "Epoch: 1/30... Training loss: 0.6663\n",
      "Epoch: 1/30... Training loss: 0.6622\n",
      "Epoch: 1/30... Training loss: 0.6550\n",
      "Epoch: 1/30... Training loss: 0.6501\n",
      "Epoch: 1/30... Training loss: 0.6420\n",
      "Epoch: 1/30... Training loss: 0.6342\n",
      "Epoch: 1/30... Training loss: 0.6262\n",
      "Epoch: 1/30... Training loss: 0.6155\n",
      "Epoch: 1/30... Training loss: 0.6067\n",
      "Epoch: 1/30... Training loss: 0.5989\n",
      "Epoch: 1/30... Training loss: 0.5896\n",
      "Epoch: 1/30... Training loss: 0.5774\n",
      "Epoch: 1/30... Training loss: 0.5604\n",
      "Epoch: 1/30... Training loss: 0.5520\n",
      "Epoch: 1/30... Training loss: 0.5470\n",
      "Epoch: 1/30... Training loss: 0.5262\n",
      "Epoch: 1/30... Training loss: 0.5159\n",
      "Epoch: 1/30... Training loss: 0.4928\n",
      "Epoch: 1/30... Training loss: 0.4852\n",
      "Epoch: 1/30... Training loss: 0.4800\n",
      "Epoch: 1/30... Training loss: 0.4595\n",
      "Epoch: 1/30... Training loss: 0.4489\n",
      "Epoch: 1/30... Training loss: 0.4462\n",
      "Epoch: 1/30... Training loss: 0.4231\n",
      "Epoch: 1/30... Training loss: 0.4100\n",
      "Epoch: 1/30... Training loss: 0.4038\n",
      "Epoch: 1/30... Training loss: 0.4053\n",
      "Epoch: 1/30... Training loss: 0.3851\n",
      "Epoch: 1/30... Training loss: 0.3758\n",
      "Epoch: 1/30... Training loss: 0.3661\n",
      "Epoch: 1/30... Training loss: 0.3608\n",
      "Epoch: 1/30... Training loss: 0.3569\n",
      "Epoch: 1/30... Training loss: 0.3581\n",
      "Epoch: 1/30... Training loss: 0.3407\n",
      "Epoch: 1/30... Training loss: 0.3298\n",
      "Epoch: 1/30... Training loss: 0.3373\n",
      "Epoch: 1/30... Training loss: 0.3093\n",
      "Epoch: 1/30... Training loss: 0.3276\n",
      "Epoch: 1/30... Training loss: 0.3222\n",
      "Epoch: 1/30... Training loss: 0.3166\n",
      "Epoch: 1/30... Training loss: 0.3154\n",
      "Epoch: 1/30... Training loss: 0.3065\n",
      "Epoch: 1/30... Training loss: 0.2965\n",
      "Epoch: 1/30... Training loss: 0.3037\n",
      "Epoch: 1/30... Training loss: 0.3049\n",
      "Epoch: 1/30... Training loss: 0.2946\n",
      "Epoch: 1/30... Training loss: 0.2951\n",
      "Epoch: 1/30... Training loss: 0.2929\n",
      "Epoch: 1/30... Training loss: 0.2867\n",
      "Epoch: 1/30... Training loss: 0.2946\n",
      "Epoch: 1/30... Training loss: 0.2964\n",
      "Epoch: 1/30... Training loss: 0.2942\n",
      "Epoch: 1/30... Training loss: 0.2894\n",
      "Epoch: 1/30... Training loss: 0.2776\n",
      "Epoch: 1/30... Training loss: 0.2847\n",
      "Epoch: 1/30... Training loss: 0.2876\n",
      "Epoch: 1/30... Training loss: 0.3011\n",
      "Epoch: 1/30... Training loss: 0.2713\n",
      "Epoch: 1/30... Training loss: 0.2855\n",
      "Epoch: 1/30... Training loss: 0.2751\n",
      "Epoch: 1/30... Training loss: 0.2745\n",
      "Epoch: 1/30... Training loss: 0.2807\n",
      "Epoch: 1/30... Training loss: 0.3066\n",
      "Epoch: 1/30... Training loss: 0.2819\n",
      "Epoch: 1/30... Training loss: 0.3028\n",
      "Epoch: 1/30... Training loss: 0.2702\n",
      "Epoch: 1/30... Training loss: 0.2740\n",
      "Epoch: 1/30... Training loss: 0.2746\n",
      "Epoch: 1/30... Training loss: 0.2769\n",
      "Epoch: 1/30... Training loss: 0.2729\n",
      "Epoch: 1/30... Training loss: 0.2893\n",
      "Epoch: 1/30... Training loss: 0.2751\n",
      "Epoch: 1/30... Training loss: 0.2727\n",
      "Epoch: 1/30... Training loss: 0.2808\n",
      "Epoch: 1/30... Training loss: 0.2832\n",
      "Epoch: 1/30... Training loss: 0.2773\n",
      "Epoch: 1/30... Training loss: 0.2713\n",
      "Epoch: 1/30... Training loss: 0.2682\n",
      "Epoch: 1/30... Training loss: 0.2678\n",
      "Epoch: 1/30... Training loss: 0.2757\n",
      "Epoch: 1/30... Training loss: 0.2843\n",
      "Epoch: 1/30... Training loss: 0.2604\n",
      "Epoch: 1/30... Training loss: 0.2632\n",
      "Epoch: 1/30... Training loss: 0.2703\n",
      "Epoch: 1/30... Training loss: 0.2643\n",
      "Epoch: 1/30... Training loss: 0.2717\n",
      "Epoch: 1/30... Training loss: 0.2796\n",
      "Epoch: 1/30... Training loss: 0.2739\n",
      "Epoch: 1/30... Training loss: 0.2690\n",
      "Epoch: 1/30... Training loss: 0.2554\n",
      "Epoch: 1/30... Training loss: 0.2702\n",
      "Epoch: 1/30... Training loss: 0.2706\n",
      "Epoch: 1/30... Training loss: 0.2762\n",
      "Epoch: 1/30... Training loss: 0.2718\n",
      "Epoch: 1/30... Training loss: 0.2645\n",
      "Epoch: 1/30... Training loss: 0.2640\n",
      "Epoch: 1/30... Training loss: 0.2675\n",
      "Epoch: 1/30... Training loss: 0.2631\n",
      "Epoch: 1/30... Training loss: 0.2601\n",
      "Epoch: 1/30... Training loss: 0.2642\n",
      "Epoch: 1/30... Training loss: 0.2534\n",
      "Epoch: 1/30... Training loss: 0.2556\n",
      "Epoch: 1/30... Training loss: 0.2630\n",
      "Epoch: 1/30... Training loss: 0.2626\n",
      "Epoch: 1/30... Training loss: 0.2596\n",
      "Epoch: 1/30... Training loss: 0.2607\n",
      "Epoch: 1/30... Training loss: 0.2588\n",
      "Epoch: 1/30... Training loss: 0.2545\n",
      "Epoch: 1/30... Training loss: 0.2502\n",
      "Epoch: 1/30... Training loss: 0.2575\n",
      "Epoch: 1/30... Training loss: 0.2469\n",
      "Epoch: 1/30... Training loss: 0.2613\n",
      "Epoch: 1/30... Training loss: 0.2543\n",
      "Epoch: 1/30... Training loss: 0.2480\n",
      "Epoch: 1/30... Training loss: 0.2575\n",
      "Epoch: 1/30... Training loss: 0.2475\n",
      "Epoch: 1/30... Training loss: 0.2569\n",
      "Epoch: 1/30... Training loss: 0.2553\n",
      "Epoch: 1/30... Training loss: 0.2499\n",
      "Epoch: 1/30... Training loss: 0.2427\n",
      "Epoch: 1/30... Training loss: 0.2430\n",
      "Epoch: 1/30... Training loss: 0.2561\n",
      "Epoch: 1/30... Training loss: 0.2535\n",
      "Epoch: 1/30... Training loss: 0.2480\n",
      "Epoch: 1/30... Training loss: 0.2508\n",
      "Epoch: 1/30... Training loss: 0.2586\n",
      "Epoch: 1/30... Training loss: 0.2560\n",
      "Epoch: 1/30... Training loss: 0.2402\n",
      "Epoch: 1/30... Training loss: 0.2368\n",
      "Epoch: 1/30... Training loss: 0.2511\n",
      "Epoch: 1/30... Training loss: 0.2453\n",
      "Epoch: 1/30... Training loss: 0.2427\n",
      "Epoch: 1/30... Training loss: 0.2664\n",
      "Epoch: 1/30... Training loss: 0.2441\n",
      "Epoch: 1/30... Training loss: 0.2655\n",
      "Epoch: 1/30... Training loss: 0.2409\n",
      "Epoch: 1/30... Training loss: 0.2395\n",
      "Epoch: 1/30... Training loss: 0.2313\n",
      "Epoch: 1/30... Training loss: 0.2397\n",
      "Epoch: 1/30... Training loss: 0.2526\n",
      "Epoch: 1/30... Training loss: 0.2497\n",
      "Epoch: 1/30... Training loss: 0.2472\n",
      "Epoch: 1/30... Training loss: 0.2472\n",
      "Epoch: 1/30... Training loss: 0.2635\n",
      "Epoch: 1/30... Training loss: 0.2456\n",
      "Epoch: 1/30... Training loss: 0.2361\n",
      "Epoch: 1/30... Training loss: 0.2356\n",
      "Epoch: 1/30... Training loss: 0.2380\n",
      "Epoch: 1/30... Training loss: 0.2336\n",
      "Epoch: 1/30... Training loss: 0.2453\n",
      "Epoch: 1/30... Training loss: 0.2364\n",
      "Epoch: 1/30... Training loss: 0.2377\n",
      "Epoch: 1/30... Training loss: 0.2359\n",
      "Epoch: 1/30... Training loss: 0.2348\n",
      "Epoch: 1/30... Training loss: 0.2370\n",
      "Epoch: 1/30... Training loss: 0.2244\n",
      "Epoch: 1/30... Training loss: 0.2399\n",
      "Epoch: 1/30... Training loss: 0.2202\n",
      "Epoch: 1/30... Training loss: 0.2270\n",
      "Epoch: 1/30... Training loss: 0.2305\n",
      "Epoch: 1/30... Training loss: 0.2364\n",
      "Epoch: 1/30... Training loss: 0.2425\n",
      "Epoch: 1/30... Training loss: 0.2344\n",
      "Epoch: 1/30... Training loss: 0.2200\n",
      "Epoch: 1/30... Training loss: 0.2270\n",
      "Epoch: 1/30... Training loss: 0.2318\n",
      "Epoch: 1/30... Training loss: 0.2231\n",
      "Epoch: 1/30... Training loss: 0.2310\n",
      "Epoch: 1/30... Training loss: 0.2468\n",
      "Epoch: 1/30... Training loss: 0.2112\n",
      "Epoch: 1/30... Training loss: 0.2264\n",
      "Epoch: 1/30... Training loss: 0.2230\n",
      "Epoch: 1/30... Training loss: 0.2335\n",
      "Epoch: 1/30... Training loss: 0.2190\n",
      "Epoch: 1/30... Training loss: 0.2283\n",
      "Epoch: 1/30... Training loss: 0.2301\n",
      "Epoch: 1/30... Training loss: 0.2222\n",
      "Epoch: 1/30... Training loss: 0.2434\n",
      "Epoch: 1/30... Training loss: 0.2199\n",
      "Epoch: 1/30... Training loss: 0.2501\n",
      "Epoch: 1/30... Training loss: 0.2299\n",
      "Epoch: 1/30... Training loss: 0.2254\n",
      "Epoch: 1/30... Training loss: 0.2253\n",
      "Epoch: 1/30... Training loss: 0.2293\n",
      "Epoch: 1/30... Training loss: 0.2350\n",
      "Epoch: 1/30... Training loss: 0.2259\n",
      "Epoch: 1/30... Training loss: 0.2239\n",
      "Epoch: 1/30... Training loss: 0.2277\n",
      "Epoch: 1/30... Training loss: 0.2165\n",
      "Epoch: 1/30... Training loss: 0.2183\n",
      "Epoch: 1/30... Training loss: 0.2212\n",
      "Epoch: 1/30... Training loss: 0.2178\n",
      "Epoch: 1/30... Training loss: 0.2204\n",
      "Epoch: 1/30... Training loss: 0.2171\n",
      "Epoch: 1/30... Training loss: 0.2186\n",
      "Epoch: 1/30... Training loss: 0.2228\n",
      "Epoch: 1/30... Training loss: 0.2251\n",
      "Epoch: 1/30... Training loss: 0.2192\n",
      "Epoch: 1/30... Training loss: 0.2226\n",
      "Epoch: 1/30... Training loss: 0.2249\n",
      "Epoch: 1/30... Training loss: 0.2178\n",
      "Epoch: 1/30... Training loss: 0.2212\n",
      "Epoch: 1/30... Training loss: 0.2190\n",
      "Epoch: 1/30... Training loss: 0.2227\n",
      "Epoch: 1/30... Training loss: 0.2235\n",
      "Epoch: 1/30... Training loss: 0.2174\n",
      "Epoch: 1/30... Training loss: 0.2107\n",
      "Epoch: 1/30... Training loss: 0.2232\n",
      "Epoch: 1/30... Training loss: 0.2138\n",
      "Epoch: 1/30... Training loss: 0.2175\n",
      "Epoch: 1/30... Training loss: 0.2181\n",
      "Epoch: 1/30... Training loss: 0.2218\n",
      "Epoch: 1/30... Training loss: 0.2194\n",
      "Epoch: 1/30... Training loss: 0.2133\n",
      "Epoch: 1/30... Training loss: 0.2184\n",
      "Epoch: 1/30... Training loss: 0.2117\n",
      "Epoch: 1/30... Training loss: 0.2190\n",
      "Epoch: 1/30... Training loss: 0.2111\n",
      "Epoch: 1/30... Training loss: 0.2155\n",
      "Epoch: 1/30... Training loss: 0.2259\n",
      "Epoch: 1/30... Training loss: 0.2091\n",
      "Epoch: 1/30... Training loss: 0.2097\n",
      "Epoch: 1/30... Training loss: 0.2193\n",
      "Epoch: 1/30... Training loss: 0.2089\n",
      "Epoch: 1/30... Training loss: 0.2071\n",
      "Epoch: 1/30... Training loss: 0.2075\n",
      "Epoch: 1/30... Training loss: 0.2133\n",
      "Epoch: 1/30... Training loss: 0.2180\n",
      "Epoch: 1/30... Training loss: 0.2186\n",
      "Epoch: 1/30... Training loss: 0.2081\n",
      "Epoch: 1/30... Training loss: 0.2135\n",
      "Epoch: 1/30... Training loss: 0.2238\n",
      "Epoch: 1/30... Training loss: 0.2108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30... Training loss: 0.1989\n",
      "Epoch: 1/30... Training loss: 0.2224\n",
      "Epoch: 1/30... Training loss: 0.2072\n",
      "Epoch: 1/30... Training loss: 0.2011\n",
      "Epoch: 1/30... Training loss: 0.2091\n",
      "Epoch: 1/30... Training loss: 0.2076\n",
      "Epoch: 1/30... Training loss: 0.2054\n",
      "Epoch: 1/30... Training loss: 0.2094\n",
      "Epoch: 1/30... Training loss: 0.2144\n",
      "Epoch: 1/30... Training loss: 0.2031\n",
      "Epoch: 1/30... Training loss: 0.2131\n",
      "Epoch: 1/30... Training loss: 0.2110\n",
      "Epoch: 1/30... Training loss: 0.1951\n",
      "Epoch: 1/30... Training loss: 0.2078\n",
      "Epoch: 1/30... Training loss: 0.1962\n",
      "Epoch: 1/30... Training loss: 0.2119\n",
      "Epoch: 1/30... Training loss: 0.2099\n",
      "Epoch: 1/30... Training loss: 0.2050\n",
      "Epoch: 1/30... Training loss: 0.2090\n",
      "Epoch: 1/30... Training loss: 0.2088\n",
      "Epoch: 1/30... Training loss: 0.2137\n",
      "Epoch: 1/30... Training loss: 0.2109\n",
      "Epoch: 1/30... Training loss: 0.2047\n",
      "Epoch: 1/30... Training loss: 0.2126\n",
      "Epoch: 1/30... Training loss: 0.2176\n",
      "Epoch: 1/30... Training loss: 0.2010\n",
      "Epoch: 1/30... Training loss: 0.2080\n",
      "Epoch: 1/30... Training loss: 0.2051\n",
      "Epoch: 1/30... Training loss: 0.1908\n",
      "Epoch: 1/30... Training loss: 0.2072\n",
      "Epoch: 1/30... Training loss: 0.2074\n",
      "Epoch: 1/30... Training loss: 0.1907\n",
      "Epoch: 1/30... Training loss: 0.2057\n",
      "Epoch: 1/30... Training loss: 0.1974\n",
      "Epoch: 1/30... Training loss: 0.1947\n",
      "Epoch: 1/30... Training loss: 0.2074\n",
      "Epoch: 1/30... Training loss: 0.2011\n",
      "Epoch: 1/30... Training loss: 0.2042\n",
      "Epoch: 1/30... Training loss: 0.1854\n",
      "Epoch: 1/30... Training loss: 0.2059\n",
      "Epoch: 1/30... Training loss: 0.1855\n",
      "Epoch: 1/30... Training loss: 0.2012\n",
      "Epoch: 1/30... Training loss: 0.2096\n",
      "Epoch: 1/30... Training loss: 0.2021\n",
      "Epoch: 1/30... Training loss: 0.2049\n",
      "Epoch: 1/30... Training loss: 0.2034\n",
      "Epoch: 1/30... Training loss: 0.2071\n",
      "Epoch: 1/30... Training loss: 0.1919\n",
      "Epoch: 1/30... Training loss: 0.1894\n",
      "Epoch: 1/30... Training loss: 0.2028\n",
      "Epoch: 1/30... Training loss: 0.1986\n",
      "Epoch: 1/30... Training loss: 0.1995\n",
      "Epoch: 1/30... Training loss: 0.1954\n",
      "Epoch: 1/30... Training loss: 0.1970\n",
      "Epoch: 1/30... Training loss: 0.1968\n",
      "Epoch: 1/30... Training loss: 0.1925\n",
      "Epoch: 1/30... Training loss: 0.1982\n",
      "Epoch: 1/30... Training loss: 0.1909\n",
      "Epoch: 1/30... Training loss: 0.1970\n",
      "Epoch: 1/30... Training loss: 0.2016\n",
      "Epoch: 1/30... Training loss: 0.1946\n",
      "Epoch: 1/30... Training loss: 0.1944\n",
      "Epoch: 1/30... Training loss: 0.1918\n",
      "Epoch: 1/30... Training loss: 0.1863\n",
      "Epoch: 1/30... Training loss: 0.2049\n",
      "Epoch: 1/30... Training loss: 0.1985\n",
      "Epoch: 1/30... Training loss: 0.1909\n",
      "Epoch: 1/30... Training loss: 0.1795\n",
      "Epoch: 1/30... Training loss: 0.2063\n",
      "Epoch: 1/30... Training loss: 0.1947\n",
      "Epoch: 1/30... Training loss: 0.1854\n",
      "Epoch: 1/30... Training loss: 0.1926\n",
      "Epoch: 1/30... Training loss: 0.2066\n",
      "Epoch: 1/30... Training loss: 0.1848\n",
      "Epoch: 1/30... Training loss: 0.1841\n",
      "Epoch: 1/30... Training loss: 0.2051\n",
      "Epoch: 1/30... Training loss: 0.1942\n",
      "Epoch: 1/30... Training loss: 0.2015\n",
      "Epoch: 1/30... Training loss: 0.1977\n",
      "Epoch: 1/30... Training loss: 0.1899\n",
      "Epoch: 1/30... Training loss: 0.1899\n",
      "Epoch: 1/30... Training loss: 0.1952\n",
      "Epoch: 1/30... Training loss: 0.1958\n",
      "Epoch: 1/30... Training loss: 0.1902\n",
      "Epoch: 1/30... Training loss: 0.2041\n",
      "Epoch: 1/30... Training loss: 0.1918\n",
      "Epoch: 1/30... Training loss: 0.1801\n",
      "Epoch: 1/30... Training loss: 0.1890\n",
      "Epoch: 1/30... Training loss: 0.1928\n",
      "Epoch: 1/30... Training loss: 0.1853\n",
      "Epoch: 1/30... Training loss: 0.1845\n",
      "Epoch: 1/30... Training loss: 0.2002\n",
      "Epoch: 1/30... Training loss: 0.1800\n",
      "Epoch: 1/30... Training loss: 0.1911\n",
      "Epoch: 1/30... Training loss: 0.1932\n",
      "Epoch: 1/30... Training loss: 0.2053\n",
      "Epoch: 1/30... Training loss: 0.1973\n",
      "Epoch: 1/30... Training loss: 0.1924\n",
      "Epoch: 1/30... Training loss: 0.1876\n",
      "Epoch: 1/30... Training loss: 0.2090\n",
      "Epoch: 1/30... Training loss: 0.1945\n",
      "Epoch: 1/30... Training loss: 0.1853\n",
      "Epoch: 1/30... Training loss: 0.1922\n",
      "Epoch: 1/30... Training loss: 0.1903\n",
      "Epoch: 1/30... Training loss: 0.1805\n",
      "Epoch: 1/30... Training loss: 0.1848\n",
      "Epoch: 1/30... Training loss: 0.1949\n",
      "Epoch: 1/30... Training loss: 0.1922\n",
      "Epoch: 1/30... Training loss: 0.1812\n",
      "Epoch: 1/30... Training loss: 0.1968\n",
      "Epoch: 1/30... Training loss: 0.1857\n",
      "Epoch: 1/30... Training loss: 0.1866\n",
      "Epoch: 1/30... Training loss: 0.1896\n",
      "Epoch: 1/30... Training loss: 0.1995\n",
      "Epoch: 1/30... Training loss: 0.1953\n",
      "Epoch: 1/30... Training loss: 0.1777\n",
      "Epoch: 1/30... Training loss: 0.1859\n",
      "Epoch: 1/30... Training loss: 0.1797\n",
      "Epoch: 1/30... Training loss: 0.1817\n",
      "Epoch: 1/30... Training loss: 0.1718\n",
      "Epoch: 1/30... Training loss: 0.1905\n",
      "Epoch: 1/30... Training loss: 0.1909\n",
      "Epoch: 1/30... Training loss: 0.1755\n",
      "Epoch: 1/30... Training loss: 0.1879\n",
      "Epoch: 1/30... Training loss: 0.1958\n",
      "Epoch: 1/30... Training loss: 0.1865\n",
      "Epoch: 1/30... Training loss: 0.1806\n",
      "Epoch: 1/30... Training loss: 0.1696\n",
      "Epoch: 1/30... Training loss: 0.1964\n",
      "Epoch: 1/30... Training loss: 0.1932\n",
      "Epoch: 1/30... Training loss: 0.1784\n",
      "Epoch: 1/30... Training loss: 0.1886\n",
      "Epoch: 1/30... Training loss: 0.1722\n",
      "Epoch: 1/30... Training loss: 0.1786\n",
      "Epoch: 1/30... Training loss: 0.1828\n",
      "Epoch: 1/30... Training loss: 0.1837\n",
      "Epoch: 1/30... Training loss: 0.1842\n",
      "Epoch: 1/30... Training loss: 0.1894\n",
      "Epoch: 1/30... Training loss: 0.1852\n",
      "Epoch: 1/30... Training loss: 0.1833\n",
      "Epoch: 1/30... Training loss: 0.1843\n",
      "Epoch: 1/30... Training loss: 0.1971\n",
      "Epoch: 1/30... Training loss: 0.1943\n",
      "Epoch: 1/30... Training loss: 0.1828\n",
      "Epoch: 1/30... Training loss: 0.1799\n",
      "Epoch: 1/30... Training loss: 0.1820\n",
      "Epoch: 1/30... Training loss: 0.1808\n",
      "Epoch: 1/30... Training loss: 0.1966\n",
      "Epoch: 1/30... Training loss: 0.1953\n",
      "Epoch: 1/30... Training loss: 0.1904\n",
      "Epoch: 1/30... Training loss: 0.1784\n",
      "Epoch: 1/30... Training loss: 0.1781\n",
      "Epoch: 1/30... Training loss: 0.1881\n",
      "Epoch: 1/30... Training loss: 0.1772\n",
      "Epoch: 1/30... Training loss: 0.1848\n",
      "Epoch: 1/30... Training loss: 0.1884\n",
      "Epoch: 1/30... Training loss: 0.1780\n",
      "Epoch: 1/30... Training loss: 0.1840\n",
      "Epoch: 1/30... Training loss: 0.1730\n",
      "Epoch: 1/30... Training loss: 0.1925\n",
      "Epoch: 1/30... Training loss: 0.1764\n",
      "Epoch: 1/30... Training loss: 0.1847\n",
      "Epoch: 1/30... Training loss: 0.1749\n",
      "Epoch: 1/30... Training loss: 0.1879\n",
      "Epoch: 1/30... Training loss: 0.1864\n",
      "Epoch: 1/30... Training loss: 0.1834\n",
      "Epoch: 1/30... Training loss: 0.1834\n",
      "Epoch: 1/30... Training loss: 0.1927\n",
      "Epoch: 1/30... Training loss: 0.1844\n",
      "Epoch: 1/30... Training loss: 0.1788\n",
      "Epoch: 1/30... Training loss: 0.1812\n",
      "Epoch: 1/30... Training loss: 0.1749\n",
      "Epoch: 1/30... Training loss: 0.1818\n",
      "Epoch: 1/30... Training loss: 0.1791\n",
      "Epoch: 1/30... Training loss: 0.1812\n",
      "Epoch: 1/30... Training loss: 0.1786\n",
      "Epoch: 1/30... Training loss: 0.1755\n",
      "Epoch: 1/30... Training loss: 0.1643\n",
      "Epoch: 1/30... Training loss: 0.1781\n",
      "Epoch: 1/30... Training loss: 0.1855\n",
      "Epoch: 1/30... Training loss: 0.1826\n",
      "Epoch: 1/30... Training loss: 0.1763\n",
      "Epoch: 1/30... Training loss: 0.1832\n",
      "Epoch: 1/30... Training loss: 0.1790\n",
      "Epoch: 1/30... Training loss: 0.1698\n",
      "Epoch: 1/30... Training loss: 0.1640\n",
      "Epoch: 1/30... Training loss: 0.1688\n",
      "Epoch: 1/30... Training loss: 0.1619\n",
      "Epoch: 1/30... Training loss: 0.1812\n",
      "Epoch: 1/30... Training loss: 0.1902\n",
      "Epoch: 1/30... Training loss: 0.1823\n",
      "Epoch: 1/30... Training loss: 0.1826\n",
      "Epoch: 1/30... Training loss: 0.1843\n",
      "Epoch: 1/30... Training loss: 0.1762\n",
      "Epoch: 1/30... Training loss: 0.1750\n",
      "Epoch: 1/30... Training loss: 0.1764\n",
      "Epoch: 1/30... Training loss: 0.1902\n",
      "Epoch: 1/30... Training loss: 0.1769\n",
      "Epoch: 1/30... Training loss: 0.1790\n",
      "Epoch: 1/30... Training loss: 0.1695\n",
      "Epoch: 1/30... Training loss: 0.1712\n",
      "Epoch: 1/30... Training loss: 0.1848\n",
      "Epoch: 1/30... Training loss: 0.1788\n",
      "Epoch: 1/30... Training loss: 0.1764\n",
      "Epoch: 1/30... Training loss: 0.1726\n",
      "Epoch: 1/30... Training loss: 0.1571\n",
      "Epoch: 1/30... Training loss: 0.1694\n",
      "Epoch: 1/30... Training loss: 0.1686\n",
      "Epoch: 1/30... Training loss: 0.1899\n",
      "Epoch: 1/30... Training loss: 0.1688\n",
      "Epoch: 1/30... Training loss: 0.1731\n",
      "Epoch: 1/30... Training loss: 0.1701\n",
      "Epoch: 1/30... Training loss: 0.1757\n",
      "Epoch: 1/30... Training loss: 0.1760\n",
      "Epoch: 1/30... Training loss: 0.1733\n",
      "Epoch: 1/30... Training loss: 0.1722\n",
      "Epoch: 1/30... Training loss: 0.1810\n",
      "Epoch: 1/30... Training loss: 0.1748\n",
      "Epoch: 1/30... Training loss: 0.1691\n",
      "Epoch: 1/30... Training loss: 0.1833\n",
      "Epoch: 1/30... Training loss: 0.1716\n",
      "Epoch: 1/30... Training loss: 0.1769\n",
      "Epoch: 1/30... Training loss: 0.1760\n",
      "Epoch: 1/30... Training loss: 0.1884\n",
      "Epoch: 1/30... Training loss: 0.1683\n",
      "Epoch: 1/30... Training loss: 0.1801\n",
      "Epoch: 1/30... Training loss: 0.1717\n",
      "Epoch: 1/30... Training loss: 0.1787\n",
      "Epoch: 1/30... Training loss: 0.1683\n",
      "Epoch: 1/30... Training loss: 0.1743\n",
      "Epoch: 1/30... Training loss: 0.1774\n",
      "Epoch: 1/30... Training loss: 0.1827\n",
      "Epoch: 1/30... Training loss: 0.1706\n",
      "Epoch: 1/30... Training loss: 0.1762\n",
      "Epoch: 1/30... Training loss: 0.1691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30... Training loss: 0.1735\n",
      "Epoch: 1/30... Training loss: 0.1580\n",
      "Epoch: 1/30... Training loss: 0.1937\n",
      "Epoch: 1/30... Training loss: 0.1799\n",
      "Epoch: 1/30... Training loss: 0.1675\n",
      "Epoch: 1/30... Training loss: 0.1610\n",
      "Epoch: 1/30... Training loss: 0.1704\n",
      "Epoch: 1/30... Training loss: 0.1710\n",
      "Epoch: 1/30... Training loss: 0.1776\n",
      "Epoch: 1/30... Training loss: 0.1605\n",
      "Epoch: 1/30... Training loss: 0.1633\n",
      "Epoch: 1/30... Training loss: 0.1751\n",
      "Epoch: 1/30... Training loss: 0.1928\n",
      "Epoch: 1/30... Training loss: 0.1681\n",
      "Epoch: 1/30... Training loss: 0.1734\n",
      "Epoch: 1/30... Training loss: 0.1708\n",
      "Epoch: 1/30... Training loss: 0.1637\n",
      "Epoch: 1/30... Training loss: 0.1691\n",
      "Epoch: 1/30... Training loss: 0.1804\n",
      "Epoch: 1/30... Training loss: 0.1767\n",
      "Epoch: 1/30... Training loss: 0.1943\n",
      "Epoch: 1/30... Training loss: 0.1677\n",
      "Epoch: 1/30... Training loss: 0.1676\n",
      "Epoch: 1/30... Training loss: 0.1694\n",
      "Epoch: 1/30... Training loss: 0.1679\n",
      "Epoch: 1/30... Training loss: 0.1648\n",
      "Epoch: 1/30... Training loss: 0.1676\n",
      "Epoch: 1/30... Training loss: 0.1632\n",
      "Epoch: 1/30... Training loss: 0.1681\n",
      "Epoch: 1/30... Training loss: 0.1560\n",
      "Epoch: 1/30... Training loss: 0.1790\n",
      "Epoch: 1/30... Training loss: 0.1615\n",
      "Epoch: 1/30... Training loss: 0.1691\n",
      "Epoch: 1/30... Training loss: 0.1664\n",
      "Epoch: 1/30... Training loss: 0.1636\n",
      "Epoch: 1/30... Training loss: 0.1707\n",
      "Epoch: 1/30... Training loss: 0.1693\n",
      "Epoch: 1/30... Training loss: 0.1647\n",
      "Epoch: 1/30... Training loss: 0.1642\n",
      "Epoch: 1/30... Training loss: 0.1762\n",
      "Epoch: 1/30... Training loss: 0.1693\n",
      "Epoch: 1/30... Training loss: 0.1717\n",
      "Epoch: 1/30... Training loss: 0.1717\n",
      "Epoch: 1/30... Training loss: 0.1727\n",
      "Epoch: 1/30... Training loss: 0.1638\n",
      "Epoch: 1/30... Training loss: 0.1724\n",
      "Epoch: 1/30... Training loss: 0.1586\n",
      "Epoch: 1/30... Training loss: 0.1738\n",
      "Epoch: 1/30... Training loss: 0.1668\n",
      "Epoch: 1/30... Training loss: 0.1754\n",
      "Epoch: 1/30... Training loss: 0.1795\n",
      "Epoch: 1/30... Training loss: 0.1677\n",
      "Epoch: 1/30... Training loss: 0.1707\n",
      "Epoch: 1/30... Training loss: 0.1660\n",
      "Epoch: 1/30... Training loss: 0.1711\n",
      "Epoch: 1/30... Training loss: 0.1669\n",
      "Epoch: 1/30... Training loss: 0.1728\n",
      "Epoch: 1/30... Training loss: 0.1789\n",
      "Epoch: 1/30... Training loss: 0.1734\n",
      "Epoch: 1/30... Training loss: 0.1855\n",
      "Epoch: 1/30... Training loss: 0.1681\n",
      "Epoch: 1/30... Training loss: 0.1646\n",
      "Epoch: 1/30... Training loss: 0.1565\n",
      "Epoch: 1/30... Training loss: 0.1747\n",
      "Epoch: 1/30... Training loss: 0.1709\n",
      "Epoch: 1/30... Training loss: 0.1691\n",
      "Epoch: 1/30... Training loss: 0.1593\n",
      "Epoch: 1/30... Training loss: 0.1640\n",
      "Epoch: 1/30... Training loss: 0.1556\n",
      "Epoch: 1/30... Training loss: 0.1683\n",
      "Epoch: 1/30... Training loss: 0.1690\n",
      "Epoch: 1/30... Training loss: 0.1591\n",
      "Epoch: 1/30... Training loss: 0.1610\n",
      "Epoch: 1/30... Training loss: 0.1707\n",
      "Epoch: 1/30... Training loss: 0.1606\n",
      "Epoch: 1/30... Training loss: 0.1610\n",
      "Epoch: 1/30... Training loss: 0.1638\n",
      "Epoch: 1/30... Training loss: 0.1622\n",
      "Epoch: 1/30... Training loss: 0.1554\n",
      "Epoch: 1/30... Training loss: 0.1598\n",
      "Epoch: 1/30... Training loss: 0.1729\n",
      "Epoch: 1/30... Training loss: 0.1707\n",
      "Epoch: 1/30... Training loss: 0.1603\n",
      "Epoch: 1/30... Training loss: 0.1724\n",
      "Epoch: 1/30... Training loss: 0.1705\n",
      "Epoch: 1/30... Training loss: 0.1703\n",
      "Epoch: 1/30... Training loss: 0.1625\n",
      "Epoch: 1/30... Training loss: 0.1652\n",
      "Epoch: 1/30... Training loss: 0.1641\n",
      "Epoch: 1/30... Training loss: 0.1666\n",
      "Epoch: 1/30... Training loss: 0.1525\n",
      "Epoch: 1/30... Training loss: 0.1551\n",
      "Epoch: 1/30... Training loss: 0.1635\n",
      "Epoch: 1/30... Training loss: 0.1523\n",
      "Epoch: 1/30... Training loss: 0.1573\n",
      "Epoch: 1/30... Training loss: 0.1825\n",
      "Epoch: 1/30... Training loss: 0.1566\n",
      "Epoch: 1/30... Training loss: 0.1562\n",
      "Epoch: 1/30... Training loss: 0.1622\n",
      "Epoch: 1/30... Training loss: 0.1637\n",
      "Epoch: 1/30... Training loss: 0.1705\n",
      "Epoch: 1/30... Training loss: 0.1551\n",
      "Epoch: 1/30... Training loss: 0.1514\n",
      "Epoch: 1/30... Training loss: 0.1728\n",
      "Epoch: 1/30... Training loss: 0.1594\n",
      "Epoch: 1/30... Training loss: 0.1641\n",
      "Epoch: 1/30... Training loss: 0.1646\n",
      "Epoch: 1/30... Training loss: 0.1641\n",
      "Epoch: 1/30... Training loss: 0.1610\n",
      "Epoch: 1/30... Training loss: 0.1607\n",
      "Epoch: 1/30... Training loss: 0.1611\n",
      "Epoch: 1/30... Training loss: 0.1708\n",
      "Epoch: 1/30... Training loss: 0.1508\n",
      "Epoch: 1/30... Training loss: 0.1622\n",
      "Epoch: 1/30... Training loss: 0.1648\n",
      "Epoch: 1/30... Training loss: 0.1669\n",
      "Epoch: 1/30... Training loss: 0.1635\n",
      "Epoch: 1/30... Training loss: 0.1595\n",
      "Epoch: 1/30... Training loss: 0.1640\n",
      "Epoch: 1/30... Training loss: 0.1662\n",
      "Epoch: 1/30... Training loss: 0.1636\n",
      "Epoch: 1/30... Training loss: 0.1655\n",
      "Epoch: 1/30... Training loss: 0.1689\n",
      "Epoch: 1/30... Training loss: 0.1630\n",
      "Epoch: 1/30... Training loss: 0.1564\n",
      "Epoch: 1/30... Training loss: 0.1599\n",
      "Epoch: 1/30... Training loss: 0.1478\n",
      "Epoch: 1/30... Training loss: 0.1665\n",
      "Epoch: 1/30... Training loss: 0.1463\n",
      "Epoch: 1/30... Training loss: 0.1581\n",
      "Epoch: 1/30... Training loss: 0.1602\n",
      "Epoch: 1/30... Training loss: 0.1505\n",
      "Epoch: 1/30... Training loss: 0.1663\n",
      "Epoch: 1/30... Training loss: 0.1619\n",
      "Epoch: 1/30... Training loss: 0.1540\n",
      "Epoch: 1/30... Training loss: 0.1581\n",
      "Epoch: 1/30... Training loss: 0.1646\n",
      "Epoch: 1/30... Training loss: 0.1581\n",
      "Epoch: 1/30... Training loss: 0.1632\n",
      "Epoch: 1/30... Training loss: 0.1574\n",
      "Epoch: 1/30... Training loss: 0.1605\n",
      "Epoch: 1/30... Training loss: 0.1584\n",
      "Epoch: 1/30... Training loss: 0.1604\n",
      "Epoch: 1/30... Training loss: 0.1510\n",
      "Epoch: 1/30... Training loss: 0.1596\n",
      "Epoch: 1/30... Training loss: 0.1603\n",
      "Epoch: 1/30... Training loss: 0.1604\n",
      "Epoch: 1/30... Training loss: 0.1671\n",
      "Epoch: 1/30... Training loss: 0.1559\n",
      "Epoch: 1/30... Training loss: 0.1693\n",
      "Epoch: 1/30... Training loss: 0.1579\n",
      "Epoch: 1/30... Training loss: 0.1522\n",
      "Epoch: 1/30... Training loss: 0.1698\n",
      "Epoch: 1/30... Training loss: 0.1640\n",
      "Epoch: 1/30... Training loss: 0.1615\n",
      "Epoch: 1/30... Training loss: 0.1619\n",
      "Epoch: 1/30... Training loss: 0.1632\n",
      "Epoch: 1/30... Training loss: 0.1702\n",
      "Epoch: 1/30... Training loss: 0.1640\n",
      "Epoch: 1/30... Training loss: 0.1646\n",
      "Epoch: 1/30... Training loss: 0.1557\n",
      "Epoch: 1/30... Training loss: 0.1625\n",
      "Epoch: 1/30... Training loss: 0.1538\n",
      "Epoch: 1/30... Training loss: 0.1579\n",
      "Epoch: 1/30... Training loss: 0.1551\n",
      "Epoch: 1/30... Training loss: 0.1598\n",
      "Epoch: 1/30... Training loss: 0.1424\n",
      "Epoch: 1/30... Training loss: 0.1538\n",
      "Epoch: 1/30... Training loss: 0.1568\n",
      "Epoch: 1/30... Training loss: 0.1467\n",
      "Epoch: 1/30... Training loss: 0.1525\n",
      "Epoch: 1/30... Training loss: 0.1724\n",
      "Epoch: 1/30... Training loss: 0.1570\n",
      "Epoch: 1/30... Training loss: 0.1526\n",
      "Epoch: 1/30... Training loss: 0.1521\n",
      "Epoch: 1/30... Training loss: 0.1637\n",
      "Epoch: 1/30... Training loss: 0.1543\n",
      "Epoch: 1/30... Training loss: 0.1617\n",
      "Epoch: 1/30... Training loss: 0.1620\n",
      "Epoch: 1/30... Training loss: 0.1437\n",
      "Epoch: 1/30... Training loss: 0.1703\n",
      "Epoch: 1/30... Training loss: 0.1543\n",
      "Epoch: 1/30... Training loss: 0.1551\n",
      "Epoch: 1/30... Training loss: 0.1708\n",
      "Epoch: 1/30... Training loss: 0.1652\n",
      "Epoch: 1/30... Training loss: 0.1735\n",
      "Epoch: 1/30... Training loss: 0.1500\n",
      "Epoch: 1/30... Training loss: 0.1595\n",
      "Epoch: 1/30... Training loss: 0.1469\n",
      "Epoch: 1/30... Training loss: 0.1618\n",
      "Epoch: 1/30... Training loss: 0.1594\n",
      "Epoch: 1/30... Training loss: 0.1568\n",
      "Epoch: 1/30... Training loss: 0.1513\n",
      "Epoch: 1/30... Training loss: 0.1522\n",
      "Epoch: 1/30... Training loss: 0.1537\n",
      "Epoch: 1/30... Training loss: 0.1743\n",
      "Epoch: 1/30... Training loss: 0.1615\n",
      "Epoch: 1/30... Training loss: 0.1588\n",
      "Epoch: 1/30... Training loss: 0.1484\n",
      "Epoch: 1/30... Training loss: 0.1578\n",
      "Epoch: 1/30... Training loss: 0.1599\n",
      "Epoch: 1/30... Training loss: 0.1538\n",
      "Epoch: 1/30... Training loss: 0.1547\n",
      "Epoch: 1/30... Training loss: 0.1659\n",
      "Epoch: 1/30... Training loss: 0.1516\n",
      "Epoch: 1/30... Training loss: 0.1420\n",
      "Epoch: 1/30... Training loss: 0.1633\n",
      "Epoch: 1/30... Training loss: 0.1552\n",
      "Epoch: 1/30... Training loss: 0.1547\n",
      "Epoch: 1/30... Training loss: 0.1658\n",
      "Epoch: 1/30... Training loss: 0.1588\n",
      "Epoch: 1/30... Training loss: 0.1532\n",
      "Epoch: 1/30... Training loss: 0.1443\n",
      "Epoch: 1/30... Training loss: 0.1549\n",
      "Epoch: 1/30... Training loss: 0.1538\n",
      "Epoch: 1/30... Training loss: 0.1521\n",
      "Epoch: 1/30... Training loss: 0.1557\n",
      "Epoch: 1/30... Training loss: 0.1728\n",
      "Epoch: 1/30... Training loss: 0.1546\n",
      "Epoch: 1/30... Training loss: 0.1517\n",
      "Epoch: 1/30... Training loss: 0.1509\n",
      "Epoch: 1/30... Training loss: 0.1531\n",
      "Epoch: 1/30... Training loss: 0.1349\n",
      "Epoch: 1/30... Training loss: 0.1623\n",
      "Epoch: 1/30... Training loss: 0.1549\n",
      "Epoch: 1/30... Training loss: 0.1545\n",
      "Epoch: 1/30... Training loss: 0.1558\n",
      "Epoch: 1/30... Training loss: 0.1538\n",
      "Epoch: 1/30... Training loss: 0.1531\n",
      "Epoch: 1/30... Training loss: 0.1610\n",
      "Epoch: 1/30... Training loss: 0.1566\n",
      "Epoch: 1/30... Training loss: 0.1546\n",
      "Epoch: 1/30... Training loss: 0.1574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30... Training loss: 0.1577\n",
      "Epoch: 1/30... Training loss: 0.1526\n",
      "Epoch: 1/30... Training loss: 0.1595\n",
      "Epoch: 1/30... Training loss: 0.1555\n",
      "Epoch: 1/30... Training loss: 0.1630\n",
      "Epoch: 1/30... Training loss: 0.1530\n",
      "Epoch: 1/30... Training loss: 0.1502\n",
      "Epoch: 1/30... Training loss: 0.1575\n",
      "Epoch: 1/30... Training loss: 0.1503\n",
      "Epoch: 1/30... Training loss: 0.1523\n",
      "Epoch: 1/30... Training loss: 0.1479\n",
      "Epoch: 1/30... Training loss: 0.1526\n",
      "Epoch: 1/30... Training loss: 0.1497\n",
      "Epoch: 1/30... Training loss: 0.1549\n",
      "Epoch: 1/30... Training loss: 0.1645\n",
      "Epoch: 1/30... Training loss: 0.1567\n",
      "Epoch: 1/30... Training loss: 0.1525\n",
      "Epoch: 1/30... Training loss: 0.1425\n",
      "Epoch: 1/30... Training loss: 0.1488\n",
      "Epoch: 1/30... Training loss: 0.1507\n",
      "Epoch: 1/30... Training loss: 0.1419\n",
      "Epoch: 1/30... Training loss: 0.1492\n",
      "Epoch: 1/30... Training loss: 0.1504\n",
      "Epoch: 1/30... Training loss: 0.1483\n",
      "Epoch: 1/30... Training loss: 0.1496\n",
      "Epoch: 1/30... Training loss: 0.1536\n",
      "Epoch: 1/30... Training loss: 0.1622\n",
      "Epoch: 1/30... Training loss: 0.1485\n",
      "Epoch: 1/30... Training loss: 0.1570\n",
      "Epoch: 1/30... Training loss: 0.1529\n",
      "Epoch: 1/30... Training loss: 0.1555\n",
      "Epoch: 1/30... Training loss: 0.1422\n",
      "Epoch: 1/30... Training loss: 0.1522\n",
      "Epoch: 1/30... Training loss: 0.1494\n",
      "Epoch: 1/30... Training loss: 0.1505\n",
      "Epoch: 1/30... Training loss: 0.1540\n",
      "Epoch: 1/30... Training loss: 0.1729\n",
      "Epoch: 1/30... Training loss: 0.1591\n",
      "Epoch: 1/30... Training loss: 0.1510\n",
      "Epoch: 1/30... Training loss: 0.1509\n",
      "Epoch: 1/30... Training loss: 0.1377\n",
      "Epoch: 1/30... Training loss: 0.1507\n",
      "Epoch: 1/30... Training loss: 0.1616\n",
      "Epoch: 1/30... Training loss: 0.1503\n",
      "Epoch: 1/30... Training loss: 0.1449\n",
      "Epoch: 1/30... Training loss: 0.1499\n",
      "Epoch: 1/30... Training loss: 0.1447\n",
      "Epoch: 1/30... Training loss: 0.1486\n",
      "Epoch: 1/30... Training loss: 0.1527\n",
      "Epoch: 1/30... Training loss: 0.1619\n",
      "Epoch: 1/30... Training loss: 0.1461\n",
      "Epoch: 1/30... Training loss: 0.1422\n",
      "Epoch: 1/30... Training loss: 0.1531\n",
      "Epoch: 1/30... Training loss: 0.1710\n",
      "Epoch: 1/30... Training loss: 0.1523\n",
      "Epoch: 1/30... Training loss: 0.1527\n",
      "Epoch: 1/30... Training loss: 0.1275\n",
      "Epoch: 1/30... Training loss: 0.1447\n",
      "Epoch: 1/30... Training loss: 0.1511\n",
      "Epoch: 1/30... Training loss: 0.1476\n",
      "Epoch: 1/30... Training loss: 0.1464\n",
      "Epoch: 1/30... Training loss: 0.1469\n",
      "Epoch: 1/30... Training loss: 0.1506\n",
      "Epoch: 1/30... Training loss: 0.1537\n",
      "Epoch: 1/30... Training loss: 0.1401\n",
      "Epoch: 1/30... Training loss: 0.1503\n",
      "Epoch: 1/30... Training loss: 0.1425\n",
      "Epoch: 1/30... Training loss: 0.1354\n",
      "Epoch: 1/30... Training loss: 0.1520\n",
      "Epoch: 1/30... Training loss: 0.1630\n",
      "Epoch: 1/30... Training loss: 0.1530\n",
      "Epoch: 1/30... Training loss: 0.1474\n",
      "Epoch: 1/30... Training loss: 0.1467\n",
      "Epoch: 1/30... Training loss: 0.1540\n",
      "Epoch: 1/30... Training loss: 0.1539\n",
      "Epoch: 1/30... Training loss: 0.1516\n",
      "Epoch: 1/30... Training loss: 0.1446\n",
      "Epoch: 1/30... Training loss: 0.1557\n",
      "Epoch: 1/30... Training loss: 0.1403\n",
      "Epoch: 1/30... Training loss: 0.1508\n",
      "Epoch: 1/30... Training loss: 0.1420\n",
      "Epoch: 1/30... Training loss: 0.1409\n",
      "Epoch: 1/30... Training loss: 0.1485\n",
      "Epoch: 1/30... Training loss: 0.1545\n",
      "Epoch: 1/30... Training loss: 0.1414\n",
      "Epoch: 1/30... Training loss: 0.1579\n",
      "Epoch: 1/30... Training loss: 0.1545\n",
      "Epoch: 1/30... Training loss: 0.1542\n",
      "Epoch: 1/30... Training loss: 0.1543\n",
      "Epoch: 1/30... Training loss: 0.1414\n",
      "Epoch: 1/30... Training loss: 0.1477\n",
      "Epoch: 1/30... Training loss: 0.1406\n",
      "Epoch: 1/30... Training loss: 0.1530\n",
      "Epoch: 1/30... Training loss: 0.1514\n",
      "Epoch: 1/30... Training loss: 0.1525\n",
      "Epoch: 1/30... Training loss: 0.1571\n",
      "Epoch: 1/30... Training loss: 0.1346\n",
      "Epoch: 1/30... Training loss: 0.1414\n",
      "Epoch: 1/30... Training loss: 0.1441\n",
      "Epoch: 1/30... Training loss: 0.1433\n",
      "Epoch: 1/30... Training loss: 0.1466\n",
      "Epoch: 1/30... Training loss: 0.1418\n",
      "Epoch: 1/30... Training loss: 0.1528\n",
      "Epoch: 1/30... Training loss: 0.1505\n",
      "Epoch: 1/30... Training loss: 0.1514\n",
      "Epoch: 1/30... Training loss: 0.1364\n",
      "Epoch: 1/30... Training loss: 0.1432\n",
      "Epoch: 1/30... Training loss: 0.1511\n",
      "Epoch: 1/30... Training loss: 0.1508\n",
      "Epoch: 1/30... Training loss: 0.1542\n",
      "Epoch: 1/30... Training loss: 0.1502\n",
      "Epoch: 1/30... Training loss: 0.1489\n",
      "Epoch: 1/30... Training loss: 0.1502\n",
      "Epoch: 1/30... Training loss: 0.1457\n",
      "Epoch: 1/30... Training loss: 0.1448\n",
      "Epoch: 1/30... Training loss: 0.1462\n",
      "Epoch: 1/30... Training loss: 0.1407\n",
      "Epoch: 1/30... Training loss: 0.1567\n",
      "Epoch: 1/30... Training loss: 0.1342\n",
      "Epoch: 1/30... Training loss: 0.1403\n",
      "Epoch: 1/30... Training loss: 0.1385\n",
      "Epoch: 1/30... Training loss: 0.1398\n",
      "Epoch: 1/30... Training loss: 0.1586\n",
      "Epoch: 1/30... Training loss: 0.1563\n",
      "Epoch: 1/30... Training loss: 0.1456\n",
      "Epoch: 1/30... Training loss: 0.1448\n",
      "Epoch: 1/30... Training loss: 0.1386\n",
      "Epoch: 1/30... Training loss: 0.1361\n",
      "Epoch: 1/30... Training loss: 0.1498\n",
      "Epoch: 1/30... Training loss: 0.1478\n",
      "Epoch: 1/30... Training loss: 0.1520\n",
      "Epoch: 1/30... Training loss: 0.1494\n",
      "Epoch: 1/30... Training loss: 0.1526\n",
      "Epoch: 1/30... Training loss: 0.1405\n",
      "Epoch: 1/30... Training loss: 0.1481\n",
      "Epoch: 1/30... Training loss: 0.1626\n",
      "Epoch: 1/30... Training loss: 0.1434\n",
      "Epoch: 1/30... Training loss: 0.1411\n",
      "Epoch: 1/30... Training loss: 0.1522\n",
      "Epoch: 1/30... Training loss: 0.1353\n",
      "Epoch: 1/30... Training loss: 0.1505\n",
      "Epoch: 1/30... Training loss: 0.1416\n",
      "Epoch: 1/30... Training loss: 0.1443\n",
      "Epoch: 1/30... Training loss: 0.1412\n",
      "Epoch: 1/30... Training loss: 0.1321\n",
      "Epoch: 1/30... Training loss: 0.1493\n",
      "Epoch: 1/30... Training loss: 0.1437\n",
      "Epoch: 1/30... Training loss: 0.1483\n",
      "Epoch: 1/30... Training loss: 0.1404\n",
      "Epoch: 1/30... Training loss: 0.1530\n",
      "Epoch: 1/30... Training loss: 0.1425\n",
      "Epoch: 1/30... Training loss: 0.1432\n",
      "Epoch: 1/30... Training loss: 0.1394\n",
      "Epoch: 1/30... Training loss: 0.1277\n",
      "Epoch: 1/30... Training loss: 0.1335\n",
      "Epoch: 1/30... Training loss: 0.1473\n",
      "Epoch: 1/30... Training loss: 0.1461\n",
      "Epoch: 1/30... Training loss: 0.1345\n",
      "Epoch: 1/30... Training loss: 0.1492\n",
      "Epoch: 1/30... Training loss: 0.1425\n",
      "Epoch: 1/30... Training loss: 0.1406\n",
      "Epoch: 1/30... Training loss: 0.1391\n",
      "Epoch: 1/30... Training loss: 0.1407\n",
      "Epoch: 1/30... Training loss: 0.1421\n",
      "Epoch: 1/30... Training loss: 0.1353\n",
      "Epoch: 1/30... Training loss: 0.1413\n",
      "Epoch: 1/30... Training loss: 0.1326\n",
      "Epoch: 1/30... Training loss: 0.1428\n",
      "Epoch: 1/30... Training loss: 0.1431\n",
      "Epoch: 1/30... Training loss: 0.1418\n",
      "Epoch: 1/30... Training loss: 0.1467\n",
      "Epoch: 1/30... Training loss: 0.1464\n",
      "Epoch: 1/30... Training loss: 0.1366\n",
      "Epoch: 1/30... Training loss: 0.1616\n",
      "Epoch: 1/30... Training loss: 0.1461\n",
      "Epoch: 1/30... Training loss: 0.1457\n",
      "Epoch: 1/30... Training loss: 0.1361\n",
      "Epoch: 1/30... Training loss: 0.1465\n",
      "Epoch: 1/30... Training loss: 0.1418\n",
      "Epoch: 1/30... Training loss: 0.1365\n",
      "Epoch: 1/30... Training loss: 0.1486\n",
      "Epoch: 1/30... Training loss: 0.1366\n",
      "Epoch: 1/30... Training loss: 0.1494\n",
      "Epoch: 1/30... Training loss: 0.1399\n",
      "Epoch: 1/30... Training loss: 0.1518\n",
      "Epoch: 1/30... Training loss: 0.1468\n",
      "Epoch: 1/30... Training loss: 0.1381\n",
      "Epoch: 1/30... Training loss: 0.1447\n",
      "Epoch: 1/30... Training loss: 0.1385\n",
      "Epoch: 1/30... Training loss: 0.1326\n",
      "Epoch: 1/30... Training loss: 0.1414\n",
      "Epoch: 1/30... Training loss: 0.1411\n",
      "Epoch: 1/30... Training loss: 0.1450\n",
      "Epoch: 1/30... Training loss: 0.1414\n",
      "Epoch: 1/30... Training loss: 0.1441\n",
      "Epoch: 1/30... Training loss: 0.1342\n",
      "Epoch: 1/30... Training loss: 0.1376\n",
      "Epoch: 1/30... Training loss: 0.1333\n",
      "Epoch: 1/30... Training loss: 0.1390\n",
      "Epoch: 1/30... Training loss: 0.1518\n",
      "Epoch: 1/30... Training loss: 0.1341\n",
      "Epoch: 1/30... Training loss: 0.1309\n",
      "Epoch: 1/30... Training loss: 0.1441\n",
      "Epoch: 1/30... Training loss: 0.1471\n",
      "Epoch: 1/30... Training loss: 0.1440\n",
      "Epoch: 1/30... Training loss: 0.1376\n",
      "Epoch: 1/30... Training loss: 0.1350\n",
      "Epoch: 1/30... Training loss: 0.1447\n",
      "Epoch: 1/30... Training loss: 0.1366\n",
      "Epoch: 1/30... Training loss: 0.1460\n",
      "Epoch: 1/30... Training loss: 0.1361\n",
      "Epoch: 1/30... Training loss: 0.1366\n",
      "Epoch: 1/30... Training loss: 0.1474\n",
      "Epoch: 1/30... Training loss: 0.1401\n",
      "Epoch: 1/30... Training loss: 0.1337\n",
      "Epoch: 1/30... Training loss: 0.1357\n",
      "Epoch: 1/30... Training loss: 0.1379\n",
      "Epoch: 1/30... Training loss: 0.1450\n",
      "Epoch: 1/30... Training loss: 0.1311\n",
      "Epoch: 1/30... Training loss: 0.1419\n",
      "Epoch: 1/30... Training loss: 0.1468\n",
      "Epoch: 1/30... Training loss: 0.1432\n",
      "Epoch: 1/30... Training loss: 0.1367\n",
      "Epoch: 1/30... Training loss: 0.1392\n",
      "Epoch: 1/30... Training loss: 0.1485\n",
      "Epoch: 1/30... Training loss: 0.1332\n",
      "Epoch: 1/30... Training loss: 0.1368\n",
      "Epoch: 1/30... Training loss: 0.1392\n",
      "Epoch: 1/30... Training loss: 0.1222\n",
      "Epoch: 1/30... Training loss: 0.1427\n",
      "Epoch: 1/30... Training loss: 0.1509\n",
      "Epoch: 1/30... Training loss: 0.1377\n",
      "Epoch: 1/30... Training loss: 0.1466\n",
      "Epoch: 1/30... Training loss: 0.1344\n",
      "Epoch: 1/30... Training loss: 0.1363\n",
      "Epoch: 1/30... Training loss: 0.1443\n",
      "Epoch: 1/30... Training loss: 0.1353\n",
      "Epoch: 1/30... Training loss: 0.1316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30... Training loss: 0.1466\n",
      "Epoch: 1/30... Training loss: 0.1375\n",
      "Epoch: 1/30... Training loss: 0.1422\n",
      "Epoch: 1/30... Training loss: 0.1402\n",
      "Epoch: 1/30... Training loss: 0.1316\n",
      "Epoch: 1/30... Training loss: 0.1373\n",
      "Epoch: 1/30... Training loss: 0.1383\n",
      "Epoch: 1/30... Training loss: 0.1297\n",
      "Epoch: 1/30... Training loss: 0.1370\n",
      "Epoch: 1/30... Training loss: 0.1353\n",
      "Epoch: 1/30... Training loss: 0.1371\n",
      "Epoch: 1/30... Training loss: 0.1464\n",
      "Epoch: 1/30... Training loss: 0.1428\n",
      "Epoch: 1/30... Training loss: 0.1362\n",
      "Epoch: 1/30... Training loss: 0.1382\n",
      "Epoch: 1/30... Training loss: 0.1386\n",
      "Epoch: 1/30... Training loss: 0.1261\n",
      "Epoch: 1/30... Training loss: 0.1451\n",
      "Epoch: 1/30... Training loss: 0.1489\n",
      "Epoch: 1/30... Training loss: 0.1411\n",
      "Epoch: 1/30... Training loss: 0.1377\n",
      "Epoch: 1/30... Training loss: 0.1379\n",
      "Epoch: 1/30... Training loss: 0.1299\n",
      "Epoch: 1/30... Training loss: 0.1346\n",
      "Epoch: 1/30... Training loss: 0.1382\n",
      "Epoch: 1/30... Training loss: 0.1435\n",
      "Epoch: 1/30... Training loss: 0.1238\n",
      "Epoch: 1/30... Training loss: 0.1345\n",
      "Epoch: 1/30... Training loss: 0.1371\n",
      "Epoch: 1/30... Training loss: 0.1325\n",
      "Epoch: 1/30... Training loss: 0.1396\n",
      "Epoch: 1/30... Training loss: 0.1379\n",
      "Epoch: 1/30... Training loss: 0.1325\n",
      "Epoch: 1/30... Training loss: 0.1397\n",
      "Epoch: 1/30... Training loss: 0.1364\n",
      "Epoch: 1/30... Training loss: 0.1444\n",
      "Epoch: 1/30... Training loss: 0.1418\n",
      "Epoch: 1/30... Training loss: 0.1381\n",
      "Epoch: 1/30... Training loss: 0.1354\n",
      "Epoch: 1/30... Training loss: 0.1421\n",
      "Epoch: 1/30... Training loss: 0.1437\n",
      "Epoch: 1/30... Training loss: 0.1363\n",
      "Epoch: 1/30... Training loss: 0.1317\n",
      "Epoch: 1/30... Training loss: 0.1359\n",
      "Epoch: 1/30... Training loss: 0.1411\n",
      "Epoch: 1/30... Training loss: 0.1370\n",
      "Epoch: 1/30... Training loss: 0.1357\n",
      "Epoch: 1/30... Training loss: 0.1366\n",
      "Epoch: 1/30... Training loss: 0.1322\n",
      "Epoch: 1/30... Training loss: 0.1394\n",
      "Epoch: 1/30... Training loss: 0.1453\n",
      "Epoch: 1/30... Training loss: 0.1401\n",
      "Epoch: 1/30... Training loss: 0.1434\n",
      "Epoch: 1/30... Training loss: 0.1374\n",
      "Epoch: 1/30... Training loss: 0.1332\n",
      "Epoch: 1/30... Training loss: 0.1347\n",
      "Epoch: 1/30... Training loss: 0.1333\n",
      "Epoch: 1/30... Training loss: 0.1313\n",
      "Epoch: 1/30... Training loss: 0.1336\n",
      "Epoch: 1/30... Training loss: 0.1454\n",
      "Epoch: 1/30... Training loss: 0.1394\n",
      "Epoch: 1/30... Training loss: 0.1325\n",
      "Epoch: 1/30... Training loss: 0.1312\n",
      "Epoch: 1/30... Training loss: 0.1388\n",
      "Epoch: 1/30... Training loss: 0.1363\n",
      "Epoch: 1/30... Training loss: 0.1395\n",
      "Epoch: 1/30... Training loss: 0.1419\n",
      "Epoch: 1/30... Training loss: 0.1563\n",
      "Epoch: 1/30... Training loss: 0.1296\n",
      "Epoch: 1/30... Training loss: 0.1333\n",
      "Epoch: 1/30... Training loss: 0.1403\n",
      "Epoch: 1/30... Training loss: 0.1379\n",
      "Epoch: 1/30... Training loss: 0.1365\n",
      "Epoch: 1/30... Training loss: 0.1461\n",
      "Epoch: 1/30... Training loss: 0.1345\n",
      "Epoch: 1/30... Training loss: 0.1385\n",
      "Epoch: 1/30... Training loss: 0.1440\n",
      "Epoch: 1/30... Training loss: 0.1442\n",
      "Epoch: 1/30... Training loss: 0.1298\n",
      "Epoch: 1/30... Training loss: 0.1314\n",
      "Epoch: 1/30... Training loss: 0.1340\n",
      "Epoch: 1/30... Training loss: 0.1397\n",
      "Epoch: 1/30... Training loss: 0.1419\n",
      "Epoch: 1/30... Training loss: 0.1276\n",
      "Epoch: 1/30... Training loss: 0.1345\n",
      "Epoch: 1/30... Training loss: 0.1343\n",
      "Epoch: 1/30... Training loss: 0.1356\n",
      "Epoch: 1/30... Training loss: 0.1386\n",
      "Epoch: 1/30... Training loss: 0.1354\n",
      "Epoch: 1/30... Training loss: 0.1366\n",
      "Epoch: 1/30... Training loss: 0.1281\n",
      "Epoch: 1/30... Training loss: 0.1399\n",
      "Epoch: 1/30... Training loss: 0.1314\n",
      "Epoch: 1/30... Training loss: 0.1309\n",
      "Epoch: 1/30... Training loss: 0.1356\n",
      "Epoch: 1/30... Training loss: 0.1427\n",
      "Epoch: 1/30... Training loss: 0.1299\n",
      "Epoch: 1/30... Training loss: 0.1237\n",
      "Epoch: 1/30... Training loss: 0.1407\n",
      "Epoch: 1/30... Training loss: 0.1361\n",
      "Epoch: 1/30... Training loss: 0.1292\n",
      "Epoch: 1/30... Training loss: 0.1369\n",
      "Epoch: 1/30... Training loss: 0.1319\n",
      "Epoch: 1/30... Training loss: 0.1347\n",
      "Epoch: 1/30... Training loss: 0.1342\n",
      "Epoch: 1/30... Training loss: 0.1423\n",
      "Epoch: 1/30... Training loss: 0.1374\n",
      "Epoch: 1/30... Training loss: 0.1302\n",
      "Epoch: 1/30... Training loss: 0.1396\n",
      "Epoch: 1/30... Training loss: 0.1497\n",
      "Epoch: 1/30... Training loss: 0.1395\n",
      "Epoch: 1/30... Training loss: 0.1426\n",
      "Epoch: 1/30... Training loss: 0.1295\n",
      "Epoch: 1/30... Training loss: 0.1341\n",
      "Epoch: 1/30... Training loss: 0.1411\n",
      "Epoch: 1/30... Training loss: 0.1349\n",
      "Epoch: 1/30... Training loss: 0.1282\n",
      "Epoch: 1/30... Training loss: 0.1284\n",
      "Epoch: 1/30... Training loss: 0.1308\n",
      "Epoch: 1/30... Training loss: 0.1432\n",
      "Epoch: 1/30... Training loss: 0.1405\n",
      "Epoch: 1/30... Training loss: 0.1341\n",
      "Epoch: 1/30... Training loss: 0.1367\n",
      "Epoch: 1/30... Training loss: 0.1219\n",
      "Epoch: 1/30... Training loss: 0.1458\n",
      "Epoch: 1/30... Training loss: 0.1423\n",
      "Epoch: 1/30... Training loss: 0.1371\n",
      "Epoch: 1/30... Training loss: 0.1311\n",
      "Epoch: 1/30... Training loss: 0.1382\n",
      "Epoch: 1/30... Training loss: 0.1337\n",
      "Epoch: 1/30... Training loss: 0.1300\n",
      "Epoch: 1/30... Training loss: 0.1344\n",
      "Epoch: 1/30... Training loss: 0.1340\n",
      "Epoch: 1/30... Training loss: 0.1440\n",
      "Epoch: 1/30... Training loss: 0.1366\n",
      "Epoch: 1/30... Training loss: 0.1378\n",
      "Epoch: 1/30... Training loss: 0.1355\n",
      "Epoch: 1/30... Training loss: 0.1295\n",
      "Epoch: 1/30... Training loss: 0.1314\n",
      "Epoch: 1/30... Training loss: 0.1456\n",
      "Epoch: 1/30... Training loss: 0.1421\n",
      "Epoch: 1/30... Training loss: 0.1340\n",
      "Epoch: 1/30... Training loss: 0.1307\n",
      "Epoch: 1/30... Training loss: 0.1409\n",
      "Epoch: 1/30... Training loss: 0.1334\n",
      "Epoch: 1/30... Training loss: 0.1227\n",
      "Epoch: 1/30... Training loss: 0.1336\n",
      "Epoch: 1/30... Training loss: 0.1332\n",
      "Epoch: 1/30... Training loss: 0.1310\n",
      "Epoch: 1/30... Training loss: 0.1305\n",
      "Epoch: 1/30... Training loss: 0.1328\n",
      "Epoch: 1/30... Training loss: 0.1330\n",
      "Epoch: 1/30... Training loss: 0.1294\n",
      "Epoch: 1/30... Training loss: 0.1349\n",
      "Epoch: 1/30... Training loss: 0.1458\n",
      "Epoch: 1/30... Training loss: 0.1347\n",
      "Epoch: 1/30... Training loss: 0.1373\n",
      "Epoch: 1/30... Training loss: 0.1362\n",
      "Epoch: 1/30... Training loss: 0.1348\n",
      "Epoch: 1/30... Training loss: 0.1306\n",
      "Epoch: 1/30... Training loss: 0.1376\n",
      "Epoch: 1/30... Training loss: 0.1371\n",
      "Epoch: 1/30... Training loss: 0.1269\n",
      "Epoch: 1/30... Training loss: 0.1342\n",
      "Epoch: 1/30... Training loss: 0.1401\n",
      "Epoch: 1/30... Training loss: 0.1329\n",
      "Epoch: 1/30... Training loss: 0.1372\n",
      "Epoch: 1/30... Training loss: 0.1245\n",
      "Epoch: 1/30... Training loss: 0.1397\n",
      "Epoch: 1/30... Training loss: 0.1274\n",
      "Epoch: 1/30... Training loss: 0.1351\n",
      "Epoch: 1/30... Training loss: 0.1368\n",
      "Epoch: 1/30... Training loss: 0.1346\n",
      "Epoch: 1/30... Training loss: 0.1392\n",
      "Epoch: 1/30... Training loss: 0.1383\n",
      "Epoch: 1/30... Training loss: 0.1383\n",
      "Epoch: 1/30... Training loss: 0.1239\n",
      "Epoch: 1/30... Training loss: 0.1447\n",
      "Epoch: 1/30... Training loss: 0.1255\n",
      "Epoch: 1/30... Training loss: 0.1342\n",
      "Epoch: 1/30... Training loss: 0.1347\n",
      "Epoch: 1/30... Training loss: 0.1286\n",
      "Epoch: 1/30... Training loss: 0.1316\n",
      "Epoch: 1/30... Training loss: 0.1334\n",
      "Epoch: 1/30... Training loss: 0.1163\n",
      "Epoch: 1/30... Training loss: 0.1353\n",
      "Epoch: 1/30... Training loss: 0.1328\n",
      "Epoch: 1/30... Training loss: 0.1289\n",
      "Epoch: 1/30... Training loss: 0.1185\n",
      "Epoch: 1/30... Training loss: 0.1372\n",
      "Epoch: 1/30... Training loss: 0.1289\n",
      "Epoch: 1/30... Training loss: 0.1387\n",
      "Epoch: 1/30... Training loss: 0.1269\n",
      "Epoch: 1/30... Training loss: 0.1221\n",
      "Epoch: 1/30... Training loss: 0.1222\n",
      "Epoch: 1/30... Training loss: 0.1242\n",
      "Epoch: 1/30... Training loss: 0.1270\n",
      "Epoch: 1/30... Training loss: 0.1339\n",
      "Epoch: 1/30... Training loss: 0.1415\n",
      "Epoch: 1/30... Training loss: 0.1208\n",
      "Epoch: 1/30... Training loss: 0.1371\n",
      "Epoch: 1/30... Training loss: 0.1242\n",
      "Epoch: 1/30... Training loss: 0.1431\n",
      "Epoch: 1/30... Training loss: 0.1288\n",
      "Epoch: 1/30... Training loss: 0.1351\n",
      "Epoch: 1/30... Training loss: 0.1339\n",
      "Epoch: 1/30... Training loss: 0.1243\n",
      "Epoch: 1/30... Training loss: 0.1255\n",
      "Epoch: 1/30... Training loss: 0.1245\n",
      "Epoch: 1/30... Training loss: 0.1331\n",
      "Epoch: 1/30... Training loss: 0.1284\n",
      "Epoch: 1/30... Training loss: 0.1222\n",
      "Epoch: 1/30... Training loss: 0.1217\n",
      "Epoch: 1/30... Training loss: 0.1342\n",
      "Epoch: 1/30... Training loss: 0.1464\n",
      "Epoch: 1/30... Training loss: 0.1364\n",
      "Epoch: 1/30... Training loss: 0.1259\n",
      "Epoch: 1/30... Training loss: 0.1285\n",
      "Epoch: 1/30... Training loss: 0.1383\n",
      "Epoch: 1/30... Training loss: 0.1295\n",
      "Epoch: 1/30... Training loss: 0.1292\n",
      "Epoch: 1/30... Training loss: 0.1260\n",
      "Epoch: 1/30... Training loss: 0.1334\n",
      "Epoch: 1/30... Training loss: 0.1304\n",
      "Epoch: 1/30... Training loss: 0.1347\n",
      "Epoch: 1/30... Training loss: 0.1374\n",
      "Epoch: 1/30... Training loss: 0.1312\n",
      "Epoch: 1/30... Training loss: 0.1327\n",
      "Epoch: 1/30... Training loss: 0.1186\n",
      "Epoch: 1/30... Training loss: 0.1383\n",
      "Epoch: 1/30... Training loss: 0.1329\n",
      "Epoch: 1/30... Training loss: 0.1324\n",
      "Epoch: 1/30... Training loss: 0.1384\n",
      "Epoch: 1/30... Training loss: 0.1334\n",
      "Epoch: 1/30... Training loss: 0.1365\n",
      "Epoch: 1/30... Training loss: 0.1420\n",
      "Epoch: 1/30... Training loss: 0.1308\n",
      "Epoch: 1/30... Training loss: 0.1283\n",
      "Epoch: 1/30... Training loss: 0.1247\n",
      "Epoch: 1/30... Training loss: 0.1260\n",
      "Epoch: 1/30... Training loss: 0.1285\n",
      "Epoch: 1/30... Training loss: 0.1458\n",
      "Epoch: 1/30... Training loss: 0.1265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30... Training loss: 0.1274\n",
      "Epoch: 1/30... Training loss: 0.1242\n",
      "Epoch: 1/30... Training loss: 0.1225\n",
      "Epoch: 1/30... Training loss: 0.1169\n",
      "Epoch: 1/30... Training loss: 0.1321\n",
      "Epoch: 1/30... Training loss: 0.1345\n",
      "Epoch: 1/30... Training loss: 0.1352\n",
      "Epoch: 1/30... Training loss: 0.1277\n",
      "Epoch: 1/30... Training loss: 0.1357\n",
      "Epoch: 1/30... Training loss: 0.1307\n",
      "Epoch: 1/30... Training loss: 0.1272\n",
      "Epoch: 1/30... Training loss: 0.1257\n",
      "Epoch: 1/30... Training loss: 0.1267\n",
      "Epoch: 1/30... Training loss: 0.1339\n",
      "Epoch: 1/30... Training loss: 0.1266\n",
      "Epoch: 1/30... Training loss: 0.1259\n",
      "Epoch: 1/30... Training loss: 0.1227\n",
      "Epoch: 1/30... Training loss: 0.1305\n",
      "Epoch: 1/30... Training loss: 0.1289\n",
      "Epoch: 1/30... Training loss: 0.1313\n",
      "Epoch: 1/30... Training loss: 0.1180\n",
      "Epoch: 1/30... Training loss: 0.1340\n",
      "Epoch: 1/30... Training loss: 0.1302\n",
      "Epoch: 1/30... Training loss: 0.1294\n",
      "Epoch: 1/30... Training loss: 0.1266\n",
      "Epoch: 1/30... Training loss: 0.1316\n",
      "Epoch: 1/30... Training loss: 0.1300\n",
      "Epoch: 1/30... Training loss: 0.1326\n",
      "Epoch: 1/30... Training loss: 0.1189\n",
      "Epoch: 1/30... Training loss: 0.1381\n",
      "Epoch: 1/30... Training loss: 0.1284\n",
      "Epoch: 1/30... Training loss: 0.1231\n",
      "Epoch: 1/30... Training loss: 0.1222\n",
      "Epoch: 1/30... Training loss: 0.1297\n",
      "Epoch: 1/30... Training loss: 0.1212\n",
      "Epoch: 1/30... Training loss: 0.1248\n",
      "Epoch: 1/30... Training loss: 0.1284\n",
      "Epoch: 1/30... Training loss: 0.1235\n",
      "Epoch: 1/30... Training loss: 0.1280\n",
      "Epoch: 1/30... Training loss: 0.1245\n",
      "Epoch: 1/30... Training loss: 0.1299\n",
      "Epoch: 1/30... Training loss: 0.1294\n",
      "Epoch: 1/30... Training loss: 0.1241\n",
      "Epoch: 1/30... Training loss: 0.1262\n",
      "Epoch: 1/30... Training loss: 0.1294\n",
      "Epoch: 1/30... Training loss: 0.1149\n",
      "Epoch: 1/30... Training loss: 0.1277\n",
      "Epoch: 1/30... Training loss: 0.1261\n",
      "Epoch: 1/30... Training loss: 0.1301\n",
      "Epoch: 1/30... Training loss: 0.1182\n",
      "Epoch: 1/30... Training loss: 0.1264\n",
      "Epoch: 1/30... Training loss: 0.1313\n",
      "Epoch: 1/30... Training loss: 0.1433\n",
      "Epoch: 1/30... Training loss: 0.1271\n",
      "Epoch: 1/30... Training loss: 0.1291\n",
      "Epoch: 1/30... Training loss: 0.1310\n",
      "Epoch: 1/30... Training loss: 0.1289\n",
      "Epoch: 1/30... Training loss: 0.1178\n",
      "Epoch: 1/30... Training loss: 0.1276\n",
      "Epoch: 1/30... Training loss: 0.1383\n",
      "Epoch: 1/30... Training loss: 0.1174\n",
      "Epoch: 2/30... Training loss: 0.1392\n",
      "Epoch: 2/30... Training loss: 0.1240\n",
      "Epoch: 2/30... Training loss: 0.1176\n",
      "Epoch: 2/30... Training loss: 0.1222\n",
      "Epoch: 2/30... Training loss: 0.1226\n",
      "Epoch: 2/30... Training loss: 0.1288\n",
      "Epoch: 2/30... Training loss: 0.1315\n",
      "Epoch: 2/30... Training loss: 0.1221\n",
      "Epoch: 2/30... Training loss: 0.1273\n",
      "Epoch: 2/30... Training loss: 0.1137\n",
      "Epoch: 2/30... Training loss: 0.1108\n",
      "Epoch: 2/30... Training loss: 0.1232\n",
      "Epoch: 2/30... Training loss: 0.1208\n",
      "Epoch: 2/30... Training loss: 0.1241\n",
      "Epoch: 2/30... Training loss: 0.1364\n",
      "Epoch: 2/30... Training loss: 0.1162\n",
      "Epoch: 2/30... Training loss: 0.1226\n",
      "Epoch: 2/30... Training loss: 0.1324\n",
      "Epoch: 2/30... Training loss: 0.1316\n",
      "Epoch: 2/30... Training loss: 0.1229\n",
      "Epoch: 2/30... Training loss: 0.1215\n",
      "Epoch: 2/30... Training loss: 0.1252\n",
      "Epoch: 2/30... Training loss: 0.1241\n",
      "Epoch: 2/30... Training loss: 0.1228\n",
      "Epoch: 2/30... Training loss: 0.1228\n",
      "Epoch: 2/30... Training loss: 0.1246\n",
      "Epoch: 2/30... Training loss: 0.1260\n",
      "Epoch: 2/30... Training loss: 0.1263\n",
      "Epoch: 2/30... Training loss: 0.1312\n",
      "Epoch: 2/30... Training loss: 0.1270\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1181\n",
      "Epoch: 2/30... Training loss: 0.1237\n",
      "Epoch: 2/30... Training loss: 0.1270\n",
      "Epoch: 2/30... Training loss: 0.1146\n",
      "Epoch: 2/30... Training loss: 0.1295\n",
      "Epoch: 2/30... Training loss: 0.1256\n",
      "Epoch: 2/30... Training loss: 0.1251\n",
      "Epoch: 2/30... Training loss: 0.1206\n",
      "Epoch: 2/30... Training loss: 0.1241\n",
      "Epoch: 2/30... Training loss: 0.1247\n",
      "Epoch: 2/30... Training loss: 0.1329\n",
      "Epoch: 2/30... Training loss: 0.1262\n",
      "Epoch: 2/30... Training loss: 0.1220\n",
      "Epoch: 2/30... Training loss: 0.1277\n",
      "Epoch: 2/30... Training loss: 0.1318\n",
      "Epoch: 2/30... Training loss: 0.1270\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1227\n",
      "Epoch: 2/30... Training loss: 0.1299\n",
      "Epoch: 2/30... Training loss: 0.1199\n",
      "Epoch: 2/30... Training loss: 0.1303\n",
      "Epoch: 2/30... Training loss: 0.1177\n",
      "Epoch: 2/30... Training loss: 0.1247\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1270\n",
      "Epoch: 2/30... Training loss: 0.1279\n",
      "Epoch: 2/30... Training loss: 0.1318\n",
      "Epoch: 2/30... Training loss: 0.1232\n",
      "Epoch: 2/30... Training loss: 0.1213\n",
      "Epoch: 2/30... Training loss: 0.1239\n",
      "Epoch: 2/30... Training loss: 0.1312\n",
      "Epoch: 2/30... Training loss: 0.1305\n",
      "Epoch: 2/30... Training loss: 0.1246\n",
      "Epoch: 2/30... Training loss: 0.1240\n",
      "Epoch: 2/30... Training loss: 0.1224\n",
      "Epoch: 2/30... Training loss: 0.1219\n",
      "Epoch: 2/30... Training loss: 0.1292\n",
      "Epoch: 2/30... Training loss: 0.1263\n",
      "Epoch: 2/30... Training loss: 0.1254\n",
      "Epoch: 2/30... Training loss: 0.1250\n",
      "Epoch: 2/30... Training loss: 0.1161\n",
      "Epoch: 2/30... Training loss: 0.1253\n",
      "Epoch: 2/30... Training loss: 0.1246\n",
      "Epoch: 2/30... Training loss: 0.1277\n",
      "Epoch: 2/30... Training loss: 0.1246\n",
      "Epoch: 2/30... Training loss: 0.1315\n",
      "Epoch: 2/30... Training loss: 0.1282\n",
      "Epoch: 2/30... Training loss: 0.1305\n",
      "Epoch: 2/30... Training loss: 0.1271\n",
      "Epoch: 2/30... Training loss: 0.1200\n",
      "Epoch: 2/30... Training loss: 0.1205\n",
      "Epoch: 2/30... Training loss: 0.1231\n",
      "Epoch: 2/30... Training loss: 0.1340\n",
      "Epoch: 2/30... Training loss: 0.1239\n",
      "Epoch: 2/30... Training loss: 0.1220\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1256\n",
      "Epoch: 2/30... Training loss: 0.1182\n",
      "Epoch: 2/30... Training loss: 0.1182\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1194\n",
      "Epoch: 2/30... Training loss: 0.1196\n",
      "Epoch: 2/30... Training loss: 0.1197\n",
      "Epoch: 2/30... Training loss: 0.1161\n",
      "Epoch: 2/30... Training loss: 0.1224\n",
      "Epoch: 2/30... Training loss: 0.1133\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1300\n",
      "Epoch: 2/30... Training loss: 0.1172\n",
      "Epoch: 2/30... Training loss: 0.1234\n",
      "Epoch: 2/30... Training loss: 0.1185\n",
      "Epoch: 2/30... Training loss: 0.1263\n",
      "Epoch: 2/30... Training loss: 0.1122\n",
      "Epoch: 2/30... Training loss: 0.1177\n",
      "Epoch: 2/30... Training loss: 0.1213\n",
      "Epoch: 2/30... Training loss: 0.1210\n",
      "Epoch: 2/30... Training loss: 0.1186\n",
      "Epoch: 2/30... Training loss: 0.1132\n",
      "Epoch: 2/30... Training loss: 0.1202\n",
      "Epoch: 2/30... Training loss: 0.1223\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1198\n",
      "Epoch: 2/30... Training loss: 0.1170\n",
      "Epoch: 2/30... Training loss: 0.1265\n",
      "Epoch: 2/30... Training loss: 0.1272\n",
      "Epoch: 2/30... Training loss: 0.1268\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1262\n",
      "Epoch: 2/30... Training loss: 0.1162\n",
      "Epoch: 2/30... Training loss: 0.1260\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1188\n",
      "Epoch: 2/30... Training loss: 0.1224\n",
      "Epoch: 2/30... Training loss: 0.1171\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1219\n",
      "Epoch: 2/30... Training loss: 0.1199\n",
      "Epoch: 2/30... Training loss: 0.1208\n",
      "Epoch: 2/30... Training loss: 0.1325\n",
      "Epoch: 2/30... Training loss: 0.1227\n",
      "Epoch: 2/30... Training loss: 0.1182\n",
      "Epoch: 2/30... Training loss: 0.1212\n",
      "Epoch: 2/30... Training loss: 0.1190\n",
      "Epoch: 2/30... Training loss: 0.1189\n",
      "Epoch: 2/30... Training loss: 0.1235\n",
      "Epoch: 2/30... Training loss: 0.1155\n",
      "Epoch: 2/30... Training loss: 0.1142\n",
      "Epoch: 2/30... Training loss: 0.1230\n",
      "Epoch: 2/30... Training loss: 0.1287\n",
      "Epoch: 2/30... Training loss: 0.1329\n",
      "Epoch: 2/30... Training loss: 0.1169\n",
      "Epoch: 2/30... Training loss: 0.1186\n",
      "Epoch: 2/30... Training loss: 0.1154\n",
      "Epoch: 2/30... Training loss: 0.1279\n",
      "Epoch: 2/30... Training loss: 0.1267\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1114\n",
      "Epoch: 2/30... Training loss: 0.1186\n",
      "Epoch: 2/30... Training loss: 0.1213\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1190\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1234\n",
      "Epoch: 2/30... Training loss: 0.1194\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1288\n",
      "Epoch: 2/30... Training loss: 0.1253\n",
      "Epoch: 2/30... Training loss: 0.1203\n",
      "Epoch: 2/30... Training loss: 0.1335\n",
      "Epoch: 2/30... Training loss: 0.1245\n",
      "Epoch: 2/30... Training loss: 0.1377\n",
      "Epoch: 2/30... Training loss: 0.1223\n",
      "Epoch: 2/30... Training loss: 0.1291\n",
      "Epoch: 2/30... Training loss: 0.1126\n",
      "Epoch: 2/30... Training loss: 0.1168\n",
      "Epoch: 2/30... Training loss: 0.1138\n",
      "Epoch: 2/30... Training loss: 0.1199\n",
      "Epoch: 2/30... Training loss: 0.1224\n",
      "Epoch: 2/30... Training loss: 0.1216\n",
      "Epoch: 2/30... Training loss: 0.1208\n",
      "Epoch: 2/30... Training loss: 0.1222\n",
      "Epoch: 2/30... Training loss: 0.1151\n",
      "Epoch: 2/30... Training loss: 0.1228\n",
      "Epoch: 2/30... Training loss: 0.1188\n",
      "Epoch: 2/30... Training loss: 0.1213\n",
      "Epoch: 2/30... Training loss: 0.1255\n",
      "Epoch: 2/30... Training loss: 0.1169\n",
      "Epoch: 2/30... Training loss: 0.1250\n",
      "Epoch: 2/30... Training loss: 0.1271\n",
      "Epoch: 2/30... Training loss: 0.1282\n",
      "Epoch: 2/30... Training loss: 0.1198\n",
      "Epoch: 2/30... Training loss: 0.1244\n",
      "Epoch: 2/30... Training loss: 0.1248\n",
      "Epoch: 2/30... Training loss: 0.1200\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1199\n",
      "Epoch: 2/30... Training loss: 0.1254\n",
      "Epoch: 2/30... Training loss: 0.1128\n",
      "Epoch: 2/30... Training loss: 0.1247\n",
      "Epoch: 2/30... Training loss: 0.1155\n",
      "Epoch: 2/30... Training loss: 0.1188\n",
      "Epoch: 2/30... Training loss: 0.1273\n",
      "Epoch: 2/30... Training loss: 0.1237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/30... Training loss: 0.1173\n",
      "Epoch: 2/30... Training loss: 0.1222\n",
      "Epoch: 2/30... Training loss: 0.1202\n",
      "Epoch: 2/30... Training loss: 0.1103\n",
      "Epoch: 2/30... Training loss: 0.1147\n",
      "Epoch: 2/30... Training loss: 0.1172\n",
      "Epoch: 2/30... Training loss: 0.1257\n",
      "Epoch: 2/30... Training loss: 0.1189\n",
      "Epoch: 2/30... Training loss: 0.1201\n",
      "Epoch: 2/30... Training loss: 0.1141\n",
      "Epoch: 2/30... Training loss: 0.1187\n",
      "Epoch: 2/30... Training loss: 0.1184\n",
      "Epoch: 2/30... Training loss: 0.1124\n",
      "Epoch: 2/30... Training loss: 0.1278\n",
      "Epoch: 2/30... Training loss: 0.1155\n",
      "Epoch: 2/30... Training loss: 0.1241\n",
      "Epoch: 2/30... Training loss: 0.1231\n",
      "Epoch: 2/30... Training loss: 0.1225\n",
      "Epoch: 2/30... Training loss: 0.1162\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1146\n",
      "Epoch: 2/30... Training loss: 0.1236\n",
      "Epoch: 2/30... Training loss: 0.1172\n",
      "Epoch: 2/30... Training loss: 0.1138\n",
      "Epoch: 2/30... Training loss: 0.1242\n",
      "Epoch: 2/30... Training loss: 0.1103\n",
      "Epoch: 2/30... Training loss: 0.1172\n",
      "Epoch: 2/30... Training loss: 0.1122\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1208\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1228\n",
      "Epoch: 2/30... Training loss: 0.1117\n",
      "Epoch: 2/30... Training loss: 0.1172\n",
      "Epoch: 2/30... Training loss: 0.1161\n",
      "Epoch: 2/30... Training loss: 0.1170\n",
      "Epoch: 2/30... Training loss: 0.1112\n",
      "Epoch: 2/30... Training loss: 0.1191\n",
      "Epoch: 2/30... Training loss: 0.1144\n",
      "Epoch: 2/30... Training loss: 0.1286\n",
      "Epoch: 2/30... Training loss: 0.1251\n",
      "Epoch: 2/30... Training loss: 0.1133\n",
      "Epoch: 2/30... Training loss: 0.1155\n",
      "Epoch: 2/30... Training loss: 0.1137\n",
      "Epoch: 2/30... Training loss: 0.1202\n",
      "Epoch: 2/30... Training loss: 0.1138\n",
      "Epoch: 2/30... Training loss: 0.1230\n",
      "Epoch: 2/30... Training loss: 0.1234\n",
      "Epoch: 2/30... Training loss: 0.1176\n",
      "Epoch: 2/30... Training loss: 0.1245\n",
      "Epoch: 2/30... Training loss: 0.1171\n",
      "Epoch: 2/30... Training loss: 0.1168\n",
      "Epoch: 2/30... Training loss: 0.1065\n",
      "Epoch: 2/30... Training loss: 0.1119\n",
      "Epoch: 2/30... Training loss: 0.1233\n",
      "Epoch: 2/30... Training loss: 0.1155\n",
      "Epoch: 2/30... Training loss: 0.1191\n",
      "Epoch: 2/30... Training loss: 0.1158\n",
      "Epoch: 2/30... Training loss: 0.1184\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1191\n",
      "Epoch: 2/30... Training loss: 0.1205\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1271\n",
      "Epoch: 2/30... Training loss: 0.1211\n",
      "Epoch: 2/30... Training loss: 0.1179\n",
      "Epoch: 2/30... Training loss: 0.1141\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1221\n",
      "Epoch: 2/30... Training loss: 0.1256\n",
      "Epoch: 2/30... Training loss: 0.1195\n",
      "Epoch: 2/30... Training loss: 0.1198\n",
      "Epoch: 2/30... Training loss: 0.1109\n",
      "Epoch: 2/30... Training loss: 0.1187\n",
      "Epoch: 2/30... Training loss: 0.1181\n",
      "Epoch: 2/30... Training loss: 0.1265\n",
      "Epoch: 2/30... Training loss: 0.1265\n",
      "Epoch: 2/30... Training loss: 0.1099\n",
      "Epoch: 2/30... Training loss: 0.1164\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1161\n",
      "Epoch: 2/30... Training loss: 0.1149\n",
      "Epoch: 2/30... Training loss: 0.1131\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1186\n",
      "Epoch: 2/30... Training loss: 0.1175\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1217\n",
      "Epoch: 2/30... Training loss: 0.1174\n",
      "Epoch: 2/30... Training loss: 0.1209\n",
      "Epoch: 2/30... Training loss: 0.1187\n",
      "Epoch: 2/30... Training loss: 0.1113\n",
      "Epoch: 2/30... Training loss: 0.1077\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1216\n",
      "Epoch: 2/30... Training loss: 0.1171\n",
      "Epoch: 2/30... Training loss: 0.1153\n",
      "Epoch: 2/30... Training loss: 0.1204\n",
      "Epoch: 2/30... Training loss: 0.1206\n",
      "Epoch: 2/30... Training loss: 0.1232\n",
      "Epoch: 2/30... Training loss: 0.1170\n",
      "Epoch: 2/30... Training loss: 0.1153\n",
      "Epoch: 2/30... Training loss: 0.1195\n",
      "Epoch: 2/30... Training loss: 0.1210\n",
      "Epoch: 2/30... Training loss: 0.1162\n",
      "Epoch: 2/30... Training loss: 0.1226\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.1183\n",
      "Epoch: 2/30... Training loss: 0.1118\n",
      "Epoch: 2/30... Training loss: 0.1142\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1242\n",
      "Epoch: 2/30... Training loss: 0.1116\n",
      "Epoch: 2/30... Training loss: 0.1207\n",
      "Epoch: 2/30... Training loss: 0.1178\n",
      "Epoch: 2/30... Training loss: 0.1196\n",
      "Epoch: 2/30... Training loss: 0.1104\n",
      "Epoch: 2/30... Training loss: 0.1101\n",
      "Epoch: 2/30... Training loss: 0.1129\n",
      "Epoch: 2/30... Training loss: 0.1190\n",
      "Epoch: 2/30... Training loss: 0.1152\n",
      "Epoch: 2/30... Training loss: 0.1126\n",
      "Epoch: 2/30... Training loss: 0.1102\n",
      "Epoch: 2/30... Training loss: 0.1230\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1129\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1166\n",
      "Epoch: 2/30... Training loss: 0.1187\n",
      "Epoch: 2/30... Training loss: 0.1212\n",
      "Epoch: 2/30... Training loss: 0.1209\n",
      "Epoch: 2/30... Training loss: 0.1192\n",
      "Epoch: 2/30... Training loss: 0.1175\n",
      "Epoch: 2/30... Training loss: 0.1209\n",
      "Epoch: 2/30... Training loss: 0.1136\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1137\n",
      "Epoch: 2/30... Training loss: 0.1086\n",
      "Epoch: 2/30... Training loss: 0.1226\n",
      "Epoch: 2/30... Training loss: 0.1150\n",
      "Epoch: 2/30... Training loss: 0.1183\n",
      "Epoch: 2/30... Training loss: 0.1171\n",
      "Epoch: 2/30... Training loss: 0.1132\n",
      "Epoch: 2/30... Training loss: 0.1227\n",
      "Epoch: 2/30... Training loss: 0.1136\n",
      "Epoch: 2/30... Training loss: 0.1191\n",
      "Epoch: 2/30... Training loss: 0.1139\n",
      "Epoch: 2/30... Training loss: 0.1159\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1095\n",
      "Epoch: 2/30... Training loss: 0.1085\n",
      "Epoch: 2/30... Training loss: 0.1170\n",
      "Epoch: 2/30... Training loss: 0.1182\n",
      "Epoch: 2/30... Training loss: 0.1093\n",
      "Epoch: 2/30... Training loss: 0.1135\n",
      "Epoch: 2/30... Training loss: 0.1178\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1169\n",
      "Epoch: 2/30... Training loss: 0.1196\n",
      "Epoch: 2/30... Training loss: 0.1212\n",
      "Epoch: 2/30... Training loss: 0.1154\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1185\n",
      "Epoch: 2/30... Training loss: 0.1159\n",
      "Epoch: 2/30... Training loss: 0.1194\n",
      "Epoch: 2/30... Training loss: 0.1176\n",
      "Epoch: 2/30... Training loss: 0.1119\n",
      "Epoch: 2/30... Training loss: 0.1133\n",
      "Epoch: 2/30... Training loss: 0.1123\n",
      "Epoch: 2/30... Training loss: 0.1213\n",
      "Epoch: 2/30... Training loss: 0.1073\n",
      "Epoch: 2/30... Training loss: 0.1211\n",
      "Epoch: 2/30... Training loss: 0.1152\n",
      "Epoch: 2/30... Training loss: 0.1104\n",
      "Epoch: 2/30... Training loss: 0.1161\n",
      "Epoch: 2/30... Training loss: 0.1197\n",
      "Epoch: 2/30... Training loss: 0.1219\n",
      "Epoch: 2/30... Training loss: 0.1154\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.1161\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1168\n",
      "Epoch: 2/30... Training loss: 0.1151\n",
      "Epoch: 2/30... Training loss: 0.1102\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1160\n",
      "Epoch: 2/30... Training loss: 0.1118\n",
      "Epoch: 2/30... Training loss: 0.1190\n",
      "Epoch: 2/30... Training loss: 0.1162\n",
      "Epoch: 2/30... Training loss: 0.1068\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1235\n",
      "Epoch: 2/30... Training loss: 0.1110\n",
      "Epoch: 2/30... Training loss: 0.1061\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1128\n",
      "Epoch: 2/30... Training loss: 0.1166\n",
      "Epoch: 2/30... Training loss: 0.1213\n",
      "Epoch: 2/30... Training loss: 0.1016\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1111\n",
      "Epoch: 2/30... Training loss: 0.1131\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1144\n",
      "Epoch: 2/30... Training loss: 0.1053\n",
      "Epoch: 2/30... Training loss: 0.1212\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1239\n",
      "Epoch: 2/30... Training loss: 0.1116\n",
      "Epoch: 2/30... Training loss: 0.1114\n",
      "Epoch: 2/30... Training loss: 0.1139\n",
      "Epoch: 2/30... Training loss: 0.1153\n",
      "Epoch: 2/30... Training loss: 0.1106\n",
      "Epoch: 2/30... Training loss: 0.1135\n",
      "Epoch: 2/30... Training loss: 0.1133\n",
      "Epoch: 2/30... Training loss: 0.1071\n",
      "Epoch: 2/30... Training loss: 0.1137\n",
      "Epoch: 2/30... Training loss: 0.1087\n",
      "Epoch: 2/30... Training loss: 0.1156\n",
      "Epoch: 2/30... Training loss: 0.1191\n",
      "Epoch: 2/30... Training loss: 0.1158\n",
      "Epoch: 2/30... Training loss: 0.1112\n",
      "Epoch: 2/30... Training loss: 0.1206\n",
      "Epoch: 2/30... Training loss: 0.1114\n",
      "Epoch: 2/30... Training loss: 0.1128\n",
      "Epoch: 2/30... Training loss: 0.1194\n",
      "Epoch: 2/30... Training loss: 0.1147\n",
      "Epoch: 2/30... Training loss: 0.1066\n",
      "Epoch: 2/30... Training loss: 0.1126\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.1122\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.1141\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1094\n",
      "Epoch: 2/30... Training loss: 0.1121\n",
      "Epoch: 2/30... Training loss: 0.1193\n",
      "Epoch: 2/30... Training loss: 0.1260\n",
      "Epoch: 2/30... Training loss: 0.1103\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1185\n",
      "Epoch: 2/30... Training loss: 0.1095\n",
      "Epoch: 2/30... Training loss: 0.1133\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1169\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.1162\n",
      "Epoch: 2/30... Training loss: 0.1124\n",
      "Epoch: 2/30... Training loss: 0.1189\n",
      "Epoch: 2/30... Training loss: 0.1110\n",
      "Epoch: 2/30... Training loss: 0.1240\n",
      "Epoch: 2/30... Training loss: 0.1109\n",
      "Epoch: 2/30... Training loss: 0.1121\n",
      "Epoch: 2/30... Training loss: 0.1077\n",
      "Epoch: 2/30... Training loss: 0.1188\n",
      "Epoch: 2/30... Training loss: 0.1048\n",
      "Epoch: 2/30... Training loss: 0.1187\n",
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.1101\n",
      "Epoch: 2/30... Training loss: 0.1138\n",
      "Epoch: 2/30... Training loss: 0.1158\n",
      "Epoch: 2/30... Training loss: 0.1098\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.1072\n",
      "Epoch: 2/30... Training loss: 0.1121\n",
      "Epoch: 2/30... Training loss: 0.1052\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1121\n",
      "Epoch: 2/30... Training loss: 0.1094\n",
      "Epoch: 2/30... Training loss: 0.1138\n",
      "Epoch: 2/30... Training loss: 0.1136\n",
      "Epoch: 2/30... Training loss: 0.1106\n",
      "Epoch: 2/30... Training loss: 0.1181\n",
      "Epoch: 2/30... Training loss: 0.1098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/30... Training loss: 0.1153\n",
      "Epoch: 2/30... Training loss: 0.1055\n",
      "Epoch: 2/30... Training loss: 0.1055\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1167\n",
      "Epoch: 2/30... Training loss: 0.1152\n",
      "Epoch: 2/30... Training loss: 0.1096\n",
      "Epoch: 2/30... Training loss: 0.1112\n",
      "Epoch: 2/30... Training loss: 0.1121\n",
      "Epoch: 2/30... Training loss: 0.1155\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1078\n",
      "Epoch: 2/30... Training loss: 0.1230\n",
      "Epoch: 2/30... Training loss: 0.1111\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1143\n",
      "Epoch: 2/30... Training loss: 0.1124\n",
      "Epoch: 2/30... Training loss: 0.1192\n",
      "Epoch: 2/30... Training loss: 0.1090\n",
      "Epoch: 2/30... Training loss: 0.1116\n",
      "Epoch: 2/30... Training loss: 0.1174\n",
      "Epoch: 2/30... Training loss: 0.1153\n",
      "Epoch: 2/30... Training loss: 0.1136\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1152\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1146\n",
      "Epoch: 2/30... Training loss: 0.1239\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1061\n",
      "Epoch: 2/30... Training loss: 0.1188\n",
      "Epoch: 2/30... Training loss: 0.1070\n",
      "Epoch: 2/30... Training loss: 0.1049\n",
      "Epoch: 2/30... Training loss: 0.1129\n",
      "Epoch: 2/30... Training loss: 0.1172\n",
      "Epoch: 2/30... Training loss: 0.1078\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1187\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1146\n",
      "Epoch: 2/30... Training loss: 0.1118\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1116\n",
      "Epoch: 2/30... Training loss: 0.1148\n",
      "Epoch: 2/30... Training loss: 0.1154\n",
      "Epoch: 2/30... Training loss: 0.1063\n",
      "Epoch: 2/30... Training loss: 0.1139\n",
      "Epoch: 2/30... Training loss: 0.1163\n",
      "Epoch: 2/30... Training loss: 0.1101\n",
      "Epoch: 2/30... Training loss: 0.1117\n",
      "Epoch: 2/30... Training loss: 0.1151\n",
      "Epoch: 2/30... Training loss: 0.1069\n",
      "Epoch: 2/30... Training loss: 0.1133\n",
      "Epoch: 2/30... Training loss: 0.1186\n",
      "Epoch: 2/30... Training loss: 0.1124\n",
      "Epoch: 2/30... Training loss: 0.1100\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.1061\n",
      "Epoch: 2/30... Training loss: 0.1126\n",
      "Epoch: 2/30... Training loss: 0.1102\n",
      "Epoch: 2/30... Training loss: 0.1106\n",
      "Epoch: 2/30... Training loss: 0.1141\n",
      "Epoch: 2/30... Training loss: 0.1012\n",
      "Epoch: 2/30... Training loss: 0.1106\n",
      "Epoch: 2/30... Training loss: 0.1108\n",
      "Epoch: 2/30... Training loss: 0.1146\n",
      "Epoch: 2/30... Training loss: 0.1077\n",
      "Epoch: 2/30... Training loss: 0.1099\n",
      "Epoch: 2/30... Training loss: 0.1115\n",
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.1123\n",
      "Epoch: 2/30... Training loss: 0.1057\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1156\n",
      "Epoch: 2/30... Training loss: 0.1137\n",
      "Epoch: 2/30... Training loss: 0.1052\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1129\n",
      "Epoch: 2/30... Training loss: 0.1099\n",
      "Epoch: 2/30... Training loss: 0.1124\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1155\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1145\n",
      "Epoch: 2/30... Training loss: 0.1111\n",
      "Epoch: 2/30... Training loss: 0.1091\n",
      "Epoch: 2/30... Training loss: 0.1118\n",
      "Epoch: 2/30... Training loss: 0.1114\n",
      "Epoch: 2/30... Training loss: 0.1034\n",
      "Epoch: 2/30... Training loss: 0.1152\n",
      "Epoch: 2/30... Training loss: 0.1133\n",
      "Epoch: 2/30... Training loss: 0.1137\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1071\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1078\n",
      "Epoch: 2/30... Training loss: 0.1063\n",
      "Epoch: 2/30... Training loss: 0.1149\n",
      "Epoch: 2/30... Training loss: 0.1118\n",
      "Epoch: 2/30... Training loss: 0.1085\n",
      "Epoch: 2/30... Training loss: 0.1118\n",
      "Epoch: 2/30... Training loss: 0.1074\n",
      "Epoch: 2/30... Training loss: 0.1042\n",
      "Epoch: 2/30... Training loss: 0.1087\n",
      "Epoch: 2/30... Training loss: 0.1066\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1115\n",
      "Epoch: 2/30... Training loss: 0.1117\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1173\n",
      "Epoch: 2/30... Training loss: 0.1075\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.1138\n",
      "Epoch: 2/30... Training loss: 0.1126\n",
      "Epoch: 2/30... Training loss: 0.1187\n",
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.1140\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.1090\n",
      "Epoch: 2/30... Training loss: 0.1121\n",
      "Epoch: 2/30... Training loss: 0.1101\n",
      "Epoch: 2/30... Training loss: 0.1155\n",
      "Epoch: 2/30... Training loss: 0.1135\n",
      "Epoch: 2/30... Training loss: 0.1065\n",
      "Epoch: 2/30... Training loss: 0.1048\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.1060\n",
      "Epoch: 2/30... Training loss: 0.1095\n",
      "Epoch: 2/30... Training loss: 0.1067\n",
      "Epoch: 2/30... Training loss: 0.1103\n",
      "Epoch: 2/30... Training loss: 0.1057\n",
      "Epoch: 2/30... Training loss: 0.1117\n",
      "Epoch: 2/30... Training loss: 0.1144\n",
      "Epoch: 2/30... Training loss: 0.1153\n",
      "Epoch: 2/30... Training loss: 0.1093\n",
      "Epoch: 2/30... Training loss: 0.1159\n",
      "Epoch: 2/30... Training loss: 0.1073\n",
      "Epoch: 2/30... Training loss: 0.1098\n",
      "Epoch: 2/30... Training loss: 0.1062\n",
      "Epoch: 2/30... Training loss: 0.1112\n",
      "Epoch: 2/30... Training loss: 0.1141\n",
      "Epoch: 2/30... Training loss: 0.1133\n",
      "Epoch: 2/30... Training loss: 0.0986\n",
      "Epoch: 2/30... Training loss: 0.1100\n",
      "Epoch: 2/30... Training loss: 0.1092\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1109\n",
      "Epoch: 2/30... Training loss: 0.1096\n",
      "Epoch: 2/30... Training loss: 0.1033\n",
      "Epoch: 2/30... Training loss: 0.1071\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.1057\n",
      "Epoch: 2/30... Training loss: 0.1064\n",
      "Epoch: 2/30... Training loss: 0.1001\n",
      "Epoch: 2/30... Training loss: 0.0994\n",
      "Epoch: 2/30... Training loss: 0.1076\n",
      "Epoch: 2/30... Training loss: 0.1122\n",
      "Epoch: 2/30... Training loss: 0.1144\n",
      "Epoch: 2/30... Training loss: 0.1002\n",
      "Epoch: 2/30... Training loss: 0.1094\n",
      "Epoch: 2/30... Training loss: 0.1136\n",
      "Epoch: 2/30... Training loss: 0.1094\n",
      "Epoch: 2/30... Training loss: 0.1035\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1096\n",
      "Epoch: 2/30... Training loss: 0.1050\n",
      "Epoch: 2/30... Training loss: 0.1116\n",
      "Epoch: 2/30... Training loss: 0.1056\n",
      "Epoch: 2/30... Training loss: 0.1094\n",
      "Epoch: 2/30... Training loss: 0.1114\n",
      "Epoch: 2/30... Training loss: 0.1118\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1106\n",
      "Epoch: 2/30... Training loss: 0.1104\n",
      "Epoch: 2/30... Training loss: 0.1094\n",
      "Epoch: 2/30... Training loss: 0.1111\n",
      "Epoch: 2/30... Training loss: 0.1118\n",
      "Epoch: 2/30... Training loss: 0.1022\n",
      "Epoch: 2/30... Training loss: 0.1068\n",
      "Epoch: 2/30... Training loss: 0.1065\n",
      "Epoch: 2/30... Training loss: 0.1025\n",
      "Epoch: 2/30... Training loss: 0.1082\n",
      "Epoch: 2/30... Training loss: 0.1069\n",
      "Epoch: 2/30... Training loss: 0.1151\n",
      "Epoch: 2/30... Training loss: 0.1095\n",
      "Epoch: 2/30... Training loss: 0.1142\n",
      "Epoch: 2/30... Training loss: 0.1092\n",
      "Epoch: 2/30... Training loss: 0.1092\n",
      "Epoch: 2/30... Training loss: 0.1120\n",
      "Epoch: 2/30... Training loss: 0.1131\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1060\n",
      "Epoch: 2/30... Training loss: 0.1073\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1070\n",
      "Epoch: 2/30... Training loss: 0.1047\n",
      "Epoch: 2/30... Training loss: 0.1131\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.1038\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.1045\n",
      "Epoch: 2/30... Training loss: 0.1146\n",
      "Epoch: 2/30... Training loss: 0.1124\n",
      "Epoch: 2/30... Training loss: 0.1100\n",
      "Epoch: 2/30... Training loss: 0.1098\n",
      "Epoch: 2/30... Training loss: 0.1019\n",
      "Epoch: 2/30... Training loss: 0.1035\n",
      "Epoch: 2/30... Training loss: 0.1127\n",
      "Epoch: 2/30... Training loss: 0.1108\n",
      "Epoch: 2/30... Training loss: 0.1012\n",
      "Epoch: 2/30... Training loss: 0.1034\n",
      "Epoch: 2/30... Training loss: 0.1064\n",
      "Epoch: 2/30... Training loss: 0.1062\n",
      "Epoch: 2/30... Training loss: 0.1010\n",
      "Epoch: 2/30... Training loss: 0.1022\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.1094\n",
      "Epoch: 2/30... Training loss: 0.1090\n",
      "Epoch: 2/30... Training loss: 0.1149\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1042\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.1078\n",
      "Epoch: 2/30... Training loss: 0.1034\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1133\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.1056\n",
      "Epoch: 2/30... Training loss: 0.1082\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.0967\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.1065\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.1173\n",
      "Epoch: 2/30... Training loss: 0.1090\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.1128\n",
      "Epoch: 2/30... Training loss: 0.1035\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1065\n",
      "Epoch: 2/30... Training loss: 0.1063\n",
      "Epoch: 2/30... Training loss: 0.1061\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.0995\n",
      "Epoch: 2/30... Training loss: 0.1113\n",
      "Epoch: 2/30... Training loss: 0.1122\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1062\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1069\n",
      "Epoch: 2/30... Training loss: 0.1165\n",
      "Epoch: 2/30... Training loss: 0.1092\n",
      "Epoch: 2/30... Training loss: 0.1040\n",
      "Epoch: 2/30... Training loss: 0.0967\n",
      "Epoch: 2/30... Training loss: 0.0962\n",
      "Epoch: 2/30... Training loss: 0.1012\n",
      "Epoch: 2/30... Training loss: 0.1083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/30... Training loss: 0.1092\n",
      "Epoch: 2/30... Training loss: 0.1149\n",
      "Epoch: 2/30... Training loss: 0.1022\n",
      "Epoch: 2/30... Training loss: 0.1098\n",
      "Epoch: 2/30... Training loss: 0.1079\n",
      "Epoch: 2/30... Training loss: 0.1100\n",
      "Epoch: 2/30... Training loss: 0.1077\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1067\n",
      "Epoch: 2/30... Training loss: 0.1056\n",
      "Epoch: 2/30... Training loss: 0.1022\n",
      "Epoch: 2/30... Training loss: 0.1020\n",
      "Epoch: 2/30... Training loss: 0.1086\n",
      "Epoch: 2/30... Training loss: 0.1044\n",
      "Epoch: 2/30... Training loss: 0.1065\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.1078\n",
      "Epoch: 2/30... Training loss: 0.1016\n",
      "Epoch: 2/30... Training loss: 0.1095\n",
      "Epoch: 2/30... Training loss: 0.1143\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1035\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1001\n",
      "Epoch: 2/30... Training loss: 0.1000\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.1111\n",
      "Epoch: 2/30... Training loss: 0.1035\n",
      "Epoch: 2/30... Training loss: 0.1033\n",
      "Epoch: 2/30... Training loss: 0.1130\n",
      "Epoch: 2/30... Training loss: 0.0988\n",
      "Epoch: 2/30... Training loss: 0.1021\n",
      "Epoch: 2/30... Training loss: 0.0909\n",
      "Epoch: 2/30... Training loss: 0.1041\n",
      "Epoch: 2/30... Training loss: 0.1042\n",
      "Epoch: 2/30... Training loss: 0.1078\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.1024\n",
      "Epoch: 2/30... Training loss: 0.1024\n",
      "Epoch: 2/30... Training loss: 0.0977\n",
      "Epoch: 2/30... Training loss: 0.1134\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1044\n",
      "Epoch: 2/30... Training loss: 0.1067\n",
      "Epoch: 2/30... Training loss: 0.1113\n",
      "Epoch: 2/30... Training loss: 0.1073\n",
      "Epoch: 2/30... Training loss: 0.1061\n",
      "Epoch: 2/30... Training loss: 0.1010\n",
      "Epoch: 2/30... Training loss: 0.1070\n",
      "Epoch: 2/30... Training loss: 0.1045\n",
      "Epoch: 2/30... Training loss: 0.1048\n",
      "Epoch: 2/30... Training loss: 0.1033\n",
      "Epoch: 2/30... Training loss: 0.1003\n",
      "Epoch: 2/30... Training loss: 0.1004\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.1021\n",
      "Epoch: 2/30... Training loss: 0.1056\n",
      "Epoch: 2/30... Training loss: 0.1062\n",
      "Epoch: 2/30... Training loss: 0.1110\n",
      "Epoch: 2/30... Training loss: 0.1114\n",
      "Epoch: 2/30... Training loss: 0.0994\n",
      "Epoch: 2/30... Training loss: 0.1113\n",
      "Epoch: 2/30... Training loss: 0.1019\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1037\n",
      "Epoch: 2/30... Training loss: 0.1003\n",
      "Epoch: 2/30... Training loss: 0.1060\n",
      "Epoch: 2/30... Training loss: 0.0997\n",
      "Epoch: 2/30... Training loss: 0.1047\n",
      "Epoch: 2/30... Training loss: 0.1000\n",
      "Epoch: 2/30... Training loss: 0.1071\n",
      "Epoch: 2/30... Training loss: 0.1105\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.1024\n",
      "Epoch: 2/30... Training loss: 0.1064\n",
      "Epoch: 2/30... Training loss: 0.1070\n",
      "Epoch: 2/30... Training loss: 0.1074\n",
      "Epoch: 2/30... Training loss: 0.1005\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.1082\n",
      "Epoch: 2/30... Training loss: 0.1098\n",
      "Epoch: 2/30... Training loss: 0.0987\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.1019\n",
      "Epoch: 2/30... Training loss: 0.1011\n",
      "Epoch: 2/30... Training loss: 0.1065\n",
      "Epoch: 2/30... Training loss: 0.1099\n",
      "Epoch: 2/30... Training loss: 0.1127\n",
      "Epoch: 2/30... Training loss: 0.1074\n",
      "Epoch: 2/30... Training loss: 0.1067\n",
      "Epoch: 2/30... Training loss: 0.0949\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.0991\n",
      "Epoch: 2/30... Training loss: 0.1067\n",
      "Epoch: 2/30... Training loss: 0.1036\n",
      "Epoch: 2/30... Training loss: 0.1041\n",
      "Epoch: 2/30... Training loss: 0.1035\n",
      "Epoch: 2/30... Training loss: 0.1021\n",
      "Epoch: 2/30... Training loss: 0.1008\n",
      "Epoch: 2/30... Training loss: 0.0982\n",
      "Epoch: 2/30... Training loss: 0.1062\n",
      "Epoch: 2/30... Training loss: 0.1018\n",
      "Epoch: 2/30... Training loss: 0.0995\n",
      "Epoch: 2/30... Training loss: 0.1045\n",
      "Epoch: 2/30... Training loss: 0.1020\n",
      "Epoch: 2/30... Training loss: 0.1096\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.1125\n",
      "Epoch: 2/30... Training loss: 0.1057\n",
      "Epoch: 2/30... Training loss: 0.1068\n",
      "Epoch: 2/30... Training loss: 0.1063\n",
      "Epoch: 2/30... Training loss: 0.1087\n",
      "Epoch: 2/30... Training loss: 0.1011\n",
      "Epoch: 2/30... Training loss: 0.0983\n",
      "Epoch: 2/30... Training loss: 0.0996\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1036\n",
      "Epoch: 2/30... Training loss: 0.0975\n",
      "Epoch: 2/30... Training loss: 0.1139\n",
      "Epoch: 2/30... Training loss: 0.0964\n",
      "Epoch: 2/30... Training loss: 0.1102\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.1093\n",
      "Epoch: 2/30... Training loss: 0.1053\n",
      "Epoch: 2/30... Training loss: 0.1040\n",
      "Epoch: 2/30... Training loss: 0.1026\n",
      "Epoch: 2/30... Training loss: 0.1005\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.1012\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1103\n",
      "Epoch: 2/30... Training loss: 0.0970\n",
      "Epoch: 2/30... Training loss: 0.1002\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.1021\n",
      "Epoch: 2/30... Training loss: 0.1065\n",
      "Epoch: 2/30... Training loss: 0.1017\n",
      "Epoch: 2/30... Training loss: 0.0998\n",
      "Epoch: 2/30... Training loss: 0.0998\n",
      "Epoch: 2/30... Training loss: 0.0944\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.1004\n",
      "Epoch: 2/30... Training loss: 0.0926\n",
      "Epoch: 2/30... Training loss: 0.0974\n",
      "Epoch: 2/30... Training loss: 0.1069\n",
      "Epoch: 2/30... Training loss: 0.0990\n",
      "Epoch: 2/30... Training loss: 0.1070\n",
      "Epoch: 2/30... Training loss: 0.1075\n",
      "Epoch: 2/30... Training loss: 0.1088\n",
      "Epoch: 2/30... Training loss: 0.0992\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1023\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.1055\n",
      "Epoch: 2/30... Training loss: 0.1057\n",
      "Epoch: 2/30... Training loss: 0.1041\n",
      "Epoch: 2/30... Training loss: 0.0981\n",
      "Epoch: 2/30... Training loss: 0.1035\n",
      "Epoch: 2/30... Training loss: 0.0974\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.0978\n",
      "Epoch: 2/30... Training loss: 0.1135\n",
      "Epoch: 2/30... Training loss: 0.1055\n",
      "Epoch: 2/30... Training loss: 0.0972\n",
      "Epoch: 2/30... Training loss: 0.1080\n",
      "Epoch: 2/30... Training loss: 0.0973\n",
      "Epoch: 2/30... Training loss: 0.1011\n",
      "Epoch: 2/30... Training loss: 0.1073\n",
      "Epoch: 2/30... Training loss: 0.0978\n",
      "Epoch: 2/30... Training loss: 0.1086\n",
      "Epoch: 2/30... Training loss: 0.1087\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1069\n",
      "Epoch: 2/30... Training loss: 0.1005\n",
      "Epoch: 2/30... Training loss: 0.1052\n",
      "Epoch: 2/30... Training loss: 0.0961\n",
      "Epoch: 2/30... Training loss: 0.0949\n",
      "Epoch: 2/30... Training loss: 0.0971\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.1034\n",
      "Epoch: 2/30... Training loss: 0.0994\n",
      "Epoch: 2/30... Training loss: 0.0937\n",
      "Epoch: 2/30... Training loss: 0.1008\n",
      "Epoch: 2/30... Training loss: 0.1067\n",
      "Epoch: 2/30... Training loss: 0.0971\n",
      "Epoch: 2/30... Training loss: 0.1049\n",
      "Epoch: 2/30... Training loss: 0.1083\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.0914\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.0975\n",
      "Epoch: 2/30... Training loss: 0.1071\n",
      "Epoch: 2/30... Training loss: 0.1086\n",
      "Epoch: 2/30... Training loss: 0.0930\n",
      "Epoch: 2/30... Training loss: 0.0955\n",
      "Epoch: 2/30... Training loss: 0.1065\n",
      "Epoch: 2/30... Training loss: 0.0978\n",
      "Epoch: 2/30... Training loss: 0.0969\n",
      "Epoch: 2/30... Training loss: 0.0986\n",
      "Epoch: 2/30... Training loss: 0.0976\n",
      "Epoch: 2/30... Training loss: 0.1010\n",
      "Epoch: 2/30... Training loss: 0.0990\n",
      "Epoch: 2/30... Training loss: 0.1033\n",
      "Epoch: 2/30... Training loss: 0.1025\n",
      "Epoch: 2/30... Training loss: 0.0966\n",
      "Epoch: 2/30... Training loss: 0.0979\n",
      "Epoch: 2/30... Training loss: 0.0983\n",
      "Epoch: 2/30... Training loss: 0.0994\n",
      "Epoch: 2/30... Training loss: 0.0916\n",
      "Epoch: 2/30... Training loss: 0.0931\n",
      "Epoch: 2/30... Training loss: 0.1018\n",
      "Epoch: 2/30... Training loss: 0.0988\n",
      "Epoch: 2/30... Training loss: 0.1107\n",
      "Epoch: 2/30... Training loss: 0.1098\n",
      "Epoch: 2/30... Training loss: 0.1084\n",
      "Epoch: 2/30... Training loss: 0.1069\n",
      "Epoch: 2/30... Training loss: 0.1075\n",
      "Epoch: 2/30... Training loss: 0.1008\n",
      "Epoch: 2/30... Training loss: 0.1053\n",
      "Epoch: 2/30... Training loss: 0.1071\n",
      "Epoch: 2/30... Training loss: 0.1089\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.1025\n",
      "Epoch: 2/30... Training loss: 0.0980\n",
      "Epoch: 2/30... Training loss: 0.0958\n",
      "Epoch: 2/30... Training loss: 0.0989\n",
      "Epoch: 2/30... Training loss: 0.1104\n",
      "Epoch: 2/30... Training loss: 0.0920\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.1016\n",
      "Epoch: 2/30... Training loss: 0.1033\n",
      "Epoch: 2/30... Training loss: 0.1111\n",
      "Epoch: 2/30... Training loss: 0.0986\n",
      "Epoch: 2/30... Training loss: 0.0979\n",
      "Epoch: 2/30... Training loss: 0.0938\n",
      "Epoch: 2/30... Training loss: 0.0967\n",
      "Epoch: 2/30... Training loss: 0.1055\n",
      "Epoch: 2/30... Training loss: 0.0972\n",
      "Epoch: 2/30... Training loss: 0.0990\n",
      "Epoch: 2/30... Training loss: 0.0936\n",
      "Epoch: 2/30... Training loss: 0.1076\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.0966\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.1077\n",
      "Epoch: 2/30... Training loss: 0.0997\n",
      "Epoch: 2/30... Training loss: 0.0965\n",
      "Epoch: 2/30... Training loss: 0.0974\n",
      "Epoch: 2/30... Training loss: 0.1001\n",
      "Epoch: 2/30... Training loss: 0.0991\n",
      "Epoch: 2/30... Training loss: 0.0967\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1023\n",
      "Epoch: 2/30... Training loss: 0.0923\n",
      "Epoch: 2/30... Training loss: 0.1063\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.1102\n",
      "Epoch: 2/30... Training loss: 0.1045\n",
      "Epoch: 2/30... Training loss: 0.0967\n",
      "Epoch: 2/30... Training loss: 0.0983\n",
      "Epoch: 2/30... Training loss: 0.1036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/30... Training loss: 0.1044\n",
      "Epoch: 2/30... Training loss: 0.1102\n",
      "Epoch: 2/30... Training loss: 0.1006\n",
      "Epoch: 2/30... Training loss: 0.1049\n",
      "Epoch: 2/30... Training loss: 0.0908\n",
      "Epoch: 2/30... Training loss: 0.1016\n",
      "Epoch: 2/30... Training loss: 0.0937\n",
      "Epoch: 2/30... Training loss: 0.0999\n",
      "Epoch: 2/30... Training loss: 0.0948\n",
      "Epoch: 2/30... Training loss: 0.0925\n",
      "Epoch: 2/30... Training loss: 0.0980\n",
      "Epoch: 2/30... Training loss: 0.1044\n",
      "Epoch: 2/30... Training loss: 0.1078\n",
      "Epoch: 2/30... Training loss: 0.1000\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1019\n",
      "Epoch: 2/30... Training loss: 0.1024\n",
      "Epoch: 2/30... Training loss: 0.0962\n",
      "Epoch: 2/30... Training loss: 0.1000\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1022\n",
      "Epoch: 2/30... Training loss: 0.0934\n",
      "Epoch: 2/30... Training loss: 0.1024\n",
      "Epoch: 2/30... Training loss: 0.1006\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.1013\n",
      "Epoch: 2/30... Training loss: 0.0984\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.1055\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.0980\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.0995\n",
      "Epoch: 2/30... Training loss: 0.0958\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1011\n",
      "Epoch: 2/30... Training loss: 0.0968\n",
      "Epoch: 2/30... Training loss: 0.0990\n",
      "Epoch: 2/30... Training loss: 0.0950\n",
      "Epoch: 2/30... Training loss: 0.1015\n",
      "Epoch: 2/30... Training loss: 0.0968\n",
      "Epoch: 2/30... Training loss: 0.1010\n",
      "Epoch: 2/30... Training loss: 0.1002\n",
      "Epoch: 2/30... Training loss: 0.1051\n",
      "Epoch: 2/30... Training loss: 0.0946\n",
      "Epoch: 2/30... Training loss: 0.1081\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.0987\n",
      "Epoch: 2/30... Training loss: 0.0938\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.0929\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.1020\n",
      "Epoch: 2/30... Training loss: 0.1064\n",
      "Epoch: 2/30... Training loss: 0.0977\n",
      "Epoch: 2/30... Training loss: 0.0953\n",
      "Epoch: 2/30... Training loss: 0.1074\n",
      "Epoch: 2/30... Training loss: 0.1036\n",
      "Epoch: 2/30... Training loss: 0.0955\n",
      "Epoch: 2/30... Training loss: 0.1006\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.0966\n",
      "Epoch: 2/30... Training loss: 0.1003\n",
      "Epoch: 2/30... Training loss: 0.0967\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.0944\n",
      "Epoch: 2/30... Training loss: 0.1034\n",
      "Epoch: 2/30... Training loss: 0.0948\n",
      "Epoch: 2/30... Training loss: 0.1041\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.0906\n",
      "Epoch: 2/30... Training loss: 0.0976\n",
      "Epoch: 2/30... Training loss: 0.0996\n",
      "Epoch: 2/30... Training loss: 0.0952\n",
      "Epoch: 2/30... Training loss: 0.1045\n",
      "Epoch: 2/30... Training loss: 0.0991\n",
      "Epoch: 2/30... Training loss: 0.0994\n",
      "Epoch: 2/30... Training loss: 0.0983\n",
      "Epoch: 2/30... Training loss: 0.1008\n",
      "Epoch: 2/30... Training loss: 0.1031\n",
      "Epoch: 2/30... Training loss: 0.1018\n",
      "Epoch: 2/30... Training loss: 0.1040\n",
      "Epoch: 2/30... Training loss: 0.0991\n",
      "Epoch: 2/30... Training loss: 0.0959\n",
      "Epoch: 2/30... Training loss: 0.1004\n",
      "Epoch: 2/30... Training loss: 0.0995\n",
      "Epoch: 2/30... Training loss: 0.1004\n",
      "Epoch: 2/30... Training loss: 0.0994\n",
      "Epoch: 2/30... Training loss: 0.0989\n",
      "Epoch: 2/30... Training loss: 0.0969\n",
      "Epoch: 2/30... Training loss: 0.1052\n",
      "Epoch: 2/30... Training loss: 0.0969\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.0977\n",
      "Epoch: 2/30... Training loss: 0.0964\n",
      "Epoch: 2/30... Training loss: 0.0942\n",
      "Epoch: 2/30... Training loss: 0.1001\n",
      "Epoch: 2/30... Training loss: 0.0982\n",
      "Epoch: 2/30... Training loss: 0.1028\n",
      "Epoch: 2/30... Training loss: 0.1008\n",
      "Epoch: 2/30... Training loss: 0.0911\n",
      "Epoch: 2/30... Training loss: 0.0938\n",
      "Epoch: 2/30... Training loss: 0.1058\n",
      "Epoch: 2/30... Training loss: 0.1042\n",
      "Epoch: 2/30... Training loss: 0.1008\n",
      "Epoch: 2/30... Training loss: 0.1043\n",
      "Epoch: 2/30... Training loss: 0.0981\n",
      "Epoch: 2/30... Training loss: 0.1016\n",
      "Epoch: 2/30... Training loss: 0.0970\n",
      "Epoch: 2/30... Training loss: 0.1003\n",
      "Epoch: 2/30... Training loss: 0.1022\n",
      "Epoch: 2/30... Training loss: 0.0914\n",
      "Epoch: 2/30... Training loss: 0.1111\n",
      "Epoch: 2/30... Training loss: 0.0933\n",
      "Epoch: 2/30... Training loss: 0.0949\n",
      "Epoch: 2/30... Training loss: 0.0973\n",
      "Epoch: 2/30... Training loss: 0.1011\n",
      "Epoch: 2/30... Training loss: 0.0929\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.0905\n",
      "Epoch: 2/30... Training loss: 0.0976\n",
      "Epoch: 2/30... Training loss: 0.0922\n",
      "Epoch: 2/30... Training loss: 0.0994\n",
      "Epoch: 2/30... Training loss: 0.1018\n",
      "Epoch: 2/30... Training loss: 0.0929\n",
      "Epoch: 2/30... Training loss: 0.1059\n",
      "Epoch: 2/30... Training loss: 0.0945\n",
      "Epoch: 2/30... Training loss: 0.0985\n",
      "Epoch: 2/30... Training loss: 0.1001\n",
      "Epoch: 2/30... Training loss: 0.1032\n",
      "Epoch: 2/30... Training loss: 0.1003\n",
      "Epoch: 2/30... Training loss: 0.0937\n",
      "Epoch: 2/30... Training loss: 0.1024\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.1017\n",
      "Epoch: 2/30... Training loss: 0.0940\n",
      "Epoch: 2/30... Training loss: 0.0988\n",
      "Epoch: 2/30... Training loss: 0.1000\n",
      "Epoch: 2/30... Training loss: 0.0992\n",
      "Epoch: 2/30... Training loss: 0.1003\n",
      "Epoch: 2/30... Training loss: 0.1031\n",
      "Epoch: 2/30... Training loss: 0.1015\n",
      "Epoch: 2/30... Training loss: 0.0985\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.0980\n",
      "Epoch: 2/30... Training loss: 0.0967\n",
      "Epoch: 2/30... Training loss: 0.0994\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.0955\n",
      "Epoch: 2/30... Training loss: 0.1064\n",
      "Epoch: 2/30... Training loss: 0.0918\n",
      "Epoch: 2/30... Training loss: 0.1031\n",
      "Epoch: 2/30... Training loss: 0.0984\n",
      "Epoch: 2/30... Training loss: 0.0948\n",
      "Epoch: 2/30... Training loss: 0.0954\n",
      "Epoch: 2/30... Training loss: 0.0926\n",
      "Epoch: 2/30... Training loss: 0.1041\n",
      "Epoch: 2/30... Training loss: 0.0879\n",
      "Epoch: 2/30... Training loss: 0.0979\n",
      "Epoch: 2/30... Training loss: 0.0995\n",
      "Epoch: 2/30... Training loss: 0.1009\n",
      "Epoch: 2/30... Training loss: 0.0995\n",
      "Epoch: 2/30... Training loss: 0.0977\n",
      "Epoch: 2/30... Training loss: 0.1010\n",
      "Epoch: 2/30... Training loss: 0.0921\n",
      "Epoch: 2/30... Training loss: 0.1039\n",
      "Epoch: 2/30... Training loss: 0.0938\n",
      "Epoch: 2/30... Training loss: 0.0933\n",
      "Epoch: 2/30... Training loss: 0.0981\n",
      "Epoch: 2/30... Training loss: 0.0885\n",
      "Epoch: 2/30... Training loss: 0.1007\n",
      "Epoch: 2/30... Training loss: 0.0982\n",
      "Epoch: 2/30... Training loss: 0.1036\n",
      "Epoch: 2/30... Training loss: 0.0929\n",
      "Epoch: 2/30... Training loss: 0.1022\n",
      "Epoch: 2/30... Training loss: 0.1054\n",
      "Epoch: 2/30... Training loss: 0.0924\n",
      "Epoch: 2/30... Training loss: 0.0990\n",
      "Epoch: 2/30... Training loss: 0.0949\n",
      "Epoch: 2/30... Training loss: 0.0972\n",
      "Epoch: 2/30... Training loss: 0.0922\n",
      "Epoch: 2/30... Training loss: 0.0966\n",
      "Epoch: 2/30... Training loss: 0.0954\n",
      "Epoch: 2/30... Training loss: 0.0912\n",
      "Epoch: 2/30... Training loss: 0.1033\n",
      "Epoch: 2/30... Training loss: 0.1019\n",
      "Epoch: 2/30... Training loss: 0.0957\n",
      "Epoch: 2/30... Training loss: 0.1048\n",
      "Epoch: 2/30... Training loss: 0.1016\n",
      "Epoch: 2/30... Training loss: 0.0947\n",
      "Epoch: 2/30... Training loss: 0.1015\n",
      "Epoch: 2/30... Training loss: 0.1056\n",
      "Epoch: 2/30... Training loss: 0.1015\n",
      "Epoch: 2/30... Training loss: 0.0963\n",
      "Epoch: 2/30... Training loss: 0.0998\n",
      "Epoch: 2/30... Training loss: 0.0972\n",
      "Epoch: 2/30... Training loss: 0.0982\n",
      "Epoch: 2/30... Training loss: 0.0988\n",
      "Epoch: 2/30... Training loss: 0.0984\n",
      "Epoch: 2/30... Training loss: 0.0938\n",
      "Epoch: 2/30... Training loss: 0.1020\n",
      "Epoch: 2/30... Training loss: 0.0975\n",
      "Epoch: 2/30... Training loss: 0.0947\n",
      "Epoch: 2/30... Training loss: 0.0968\n",
      "Epoch: 2/30... Training loss: 0.0998\n",
      "Epoch: 2/30... Training loss: 0.1034\n",
      "Epoch: 2/30... Training loss: 0.0988\n",
      "Epoch: 2/30... Training loss: 0.0952\n",
      "Epoch: 2/30... Training loss: 0.1014\n",
      "Epoch: 2/30... Training loss: 0.0936\n",
      "Epoch: 2/30... Training loss: 0.1030\n",
      "Epoch: 2/30... Training loss: 0.1003\n",
      "Epoch: 2/30... Training loss: 0.0976\n",
      "Epoch: 2/30... Training loss: 0.0933\n",
      "Epoch: 2/30... Training loss: 0.0996\n",
      "Epoch: 2/30... Training loss: 0.0981\n",
      "Epoch: 2/30... Training loss: 0.1045\n",
      "Epoch: 2/30... Training loss: 0.1027\n",
      "Epoch: 2/30... Training loss: 0.0910\n",
      "Epoch: 2/30... Training loss: 0.0977\n",
      "Epoch: 2/30... Training loss: 0.1025\n",
      "Epoch: 2/30... Training loss: 0.0948\n",
      "Epoch: 2/30... Training loss: 0.1012\n",
      "Epoch: 2/30... Training loss: 0.0876\n",
      "Epoch: 2/30... Training loss: 0.0948\n",
      "Epoch: 2/30... Training loss: 0.0880\n",
      "Epoch: 2/30... Training loss: 0.0967\n",
      "Epoch: 2/30... Training loss: 0.0956\n",
      "Epoch: 2/30... Training loss: 0.0954\n",
      "Epoch: 2/30... Training loss: 0.0978\n",
      "Epoch: 2/30... Training loss: 0.1029\n",
      "Epoch: 2/30... Training loss: 0.1017\n",
      "Epoch: 2/30... Training loss: 0.0963\n",
      "Epoch: 2/30... Training loss: 0.1017\n",
      "Epoch: 2/30... Training loss: 0.0978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.1023\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0979\n",
      "Epoch: 3/30... Training loss: 0.0997\n",
      "Epoch: 3/30... Training loss: 0.0975\n",
      "Epoch: 3/30... Training loss: 0.0977\n",
      "Epoch: 3/30... Training loss: 0.0976\n",
      "Epoch: 3/30... Training loss: 0.0988\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.1019\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.1020\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.1039\n",
      "Epoch: 3/30... Training loss: 0.0962\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.0980\n",
      "Epoch: 3/30... Training loss: 0.0997\n",
      "Epoch: 3/30... Training loss: 0.1032\n",
      "Epoch: 3/30... Training loss: 0.0975\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.1011\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0953\n",
      "Epoch: 3/30... Training loss: 0.0962\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0947\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.1001\n",
      "Epoch: 3/30... Training loss: 0.0997\n",
      "Epoch: 3/30... Training loss: 0.1002\n",
      "Epoch: 3/30... Training loss: 0.0998\n",
      "Epoch: 3/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.1014\n",
      "Epoch: 3/30... Training loss: 0.0971\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0981\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0988\n",
      "Epoch: 3/30... Training loss: 0.0971\n",
      "Epoch: 3/30... Training loss: 0.0958\n",
      "Epoch: 3/30... Training loss: 0.1012\n",
      "Epoch: 3/30... Training loss: 0.0975\n",
      "Epoch: 3/30... Training loss: 0.0958\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0988\n",
      "Epoch: 3/30... Training loss: 0.1016\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0969\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.1012\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0976\n",
      "Epoch: 3/30... Training loss: 0.0979\n",
      "Epoch: 3/30... Training loss: 0.1032\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0994\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0999\n",
      "Epoch: 3/30... Training loss: 0.0991\n",
      "Epoch: 3/30... Training loss: 0.0927\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0991\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.1017\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.1041\n",
      "Epoch: 3/30... Training loss: 0.0986\n",
      "Epoch: 3/30... Training loss: 0.0942\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.0991\n",
      "Epoch: 3/30... Training loss: 0.0986\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.1026\n",
      "Epoch: 3/30... Training loss: 0.0977\n",
      "Epoch: 3/30... Training loss: 0.1014\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.0945\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0986\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0975\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.1057\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.0957\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0978\n",
      "Epoch: 3/30... Training loss: 0.0967\n",
      "Epoch: 3/30... Training loss: 0.0987\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.1008\n",
      "Epoch: 3/30... Training loss: 0.0967\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.0927\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0968\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0987\n",
      "Epoch: 3/30... Training loss: 0.0969\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0991\n",
      "Epoch: 3/30... Training loss: 0.1022\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.1002\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.1036\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0945\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.1011\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.1026\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0862\n",
      "Epoch: 3/30... Training loss: 0.0983\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0980\n",
      "Epoch: 3/30... Training loss: 0.0996\n",
      "Epoch: 3/30... Training loss: 0.1016\n",
      "Epoch: 3/30... Training loss: 0.1009\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0990\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0980\n",
      "Epoch: 3/30... Training loss: 0.0986\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0984\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0977\n",
      "Epoch: 3/30... Training loss: 0.0959\n",
      "Epoch: 3/30... Training loss: 0.0950\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0947\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0989\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0942\n",
      "Epoch: 3/30... Training loss: 0.0927\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0996\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0993\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.1095\n",
      "Epoch: 3/30... Training loss: 0.0947\n",
      "Epoch: 3/30... Training loss: 0.0966\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.1032\n",
      "Epoch: 3/30... Training loss: 0.0959\n",
      "Epoch: 3/30... Training loss: 0.0967\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0992\n",
      "Epoch: 3/30... Training loss: 0.0957\n",
      "Epoch: 3/30... Training loss: 0.0996\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0972\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.1005\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.1011\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0966\n",
      "Epoch: 3/30... Training loss: 0.1017\n",
      "Epoch: 3/30... Training loss: 0.0829\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.1007\n",
      "Epoch: 3/30... Training loss: 0.1034\n",
      "Epoch: 3/30... Training loss: 0.0945\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0969\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0973\n",
      "Epoch: 3/30... Training loss: 0.1008\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0990\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0989\n",
      "Epoch: 3/30... Training loss: 0.0979\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0989\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0953\n",
      "Epoch: 3/30... Training loss: 0.0959\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0968\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30... Training loss: 0.1040\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.1037\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0950\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0945\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0977\n",
      "Epoch: 3/30... Training loss: 0.0962\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.1008\n",
      "Epoch: 3/30... Training loss: 0.0957\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.0827\n",
      "Epoch: 3/30... Training loss: 0.1009\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0950\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0990\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0988\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0829\n",
      "Epoch: 3/30... Training loss: 0.0966\n",
      "Epoch: 3/30... Training loss: 0.0993\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.0969\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.1003\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0957\n",
      "Epoch: 3/30... Training loss: 0.0953\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0969\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0862\n",
      "Epoch: 3/30... Training loss: 0.0999\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0950\n",
      "Epoch: 3/30... Training loss: 0.0978\n",
      "Epoch: 3/30... Training loss: 0.0821\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0992\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0958\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0968\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.1021\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0983\n",
      "Epoch: 3/30... Training loss: 0.0978\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0954\n",
      "Epoch: 3/30... Training loss: 0.0950\n",
      "Epoch: 3/30... Training loss: 0.0950\n",
      "Epoch: 3/30... Training loss: 0.1022\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0977\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.0942\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0950\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.0986\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0990\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0862\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0995\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0975\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0898\n",
      "Epoch: 3/30... Training loss: 0.0972\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0953\n",
      "Epoch: 3/30... Training loss: 0.0928\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0984\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0974\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0982\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0998\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0823\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0970\n",
      "Epoch: 3/30... Training loss: 0.0973\n",
      "Epoch: 3/30... Training loss: 0.0898\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0947\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0863\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0976\n",
      "Epoch: 3/30... Training loss: 0.1014\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0828\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30... Training loss: 0.0967\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0945\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0956\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0898\n",
      "Epoch: 3/30... Training loss: 0.0954\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0974\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.0823\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0834\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0939\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0931\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0959\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0934\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0961\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0969\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0862\n",
      "Epoch: 3/30... Training loss: 0.0952\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0847\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0844\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0983\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0942\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.0973\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0964\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0978\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0862\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0965\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0830\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0944\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0945\n",
      "Epoch: 3/30... Training loss: 0.0932\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0960\n",
      "Epoch: 3/30... Training loss: 0.0811\n",
      "Epoch: 3/30... Training loss: 0.0848\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0927\n",
      "Epoch: 3/30... Training loss: 0.0943\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0940\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0812\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0948\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0976\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0791\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0976\n",
      "Epoch: 3/30... Training loss: 0.0945\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0963\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0924\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0955\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0951\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0858\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0839\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0930\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0843\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0869\n",
      "Epoch: 3/30... Training loss: 0.0839\n",
      "Epoch: 3/30... Training loss: 0.0840\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0844\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0868\n",
      "Epoch: 3/30... Training loss: 0.0985\n",
      "Epoch: 3/30... Training loss: 0.0846\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0938\n",
      "Epoch: 3/30... Training loss: 0.0912\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0832\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0989\n",
      "Epoch: 3/30... Training loss: 0.0805\n",
      "Epoch: 3/30... Training loss: 0.0922\n",
      "Epoch: 3/30... Training loss: 0.0818\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0845\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0843\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0839\n",
      "Epoch: 3/30... Training loss: 0.0864\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0863\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0842\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0923\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0907\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0937\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0911\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0817\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0941\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0946\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0947\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0803\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0927\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0847\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0954\n",
      "Epoch: 3/30... Training loss: 0.0833\n",
      "Epoch: 3/30... Training loss: 0.0837\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0803\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0862\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0949\n",
      "Epoch: 3/30... Training loss: 0.0837\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0823\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0894\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0910\n",
      "Epoch: 3/30... Training loss: 0.0811\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0920\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0846\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0846\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0836\n",
      "Epoch: 3/30... Training loss: 0.0798\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0814\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0845\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0929\n",
      "Epoch: 3/30... Training loss: 0.0896\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0925\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0824\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0898\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0827\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0842\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0957\n",
      "Epoch: 3/30... Training loss: 0.0857\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0858\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0908\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0847\n",
      "Epoch: 3/30... Training loss: 0.0829\n",
      "Epoch: 3/30... Training loss: 0.0874\n",
      "Epoch: 3/30... Training loss: 0.0868\n",
      "Epoch: 3/30... Training loss: 0.0936\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0873\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0878\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0918\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0832\n",
      "Epoch: 3/30... Training loss: 0.0844\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0840\n",
      "Epoch: 3/30... Training loss: 0.0839\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0851\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0828\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0804\n",
      "Epoch: 3/30... Training loss: 0.0903\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0966\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0879\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0913\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0863\n",
      "Epoch: 3/30... Training loss: 0.0810\n",
      "Epoch: 3/30... Training loss: 0.0824\n",
      "Epoch: 3/30... Training loss: 0.0844\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0865\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0816\n",
      "Epoch: 3/30... Training loss: 0.0834\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0838\n",
      "Epoch: 3/30... Training loss: 0.0902\n",
      "Epoch: 3/30... Training loss: 0.0823\n",
      "Epoch: 3/30... Training loss: 0.0795\n",
      "Epoch: 3/30... Training loss: 0.0845\n",
      "Epoch: 3/30... Training loss: 0.0833\n",
      "Epoch: 3/30... Training loss: 0.0870\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0926\n",
      "Epoch: 3/30... Training loss: 0.0819\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0858\n",
      "Epoch: 3/30... Training loss: 0.0798\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0807\n",
      "Epoch: 3/30... Training loss: 0.0832\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0849\n",
      "Epoch: 3/30... Training loss: 0.0950\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0834\n",
      "Epoch: 3/30... Training loss: 0.0834\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0909\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0824\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0833\n",
      "Epoch: 3/30... Training loss: 0.0853\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0844\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0935\n",
      "Epoch: 3/30... Training loss: 0.0847\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0900\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0821\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0899\n",
      "Epoch: 3/30... Training loss: 0.0916\n",
      "Epoch: 3/30... Training loss: 0.0863\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0837\n",
      "Epoch: 3/30... Training loss: 0.0862\n",
      "Epoch: 3/30... Training loss: 0.0897\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0846\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0888\n",
      "Epoch: 3/30... Training loss: 0.0824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30... Training loss: 0.0844\n",
      "Epoch: 3/30... Training loss: 0.0915\n",
      "Epoch: 3/30... Training loss: 0.0885\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0780\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0834\n",
      "Epoch: 3/30... Training loss: 0.0821\n",
      "Epoch: 3/30... Training loss: 0.0858\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0844\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0817\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0868\n",
      "Epoch: 3/30... Training loss: 0.0881\n",
      "Epoch: 3/30... Training loss: 0.0814\n",
      "Epoch: 3/30... Training loss: 0.0933\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0786\n",
      "Epoch: 3/30... Training loss: 0.0837\n",
      "Epoch: 3/30... Training loss: 0.0794\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0818\n",
      "Epoch: 3/30... Training loss: 0.0829\n",
      "Epoch: 3/30... Training loss: 0.0847\n",
      "Epoch: 3/30... Training loss: 0.0860\n",
      "Epoch: 3/30... Training loss: 0.0906\n",
      "Epoch: 3/30... Training loss: 0.0821\n",
      "Epoch: 3/30... Training loss: 0.0886\n",
      "Epoch: 3/30... Training loss: 0.0812\n",
      "Epoch: 3/30... Training loss: 0.0841\n",
      "Epoch: 3/30... Training loss: 0.0895\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0820\n",
      "Epoch: 3/30... Training loss: 0.0843\n",
      "Epoch: 3/30... Training loss: 0.0774\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0893\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0917\n",
      "Epoch: 3/30... Training loss: 0.0814\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0832\n",
      "Epoch: 3/30... Training loss: 0.0808\n",
      "Epoch: 3/30... Training loss: 0.0824\n",
      "Epoch: 3/30... Training loss: 0.0921\n",
      "Epoch: 3/30... Training loss: 0.0834\n",
      "Epoch: 3/30... Training loss: 0.0797\n",
      "Epoch: 3/30... Training loss: 0.0746\n",
      "Epoch: 3/30... Training loss: 0.0820\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0884\n",
      "Epoch: 3/30... Training loss: 0.0834\n",
      "Epoch: 3/30... Training loss: 0.0901\n",
      "Epoch: 3/30... Training loss: 0.0883\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0804\n",
      "Epoch: 3/30... Training loss: 0.0905\n",
      "Epoch: 3/30... Training loss: 0.0919\n",
      "Epoch: 3/30... Training loss: 0.0880\n",
      "Epoch: 3/30... Training loss: 0.0833\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0866\n",
      "Epoch: 3/30... Training loss: 0.0854\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0904\n",
      "Epoch: 3/30... Training loss: 0.0855\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0867\n",
      "Epoch: 3/30... Training loss: 0.0875\n",
      "Epoch: 3/30... Training loss: 0.0856\n",
      "Epoch: 3/30... Training loss: 0.0914\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 3/30... Training loss: 0.0842\n",
      "Epoch: 3/30... Training loss: 0.0877\n",
      "Epoch: 3/30... Training loss: 0.0842\n",
      "Epoch: 3/30... Training loss: 0.0863\n",
      "Epoch: 3/30... Training loss: 0.0871\n",
      "Epoch: 3/30... Training loss: 0.0890\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0815\n",
      "Epoch: 3/30... Training loss: 0.0927\n",
      "Epoch: 3/30... Training loss: 0.0887\n",
      "Epoch: 3/30... Training loss: 0.0898\n",
      "Epoch: 3/30... Training loss: 0.0876\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0889\n",
      "Epoch: 3/30... Training loss: 0.0823\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0822\n",
      "Epoch: 3/30... Training loss: 0.0861\n",
      "Epoch: 3/30... Training loss: 0.0833\n",
      "Epoch: 3/30... Training loss: 0.0891\n",
      "Epoch: 3/30... Training loss: 0.0790\n",
      "Epoch: 3/30... Training loss: 0.0807\n",
      "Epoch: 3/30... Training loss: 0.0850\n",
      "Epoch: 3/30... Training loss: 0.0852\n",
      "Epoch: 3/30... Training loss: 0.0804\n",
      "Epoch: 3/30... Training loss: 0.0821\n",
      "Epoch: 3/30... Training loss: 0.0868\n",
      "Epoch: 3/30... Training loss: 0.0833\n",
      "Epoch: 3/30... Training loss: 0.0820\n",
      "Epoch: 3/30... Training loss: 0.0882\n",
      "Epoch: 3/30... Training loss: 0.0846\n",
      "Epoch: 3/30... Training loss: 0.0868\n",
      "Epoch: 3/30... Training loss: 0.0774\n",
      "Epoch: 3/30... Training loss: 0.0859\n",
      "Epoch: 3/30... Training loss: 0.0872\n",
      "Epoch: 3/30... Training loss: 0.0809\n",
      "Epoch: 3/30... Training loss: 0.0829\n",
      "Epoch: 3/30... Training loss: 0.0892\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0876\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0873\n",
      "Epoch: 4/30... Training loss: 0.0889\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0880\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0865\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0896\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0893\n",
      "Epoch: 4/30... Training loss: 0.0879\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0767\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0923\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0896\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0931\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0868\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0891\n",
      "Epoch: 4/30... Training loss: 0.0865\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0895\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0913\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0904\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0873\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0906\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0905\n",
      "Epoch: 4/30... Training loss: 0.0968\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0892\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0865\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0896\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0936\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0910\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0887\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0881\n",
      "Epoch: 4/30... Training loss: 0.0881\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0921\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0775\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0886\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0865\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0874\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0885\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0880\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0772\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0927\n",
      "Epoch: 4/30... Training loss: 0.0883\n",
      "Epoch: 4/30... Training loss: 0.0891\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0890\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0893\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0889\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0941\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0901\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0888\n",
      "Epoch: 4/30... Training loss: 0.0885\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0865\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0886\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0903\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0889\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0769\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0891\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0890\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0915\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0885\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0882\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0913\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0772\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0914\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0894\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0874\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0756\n",
      "Epoch: 4/30... Training loss: 0.0756\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0876\n",
      "Epoch: 4/30... Training loss: 0.0880\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0880\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0902\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0754\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0885\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0893\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0898\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0897\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0892\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0873\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0724\n",
      "Epoch: 4/30... Training loss: 0.0891\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0752\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0774\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0893\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0885\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0895\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0753\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0885\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0895\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0880\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0904\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0868\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0768\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0760\n",
      "Epoch: 4/30... Training loss: 0.0865\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0876\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0902\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0770\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0912\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0747\n",
      "Epoch: 4/30... Training loss: 0.0879\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0774\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0759\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0886\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0886\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0770\n",
      "Epoch: 4/30... Training loss: 0.0885\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0870\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0876\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0879\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0879\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0756\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0873\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0855\n",
      "Epoch: 4/30... Training loss: 0.0865\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0892\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0864\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0771\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0778\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0778\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0759\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0763\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0762\n",
      "Epoch: 4/30... Training loss: 0.0763\n",
      "Epoch: 4/30... Training loss: 0.0755\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0775\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0774\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0765\n",
      "Epoch: 4/30... Training loss: 0.0771\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0763\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0774\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0770\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0843\n",
      "Epoch: 4/30... Training loss: 0.0764\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0774\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0752\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0757\n",
      "Epoch: 4/30... Training loss: 0.0866\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0871\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0881\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0767\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0856\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0861\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0817\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0718\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0847\n",
      "Epoch: 4/30... Training loss: 0.0784\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0778\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0753\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0862\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0836\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0772\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0757\n",
      "Epoch: 4/30... Training loss: 0.0768\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0748\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0859\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0778\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0850\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0869\n",
      "Epoch: 4/30... Training loss: 0.0839\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0775\n",
      "Epoch: 4/30... Training loss: 0.0766\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0794\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0737\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0775\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0919\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0769\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0774\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0774\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0762\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0774\n",
      "Epoch: 4/30... Training loss: 0.0761\n",
      "Epoch: 4/30... Training loss: 0.0763\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0830\n",
      "Epoch: 4/30... Training loss: 0.0805\n",
      "Epoch: 4/30... Training loss: 0.0829\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0758\n",
      "Epoch: 4/30... Training loss: 0.0793\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0867\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0765\n",
      "Epoch: 4/30... Training loss: 0.0760\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0852\n",
      "Epoch: 4/30... Training loss: 0.0745\n",
      "Epoch: 4/30... Training loss: 0.0831\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0875\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0833\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0755\n",
      "Epoch: 4/30... Training loss: 0.0799\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0757\n",
      "Epoch: 4/30... Training loss: 0.0784\n",
      "Epoch: 4/30... Training loss: 0.0776\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0758\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0819\n",
      "Epoch: 4/30... Training loss: 0.0837\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0842\n",
      "Epoch: 4/30... Training loss: 0.0792\n",
      "Epoch: 4/30... Training loss: 0.0808\n",
      "Epoch: 4/30... Training loss: 0.0779\n",
      "Epoch: 4/30... Training loss: 0.0754\n",
      "Epoch: 4/30... Training loss: 0.0705\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0768\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0810\n",
      "Epoch: 4/30... Training loss: 0.0797\n",
      "Epoch: 4/30... Training loss: 0.0844\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0821\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0857\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0813\n",
      "Epoch: 4/30... Training loss: 0.0775\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0783\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0853\n",
      "Epoch: 4/30... Training loss: 0.0851\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0824\n",
      "Epoch: 4/30... Training loss: 0.0772\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0826\n",
      "Epoch: 4/30... Training loss: 0.0798\n",
      "Epoch: 4/30... Training loss: 0.0834\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0762\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0904\n",
      "Epoch: 4/30... Training loss: 0.0788\n",
      "Epoch: 4/30... Training loss: 0.0840\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0823\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0828\n",
      "Epoch: 4/30... Training loss: 0.0796\n",
      "Epoch: 4/30... Training loss: 0.0832\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0815\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0785\n",
      "Epoch: 4/30... Training loss: 0.0803\n",
      "Epoch: 4/30... Training loss: 0.0841\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0801\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0760\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0787\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0860\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0872\n",
      "Epoch: 4/30... Training loss: 0.0806\n",
      "Epoch: 4/30... Training loss: 0.0770\n",
      "Epoch: 4/30... Training loss: 0.0811\n",
      "Epoch: 4/30... Training loss: 0.0878\n",
      "Epoch: 4/30... Training loss: 0.0820\n",
      "Epoch: 4/30... Training loss: 0.0750\n",
      "Epoch: 4/30... Training loss: 0.0838\n",
      "Epoch: 4/30... Training loss: 0.0809\n",
      "Epoch: 4/30... Training loss: 0.0777\n",
      "Epoch: 4/30... Training loss: 0.0789\n",
      "Epoch: 4/30... Training loss: 0.0780\n",
      "Epoch: 4/30... Training loss: 0.0800\n",
      "Epoch: 4/30... Training loss: 0.0845\n",
      "Epoch: 4/30... Training loss: 0.0795\n",
      "Epoch: 4/30... Training loss: 0.0822\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0858\n",
      "Epoch: 4/30... Training loss: 0.0771\n",
      "Epoch: 4/30... Training loss: 0.0757\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0894\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0773\n",
      "Epoch: 4/30... Training loss: 0.0791\n",
      "Epoch: 4/30... Training loss: 0.0804\n",
      "Epoch: 4/30... Training loss: 0.0835\n",
      "Epoch: 4/30... Training loss: 0.0816\n",
      "Epoch: 4/30... Training loss: 0.0781\n",
      "Epoch: 4/30... Training loss: 0.0784\n",
      "Epoch: 4/30... Training loss: 0.0782\n",
      "Epoch: 4/30... Training loss: 0.0760\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0849\n",
      "Epoch: 4/30... Training loss: 0.0814\n",
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0760\n",
      "Epoch: 4/30... Training loss: 0.0827\n",
      "Epoch: 4/30... Training loss: 0.0802\n",
      "Epoch: 4/30... Training loss: 0.0790\n",
      "Epoch: 4/30... Training loss: 0.0877\n",
      "Epoch: 4/30... Training loss: 0.0812\n",
      "Epoch: 4/30... Training loss: 0.0829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/30... Training loss: 0.0786\n",
      "Epoch: 4/30... Training loss: 0.0769\n",
      "Epoch: 4/30... Training loss: 0.0772\n",
      "Epoch: 4/30... Training loss: 0.0807\n",
      "Epoch: 4/30... Training loss: 0.0818\n",
      "Epoch: 4/30... Training loss: 0.0770\n",
      "Epoch: 4/30... Training loss: 0.0765\n",
      "Epoch: 4/30... Training loss: 0.0846\n",
      "Epoch: 4/30... Training loss: 0.0825\n",
      "Epoch: 4/30... Training loss: 0.0848\n",
      "Epoch: 4/30... Training loss: 0.0854\n",
      "Epoch: 4/30... Training loss: 0.0888\n",
      "Epoch: 4/30... Training loss: 0.0863\n",
      "Epoch: 4/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0842\n",
      "Epoch: 5/30... Training loss: 0.0848\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0851\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0839\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0844\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0845\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0837\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0856\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0849\n",
      "Epoch: 5/30... Training loss: 0.0851\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0841\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0864\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0832\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0847\n",
      "Epoch: 5/30... Training loss: 0.0837\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0847\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0850\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0736\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0856\n",
      "Epoch: 5/30... Training loss: 0.0832\n",
      "Epoch: 5/30... Training loss: 0.0736\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0832\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0849\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0841\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0847\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0837\n",
      "Epoch: 5/30... Training loss: 0.0869\n",
      "Epoch: 5/30... Training loss: 0.0832\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0867\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0895\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0856\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0842\n",
      "Epoch: 5/30... Training loss: 0.0844\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0719\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0738\n",
      "Epoch: 5/30... Training loss: 0.0850\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0850\n",
      "Epoch: 5/30... Training loss: 0.0841\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0828\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0710\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0729\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0832\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0740\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0851\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0828\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0861\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0836\n",
      "Epoch: 5/30... Training loss: 0.0744\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0843\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0838\n",
      "Epoch: 5/30... Training loss: 0.0880\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0726\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0850\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0868\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0850\n",
      "Epoch: 5/30... Training loss: 0.0832\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0836\n",
      "Epoch: 5/30... Training loss: 0.0880\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0839\n",
      "Epoch: 5/30... Training loss: 0.0734\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0867\n",
      "Epoch: 5/30... Training loss: 0.0852\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0837\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0685\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0856\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0852\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0856\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0707\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0839\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0714\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0706\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0848\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0732\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0838\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0735\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0718\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0755\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0851\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0726\n",
      "Epoch: 5/30... Training loss: 0.0731\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0732\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0740\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0857\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0845\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0723\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0725\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0845\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0712\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0736\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0871\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0832\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0866\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0842\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0861\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0847\n",
      "Epoch: 5/30... Training loss: 0.0842\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0868\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0839\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0711\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0735\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0831\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0836\n",
      "Epoch: 5/30... Training loss: 0.0834\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0819\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0841\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0847\n",
      "Epoch: 5/30... Training loss: 0.0739\n",
      "Epoch: 5/30... Training loss: 0.0738\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0837\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0839\n",
      "Epoch: 5/30... Training loss: 0.0728\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0869\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0823\n",
      "Epoch: 5/30... Training loss: 0.0720\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0845\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0836\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0859\n",
      "Epoch: 5/30... Training loss: 0.0735\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0730\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0755\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0873\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0721\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0699\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0717\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0738\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0824\n",
      "Epoch: 5/30... Training loss: 0.0836\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0848\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0744\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0687\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0815\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0827\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0822\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0895\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0826\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0741\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0733\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0850\n",
      "Epoch: 5/30... Training loss: 0.0800\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0839\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0833\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0721\n",
      "Epoch: 5/30... Training loss: 0.0802\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0727\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0846\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0709\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0741\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0847\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0725\n",
      "Epoch: 5/30... Training loss: 0.0746\n",
      "Epoch: 5/30... Training loss: 0.0836\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0829\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0780\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0752\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0796\n",
      "Epoch: 5/30... Training loss: 0.0740\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0830\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0797\n",
      "Epoch: 5/30... Training loss: 0.0733\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0789\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0732\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0710\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0760\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0711\n",
      "Epoch: 5/30... Training loss: 0.0738\n",
      "Epoch: 5/30... Training loss: 0.0733\n",
      "Epoch: 5/30... Training loss: 0.0734\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0820\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0846\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0713\n",
      "Epoch: 5/30... Training loss: 0.0744\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0772\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0763\n",
      "Epoch: 5/30... Training loss: 0.0825\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0735\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0754\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0732\n",
      "Epoch: 5/30... Training loss: 0.0770\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0808\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 5/30... Training loss: 0.0719\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0846\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0812\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0729\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0748\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0736\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0742\n",
      "Epoch: 5/30... Training loss: 0.0758\n",
      "Epoch: 5/30... Training loss: 0.0729\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0774\n",
      "Epoch: 5/30... Training loss: 0.0776\n",
      "Epoch: 5/30... Training loss: 0.0814\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0807\n",
      "Epoch: 5/30... Training loss: 0.0805\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0840\n",
      "Epoch: 5/30... Training loss: 0.0787\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0788\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0755\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0737\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0775\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0792\n",
      "Epoch: 5/30... Training loss: 0.0811\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0731\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0749\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0783\n",
      "Epoch: 5/30... Training loss: 0.0761\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0747\n",
      "Epoch: 5/30... Training loss: 0.0782\n",
      "Epoch: 5/30... Training loss: 0.0784\n",
      "Epoch: 5/30... Training loss: 0.0771\n",
      "Epoch: 5/30... Training loss: 0.0730\n",
      "Epoch: 5/30... Training loss: 0.0773\n",
      "Epoch: 5/30... Training loss: 0.0733\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0801\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0723\n",
      "Epoch: 5/30... Training loss: 0.0730\n",
      "Epoch: 5/30... Training loss: 0.0842\n",
      "Epoch: 5/30... Training loss: 0.0813\n",
      "Epoch: 5/30... Training loss: 0.0719\n",
      "Epoch: 5/30... Training loss: 0.0757\n",
      "Epoch: 5/30... Training loss: 0.0804\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0785\n",
      "Epoch: 5/30... Training loss: 0.0762\n",
      "Epoch: 5/30... Training loss: 0.0767\n",
      "Epoch: 5/30... Training loss: 0.0764\n",
      "Epoch: 5/30... Training loss: 0.0725\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0778\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0809\n",
      "Epoch: 5/30... Training loss: 0.0745\n",
      "Epoch: 5/30... Training loss: 0.0817\n",
      "Epoch: 5/30... Training loss: 0.0730\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0835\n",
      "Epoch: 5/30... Training loss: 0.0756\n",
      "Epoch: 5/30... Training loss: 0.0840\n",
      "Epoch: 5/30... Training loss: 0.0781\n",
      "Epoch: 5/30... Training loss: 0.0727\n",
      "Epoch: 5/30... Training loss: 0.0779\n",
      "Epoch: 5/30... Training loss: 0.0750\n",
      "Epoch: 5/30... Training loss: 0.0791\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0832\n",
      "Epoch: 5/30... Training loss: 0.0806\n",
      "Epoch: 5/30... Training loss: 0.0818\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0816\n",
      "Epoch: 5/30... Training loss: 0.0799\n",
      "Epoch: 5/30... Training loss: 0.0810\n",
      "Epoch: 5/30... Training loss: 0.0786\n",
      "Epoch: 5/30... Training loss: 0.0733\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0777\n",
      "Epoch: 5/30... Training loss: 0.0793\n",
      "Epoch: 5/30... Training loss: 0.0759\n",
      "Epoch: 5/30... Training loss: 0.0768\n",
      "Epoch: 5/30... Training loss: 0.0751\n",
      "Epoch: 5/30... Training loss: 0.0769\n",
      "Epoch: 5/30... Training loss: 0.0821\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0723\n",
      "Epoch: 5/30... Training loss: 0.0753\n",
      "Epoch: 5/30... Training loss: 0.0731\n",
      "Epoch: 5/30... Training loss: 0.0794\n",
      "Epoch: 5/30... Training loss: 0.0790\n",
      "Epoch: 5/30... Training loss: 0.0707\n",
      "Epoch: 5/30... Training loss: 0.0795\n",
      "Epoch: 5/30... Training loss: 0.0803\n",
      "Epoch: 5/30... Training loss: 0.0726\n",
      "Epoch: 5/30... Training loss: 0.0715\n",
      "Epoch: 5/30... Training loss: 0.0798\n",
      "Epoch: 5/30... Training loss: 0.0766\n",
      "Epoch: 5/30... Training loss: 0.0765\n",
      "Epoch: 5/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0846\n",
      "Epoch: 6/30... Training loss: 0.0816\n",
      "Epoch: 6/30... Training loss: 0.0728\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0824\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0721\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0819\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0835\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0714\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0695\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0708\n",
      "Epoch: 6/30... Training loss: 0.0831\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0721\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0841\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0842\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0805\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0810\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0707\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0835\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0805\n",
      "Epoch: 6/30... Training loss: 0.0822\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0712\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0725\n",
      "Epoch: 6/30... Training loss: 0.0817\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0829\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0824\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0729\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0713\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0732\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0720\n",
      "Epoch: 6/30... Training loss: 0.0694\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0821\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0700\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0821\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0698\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0817\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0707\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0712\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0816\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0812\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0819\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0821\n",
      "Epoch: 6/30... Training loss: 0.0719\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0843\n",
      "Epoch: 6/30... Training loss: 0.0822\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0832\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0824\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0818\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0702\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0835\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0823\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0705\n",
      "Epoch: 6/30... Training loss: 0.0827\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0728\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0824\n",
      "Epoch: 6/30... Training loss: 0.0847\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0724\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0714\n",
      "Epoch: 6/30... Training loss: 0.0723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0826\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0721\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0716\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0823\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0713\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0824\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0834\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0830\n",
      "Epoch: 6/30... Training loss: 0.0804\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0819\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0828\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0812\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0819\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0821\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0701\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0821\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0713\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0725\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0718\n",
      "Epoch: 6/30... Training loss: 0.0826\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0717\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0816\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0828\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0824\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0819\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0823\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0708\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0804\n",
      "Epoch: 6/30... Training loss: 0.0816\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0820\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0728\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0725\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0720\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0820\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0817\n",
      "Epoch: 6/30... Training loss: 0.0850\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0710\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0816\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0710\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0812\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0826\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0697\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0678\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0819\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0706\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0816\n",
      "Epoch: 6/30... Training loss: 0.0819\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0721\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0812\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0812\n",
      "Epoch: 6/30... Training loss: 0.0718\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0805\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0717\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0717\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0850\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0815\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0724\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0729\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0816\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0684\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0717\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0825\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0839\n",
      "Epoch: 6/30... Training loss: 0.0820\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0718\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0729\n",
      "Epoch: 6/30... Training loss: 0.0716\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0716\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0835\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0771\n",
      "Epoch: 6/30... Training loss: 0.0831\n",
      "Epoch: 6/30... Training loss: 0.0721\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0710\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0695\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0735\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0820\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0828\n",
      "Epoch: 6/30... Training loss: 0.0740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0688\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0728\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0678\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0709\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0828\n",
      "Epoch: 6/30... Training loss: 0.0737\n",
      "Epoch: 6/30... Training loss: 0.0800\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0783\n",
      "Epoch: 6/30... Training loss: 0.0804\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0804\n",
      "Epoch: 6/30... Training loss: 0.0707\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0732\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0712\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0724\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0814\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0805\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0732\n",
      "Epoch: 6/30... Training loss: 0.0801\n",
      "Epoch: 6/30... Training loss: 0.0812\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0730\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0718\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0829\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0716\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0808\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0803\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0738\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0706\n",
      "Epoch: 6/30... Training loss: 0.0749\n",
      "Epoch: 6/30... Training loss: 0.0739\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0715\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0768\n",
      "Epoch: 6/30... Training loss: 0.0712\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0788\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0724\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0702\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0757\n",
      "Epoch: 6/30... Training loss: 0.0723\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0779\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0744\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0764\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0708\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0813\n",
      "Epoch: 6/30... Training loss: 0.0707\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0720\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0820\n",
      "Epoch: 6/30... Training loss: 0.0701\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0717\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0733\n",
      "Epoch: 6/30... Training loss: 0.0810\n",
      "Epoch: 6/30... Training loss: 0.0792\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0727\n",
      "Epoch: 6/30... Training loss: 0.0810\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0763\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0802\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0760\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0690\n",
      "Epoch: 6/30... Training loss: 0.0740\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0774\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0782\n",
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0826\n",
      "Epoch: 6/30... Training loss: 0.0708\n",
      "Epoch: 6/30... Training loss: 0.0753\n",
      "Epoch: 6/30... Training loss: 0.0777\n",
      "Epoch: 6/30... Training loss: 0.0776\n",
      "Epoch: 6/30... Training loss: 0.0703\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0731\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0758\n",
      "Epoch: 6/30... Training loss: 0.0781\n",
      "Epoch: 6/30... Training loss: 0.0811\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0702\n",
      "Epoch: 6/30... Training loss: 0.0724\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0769\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/30... Training loss: 0.0794\n",
      "Epoch: 6/30... Training loss: 0.0791\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0784\n",
      "Epoch: 6/30... Training loss: 0.0725\n",
      "Epoch: 6/30... Training loss: 0.0713\n",
      "Epoch: 6/30... Training loss: 0.0756\n",
      "Epoch: 6/30... Training loss: 0.0722\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0793\n",
      "Epoch: 6/30... Training loss: 0.0809\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0703\n",
      "Epoch: 6/30... Training loss: 0.0780\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0707\n",
      "Epoch: 6/30... Training loss: 0.0807\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0799\n",
      "Epoch: 6/30... Training loss: 0.0720\n",
      "Epoch: 6/30... Training loss: 0.0754\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0796\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0765\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0719\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0746\n",
      "Epoch: 6/30... Training loss: 0.0748\n",
      "Epoch: 6/30... Training loss: 0.0798\n",
      "Epoch: 6/30... Training loss: 0.0716\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0789\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 6/30... Training loss: 0.0787\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0790\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0747\n",
      "Epoch: 6/30... Training loss: 0.0786\n",
      "Epoch: 6/30... Training loss: 0.0709\n",
      "Epoch: 6/30... Training loss: 0.0767\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0806\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0751\n",
      "Epoch: 6/30... Training loss: 0.0772\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0734\n",
      "Epoch: 6/30... Training loss: 0.0775\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0726\n",
      "Epoch: 6/30... Training loss: 0.0750\n",
      "Epoch: 6/30... Training loss: 0.0818\n",
      "Epoch: 6/30... Training loss: 0.0745\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0741\n",
      "Epoch: 6/30... Training loss: 0.0729\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0785\n",
      "Epoch: 6/30... Training loss: 0.0759\n",
      "Epoch: 6/30... Training loss: 0.0770\n",
      "Epoch: 6/30... Training loss: 0.0761\n",
      "Epoch: 6/30... Training loss: 0.0797\n",
      "Epoch: 6/30... Training loss: 0.0752\n",
      "Epoch: 6/30... Training loss: 0.0743\n",
      "Epoch: 6/30... Training loss: 0.0766\n",
      "Epoch: 6/30... Training loss: 0.0827\n",
      "Epoch: 6/30... Training loss: 0.0762\n",
      "Epoch: 6/30... Training loss: 0.0847\n",
      "Epoch: 6/30... Training loss: 0.0846\n",
      "Epoch: 6/30... Training loss: 0.0819\n",
      "Epoch: 6/30... Training loss: 0.0736\n",
      "Epoch: 6/30... Training loss: 0.0742\n",
      "Epoch: 6/30... Training loss: 0.0778\n",
      "Epoch: 6/30... Training loss: 0.0755\n",
      "Epoch: 6/30... Training loss: 0.0795\n",
      "Epoch: 6/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0801\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0812\n",
      "Epoch: 7/30... Training loss: 0.0833\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0801\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0808\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0818\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0717\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0690\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0810\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0821\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0717\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0808\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0804\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0681\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0850\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0805\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0701\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0794\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0828\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0713\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0818\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0810\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0681\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0717\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0700\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0816\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0814\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0810\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0801\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0703\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0817\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0801\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0806\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0806\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0711\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0717\n",
      "Epoch: 7/30... Training loss: 0.0694\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0697\n",
      "Epoch: 7/30... Training loss: 0.0832\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0700\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0717\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0840\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0820\n",
      "Epoch: 7/30... Training loss: 0.0711\n",
      "Epoch: 7/30... Training loss: 0.0700\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0810\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0803\n",
      "Epoch: 7/30... Training loss: 0.0705\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0804\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0811\n",
      "Epoch: 7/30... Training loss: 0.0853\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0701\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0825\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0815\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0806\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0713\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0708\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0706\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0712\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0701\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0699\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0697\n",
      "Epoch: 7/30... Training loss: 0.0804\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0709\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0814\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0810\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0689\n",
      "Epoch: 7/30... Training loss: 0.0702\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0690\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0807\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0831\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0802\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0705\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0808\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0705\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0705\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0805\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0804\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0696\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0825\n",
      "Epoch: 7/30... Training loss: 0.0706\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0839\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0811\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0707\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0811\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0829\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0817\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0712\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0813\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0712\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0708\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0717\n",
      "Epoch: 7/30... Training loss: 0.0710\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0829\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0699\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0697\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0706\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/30... Training loss: 0.0809\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0843\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0715\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0806\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0824\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0699\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0710\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0803\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0814\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0717\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0815\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0702\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0808\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0840\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0707\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0712\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0711\n",
      "Epoch: 7/30... Training loss: 0.0810\n",
      "Epoch: 7/30... Training loss: 0.0689\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0821\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0674\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0689\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0709\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0810\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0707\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0806\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0703\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0711\n",
      "Epoch: 7/30... Training loss: 0.0720\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0785\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0806\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0692\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0697\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0707\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0711\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0807\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0811\n",
      "Epoch: 7/30... Training loss: 0.0729\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0726\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0718\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0710\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0659\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0776\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0780\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0719\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0807\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0801\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0800\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0728\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0754\n",
      "Epoch: 7/30... Training loss: 0.0794\n",
      "Epoch: 7/30... Training loss: 0.0782\n",
      "Epoch: 7/30... Training loss: 0.0708\n",
      "Epoch: 7/30... Training loss: 0.0733\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0819\n",
      "Epoch: 7/30... Training loss: 0.0775\n",
      "Epoch: 7/30... Training loss: 0.0744\n",
      "Epoch: 7/30... Training loss: 0.0813\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0809\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0727\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0723\n",
      "Epoch: 7/30... Training loss: 0.0748\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0805\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0791\n",
      "Epoch: 7/30... Training loss: 0.0799\n",
      "Epoch: 7/30... Training loss: 0.0687\n",
      "Epoch: 7/30... Training loss: 0.0746\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0774\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0793\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0721\n",
      "Epoch: 7/30... Training loss: 0.0709\n",
      "Epoch: 7/30... Training loss: 0.0786\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0794\n",
      "Epoch: 7/30... Training loss: 0.0805\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0730\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0703\n",
      "Epoch: 7/30... Training loss: 0.0768\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0814\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0703\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0772\n",
      "Epoch: 7/30... Training loss: 0.0763\n",
      "Epoch: 7/30... Training loss: 0.0783\n",
      "Epoch: 7/30... Training loss: 0.0784\n",
      "Epoch: 7/30... Training loss: 0.0735\n",
      "Epoch: 7/30... Training loss: 0.0761\n",
      "Epoch: 7/30... Training loss: 0.0703\n",
      "Epoch: 7/30... Training loss: 0.0698\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0710\n",
      "Epoch: 7/30... Training loss: 0.0779\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0696\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0798\n",
      "Epoch: 7/30... Training loss: 0.0858\n",
      "Epoch: 7/30... Training loss: 0.0795\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0806\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0716\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0731\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0724\n",
      "Epoch: 7/30... Training loss: 0.0819\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0769\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0790\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0797\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0736\n",
      "Epoch: 7/30... Training loss: 0.0773\n",
      "Epoch: 7/30... Training loss: 0.0764\n",
      "Epoch: 7/30... Training loss: 0.0751\n",
      "Epoch: 7/30... Training loss: 0.0788\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0704\n",
      "Epoch: 7/30... Training loss: 0.0749\n",
      "Epoch: 7/30... Training loss: 0.0778\n",
      "Epoch: 7/30... Training loss: 0.0801\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0755\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0756\n",
      "Epoch: 7/30... Training loss: 0.0750\n",
      "Epoch: 7/30... Training loss: 0.0738\n",
      "Epoch: 7/30... Training loss: 0.0762\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0714\n",
      "Epoch: 7/30... Training loss: 0.0711\n",
      "Epoch: 7/30... Training loss: 0.0777\n",
      "Epoch: 7/30... Training loss: 0.0789\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0705\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/30... Training loss: 0.0805\n",
      "Epoch: 7/30... Training loss: 0.0829\n",
      "Epoch: 7/30... Training loss: 0.0743\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0766\n",
      "Epoch: 7/30... Training loss: 0.0722\n",
      "Epoch: 7/30... Training loss: 0.0725\n",
      "Epoch: 7/30... Training loss: 0.0742\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0734\n",
      "Epoch: 7/30... Training loss: 0.0794\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0758\n",
      "Epoch: 7/30... Training loss: 0.0737\n",
      "Epoch: 7/30... Training loss: 0.0752\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0745\n",
      "Epoch: 7/30... Training loss: 0.0759\n",
      "Epoch: 7/30... Training loss: 0.0739\n",
      "Epoch: 7/30... Training loss: 0.0796\n",
      "Epoch: 7/30... Training loss: 0.0787\n",
      "Epoch: 7/30... Training loss: 0.0740\n",
      "Epoch: 7/30... Training loss: 0.0781\n",
      "Epoch: 7/30... Training loss: 0.0771\n",
      "Epoch: 7/30... Training loss: 0.0770\n",
      "Epoch: 7/30... Training loss: 0.0760\n",
      "Epoch: 7/30... Training loss: 0.0700\n",
      "Epoch: 7/30... Training loss: 0.0753\n",
      "Epoch: 7/30... Training loss: 0.0765\n",
      "Epoch: 7/30... Training loss: 0.0741\n",
      "Epoch: 7/30... Training loss: 0.0747\n",
      "Epoch: 7/30... Training loss: 0.0690\n",
      "Epoch: 7/30... Training loss: 0.0732\n",
      "Epoch: 7/30... Training loss: 0.0792\n",
      "Epoch: 7/30... Training loss: 0.0767\n",
      "Epoch: 7/30... Training loss: 0.0757\n",
      "Epoch: 7/30... Training loss: 0.0814\n",
      "Epoch: 7/30... Training loss: 0.0665\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0698\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0816\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0805\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0792\n",
      "Epoch: 8/30... Training loss: 0.0712\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0821\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0796\n",
      "Epoch: 8/30... Training loss: 0.0795\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0715\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0809\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0702\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0794\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0700\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0826\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0696\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0686\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0688\n",
      "Epoch: 8/30... Training loss: 0.0702\n",
      "Epoch: 8/30... Training loss: 0.0813\n",
      "Epoch: 8/30... Training loss: 0.0796\n",
      "Epoch: 8/30... Training loss: 0.0796\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0707\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0794\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0807\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0712\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0677\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0808\n",
      "Epoch: 8/30... Training loss: 0.0729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0797\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0802\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0804\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0701\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0810\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0693\n",
      "Epoch: 8/30... Training loss: 0.0808\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0790\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0708\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0689\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0708\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0664\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0804\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0805\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0669\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0844\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0686\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0807\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0790\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0803\n",
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0701\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0715\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0696\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0803\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0702\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0794\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0806\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0712\n",
      "Epoch: 8/30... Training loss: 0.0802\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0806\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0805\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0808\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0695\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0798\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0717\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0712\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0691\n",
      "Epoch: 8/30... Training loss: 0.0797\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0804\n",
      "Epoch: 8/30... Training loss: 0.0799\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/30... Training loss: 0.0717\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0794\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0708\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0677\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0818\n",
      "Epoch: 8/30... Training loss: 0.0690\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0692\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0689\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0679\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0799\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0790\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0808\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0803\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0828\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0697\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0796\n",
      "Epoch: 8/30... Training loss: 0.0698\n",
      "Epoch: 8/30... Training loss: 0.0708\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0702\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0814\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0702\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0696\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0808\n",
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0799\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0805\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0698\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0798\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0717\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0700\n",
      "Epoch: 8/30... Training loss: 0.0708\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0820\n",
      "Epoch: 8/30... Training loss: 0.0669\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0702\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0806\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0687\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0696\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0705\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0795\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0701\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0712\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0701\n",
      "Epoch: 8/30... Training loss: 0.0707\n",
      "Epoch: 8/30... Training loss: 0.0835\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0804\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0707\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0689\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0697\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0705\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0797\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0794\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0695\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0812\n",
      "Epoch: 8/30... Training loss: 0.0807\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0801\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0682\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0796\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0789\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0799\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0664\n",
      "Epoch: 8/30... Training loss: 0.0794\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0709\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0679\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0800\n",
      "Epoch: 8/30... Training loss: 0.0799\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0827\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0717\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0715\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0777\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0815\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0702\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0697\n",
      "Epoch: 8/30... Training loss: 0.0797\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0731\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0782\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0760\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0722\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0675\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0725\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0733\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0797\n",
      "Epoch: 8/30... Training loss: 0.0715\n",
      "Epoch: 8/30... Training loss: 0.0808\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0687\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0798\n",
      "Epoch: 8/30... Training loss: 0.0799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0768\n",
      "Epoch: 8/30... Training loss: 0.0718\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0793\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0792\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0694\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0675\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0785\n",
      "Epoch: 8/30... Training loss: 0.0684\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0758\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0784\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0790\n",
      "Epoch: 8/30... Training loss: 0.0795\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0774\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0743\n",
      "Epoch: 8/30... Training loss: 0.0700\n",
      "Epoch: 8/30... Training loss: 0.0765\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0697\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0783\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0796\n",
      "Epoch: 8/30... Training loss: 0.0706\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0761\n",
      "Epoch: 8/30... Training loss: 0.0821\n",
      "Epoch: 8/30... Training loss: 0.0735\n",
      "Epoch: 8/30... Training loss: 0.0720\n",
      "Epoch: 8/30... Training loss: 0.0786\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0780\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0794\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0738\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0807\n",
      "Epoch: 8/30... Training loss: 0.0764\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0748\n",
      "Epoch: 8/30... Training loss: 0.0790\n",
      "Epoch: 8/30... Training loss: 0.0700\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0798\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0773\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0717\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0798\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0716\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0694\n",
      "Epoch: 8/30... Training loss: 0.0744\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0723\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0707\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0736\n",
      "Epoch: 8/30... Training loss: 0.0781\n",
      "Epoch: 8/30... Training loss: 0.0683\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0749\n",
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0737\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0746\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0779\n",
      "Epoch: 8/30... Training loss: 0.0686\n",
      "Epoch: 8/30... Training loss: 0.0750\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0754\n",
      "Epoch: 8/30... Training loss: 0.0693\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0729\n",
      "Epoch: 8/30... Training loss: 0.0699\n",
      "Epoch: 8/30... Training loss: 0.0695\n",
      "Epoch: 8/30... Training loss: 0.0804\n",
      "Epoch: 8/30... Training loss: 0.0710\n",
      "Epoch: 8/30... Training loss: 0.0787\n",
      "Epoch: 8/30... Training loss: 0.0757\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0734\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0763\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0775\n",
      "Epoch: 8/30... Training loss: 0.0714\n",
      "Epoch: 8/30... Training loss: 0.0742\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0690\n",
      "Epoch: 8/30... Training loss: 0.0770\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0796\n",
      "Epoch: 8/30... Training loss: 0.0701\n",
      "Epoch: 8/30... Training loss: 0.0762\n",
      "Epoch: 8/30... Training loss: 0.0771\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0727\n",
      "Epoch: 8/30... Training loss: 0.0769\n",
      "Epoch: 8/30... Training loss: 0.0795\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0697\n",
      "Epoch: 8/30... Training loss: 0.0694\n",
      "Epoch: 8/30... Training loss: 0.0747\n",
      "Epoch: 8/30... Training loss: 0.0670\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0704\n",
      "Epoch: 8/30... Training loss: 0.0753\n",
      "Epoch: 8/30... Training loss: 0.0791\n",
      "Epoch: 8/30... Training loss: 0.0740\n",
      "Epoch: 8/30... Training loss: 0.0792\n",
      "Epoch: 8/30... Training loss: 0.0778\n",
      "Epoch: 8/30... Training loss: 0.0776\n",
      "Epoch: 8/30... Training loss: 0.0759\n",
      "Epoch: 8/30... Training loss: 0.0745\n",
      "Epoch: 8/30... Training loss: 0.0751\n",
      "Epoch: 8/30... Training loss: 0.0711\n",
      "Epoch: 8/30... Training loss: 0.0797\n",
      "Epoch: 8/30... Training loss: 0.0772\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0719\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0730\n",
      "Epoch: 8/30... Training loss: 0.0703\n",
      "Epoch: 8/30... Training loss: 0.0726\n",
      "Epoch: 8/30... Training loss: 0.0721\n",
      "Epoch: 8/30... Training loss: 0.0715\n",
      "Epoch: 8/30... Training loss: 0.0756\n",
      "Epoch: 8/30... Training loss: 0.0728\n",
      "Epoch: 8/30... Training loss: 0.0724\n",
      "Epoch: 8/30... Training loss: 0.0755\n",
      "Epoch: 8/30... Training loss: 0.0767\n",
      "Epoch: 8/30... Training loss: 0.0741\n",
      "Epoch: 8/30... Training loss: 0.0792\n",
      "Epoch: 8/30... Training loss: 0.0739\n",
      "Epoch: 8/30... Training loss: 0.0766\n",
      "Epoch: 8/30... Training loss: 0.0795\n",
      "Epoch: 8/30... Training loss: 0.0788\n",
      "Epoch: 8/30... Training loss: 0.0732\n",
      "Epoch: 8/30... Training loss: 0.0752\n",
      "Epoch: 8/30... Training loss: 0.0713\n",
      "Epoch: 8/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0809\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0787\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0801\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0795\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0806\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0808\n",
      "Epoch: 9/30... Training loss: 0.0687\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0786\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0800\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0691\n",
      "Epoch: 9/30... Training loss: 0.0802\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0698\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0701\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0810\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0816\n",
      "Epoch: 9/30... Training loss: 0.0803\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0695\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0688\n",
      "Epoch: 9/30... Training loss: 0.0796\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0659\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0689\n",
      "Epoch: 9/30... Training loss: 0.0675\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0692\n",
      "Epoch: 9/30... Training loss: 0.0801\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0694\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0796\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0806\n",
      "Epoch: 9/30... Training loss: 0.0797\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0713\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0794\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0809\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0798\n",
      "Epoch: 9/30... Training loss: 0.0791\n",
      "Epoch: 9/30... Training loss: 0.0703\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0698\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0808\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0677\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0816\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0702\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0686\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0702\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0698\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0702\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0807\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0692\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0792\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0698\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0703\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0664\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0688\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0686\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0799\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0815\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0788\n",
      "Epoch: 9/30... Training loss: 0.0693\n",
      "Epoch: 9/30... Training loss: 0.0787\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0798\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0831\n",
      "Epoch: 9/30... Training loss: 0.0787\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0703\n",
      "Epoch: 9/30... Training loss: 0.0691\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0787\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0804\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0680\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0817\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0790\n",
      "Epoch: 9/30... Training loss: 0.0822\n",
      "Epoch: 9/30... Training loss: 0.0692\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0787\n",
      "Epoch: 9/30... Training loss: 0.0695\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0689\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0695\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0699\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0693\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0698\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0805\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0787\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0796\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0790\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0699\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0695\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0698\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0796\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0694\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0793\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0695\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0701\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0689\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0682\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0791\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0701\n",
      "Epoch: 9/30... Training loss: 0.0817\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0819\n",
      "Epoch: 9/30... Training loss: 0.0698\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0713\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0822\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0671\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0673\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0793\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0786\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0702\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0792\n",
      "Epoch: 9/30... Training loss: 0.0799\n",
      "Epoch: 9/30... Training loss: 0.0662\n",
      "Epoch: 9/30... Training loss: 0.0691\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0809\n",
      "Epoch: 9/30... Training loss: 0.0793\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0655\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0802\n",
      "Epoch: 9/30... Training loss: 0.0788\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0703\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0690\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0707\n",
      "Epoch: 9/30... Training loss: 0.0788\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0691\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0778\n",
      "Epoch: 9/30... Training loss: 0.0713\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0667\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0787\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0787\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0695\n",
      "Epoch: 9/30... Training loss: 0.0792\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0687\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0790\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0693\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0701\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0811\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0699\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0790\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0696\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0783\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0812\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0784\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0711\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0701\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0791\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0693\n",
      "Epoch: 9/30... Training loss: 0.0713\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0795\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0679\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0797\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0701\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0700\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0791\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0799\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0767\n",
      "Epoch: 9/30... Training loss: 0.0774\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0746\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0765\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0772\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0695\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0790\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0693\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0727\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0720\n",
      "Epoch: 9/30... Training loss: 0.0786\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0793\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0730\n",
      "Epoch: 9/30... Training loss: 0.0690\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0673\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0758\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0807\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0719\n",
      "Epoch: 9/30... Training loss: 0.0768\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0793\n",
      "Epoch: 9/30... Training loss: 0.0789\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0763\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0796\n",
      "Epoch: 9/30... Training loss: 0.0782\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0776\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0690\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0822\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0799\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0694\n",
      "Epoch: 9/30... Training loss: 0.0770\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0687\n",
      "Epoch: 9/30... Training loss: 0.0741\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0800\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0769\n",
      "Epoch: 9/30... Training loss: 0.0807\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0714\n",
      "Epoch: 9/30... Training loss: 0.0696\n",
      "Epoch: 9/30... Training loss: 0.0777\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0790\n",
      "Epoch: 9/30... Training loss: 0.0724\n",
      "Epoch: 9/30... Training loss: 0.0743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0704\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0739\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0715\n",
      "Epoch: 9/30... Training loss: 0.0742\n",
      "Epoch: 9/30... Training loss: 0.0759\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0744\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0734\n",
      "Epoch: 9/30... Training loss: 0.0726\n",
      "Epoch: 9/30... Training loss: 0.0737\n",
      "Epoch: 9/30... Training loss: 0.0797\n",
      "Epoch: 9/30... Training loss: 0.0735\n",
      "Epoch: 9/30... Training loss: 0.0750\n",
      "Epoch: 9/30... Training loss: 0.0766\n",
      "Epoch: 9/30... Training loss: 0.0773\n",
      "Epoch: 9/30... Training loss: 0.0752\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0757\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0689\n",
      "Epoch: 9/30... Training loss: 0.0705\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0723\n",
      "Epoch: 9/30... Training loss: 0.0755\n",
      "Epoch: 9/30... Training loss: 0.0749\n",
      "Epoch: 9/30... Training loss: 0.0780\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0717\n",
      "Epoch: 9/30... Training loss: 0.0798\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0690\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0691\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0775\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0716\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 9/30... Training loss: 0.0781\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0821\n",
      "Epoch: 9/30... Training loss: 0.0785\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0787\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0810\n",
      "Epoch: 9/30... Training loss: 0.0740\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0731\n",
      "Epoch: 9/30... Training loss: 0.0747\n",
      "Epoch: 9/30... Training loss: 0.0736\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0760\n",
      "Epoch: 9/30... Training loss: 0.0703\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0696\n",
      "Epoch: 9/30... Training loss: 0.0706\n",
      "Epoch: 9/30... Training loss: 0.0690\n",
      "Epoch: 9/30... Training loss: 0.0779\n",
      "Epoch: 9/30... Training loss: 0.0697\n",
      "Epoch: 9/30... Training loss: 0.0762\n",
      "Epoch: 9/30... Training loss: 0.0691\n",
      "Epoch: 9/30... Training loss: 0.0748\n",
      "Epoch: 9/30... Training loss: 0.0738\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0796\n",
      "Epoch: 9/30... Training loss: 0.0733\n",
      "Epoch: 9/30... Training loss: 0.0797\n",
      "Epoch: 9/30... Training loss: 0.0756\n",
      "Epoch: 9/30... Training loss: 0.0732\n",
      "Epoch: 9/30... Training loss: 0.0692\n",
      "Epoch: 9/30... Training loss: 0.0710\n",
      "Epoch: 9/30... Training loss: 0.0718\n",
      "Epoch: 9/30... Training loss: 0.0751\n",
      "Epoch: 9/30... Training loss: 0.0693\n",
      "Epoch: 9/30... Training loss: 0.0753\n",
      "Epoch: 9/30... Training loss: 0.0709\n",
      "Epoch: 9/30... Training loss: 0.0729\n",
      "Epoch: 9/30... Training loss: 0.0761\n",
      "Epoch: 9/30... Training loss: 0.0712\n",
      "Epoch: 9/30... Training loss: 0.0745\n",
      "Epoch: 9/30... Training loss: 0.0743\n",
      "Epoch: 9/30... Training loss: 0.0771\n",
      "Epoch: 9/30... Training loss: 0.0728\n",
      "Epoch: 9/30... Training loss: 0.0708\n",
      "Epoch: 9/30... Training loss: 0.0812\n",
      "Epoch: 9/30... Training loss: 0.0722\n",
      "Epoch: 9/30... Training loss: 0.0754\n",
      "Epoch: 9/30... Training loss: 0.0721\n",
      "Epoch: 9/30... Training loss: 0.0725\n",
      "Epoch: 9/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0668\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0799\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0687\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0797\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0781\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0792\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0803\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0781\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0711\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0711\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0673\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0789\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0778\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0805\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0785\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0790\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0786\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0806\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0796\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0788\n",
      "Epoch: 10/30... Training loss: 0.0832\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0700\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0789\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0693\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0683\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0673\n",
      "Epoch: 10/30... Training loss: 0.0804\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0693\n",
      "Epoch: 10/30... Training loss: 0.0798\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0693\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0711\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0686\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0799\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0686\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0695\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0790\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0794\n",
      "Epoch: 10/30... Training loss: 0.0795\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0691\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0791\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0683\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0801\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0704\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0806\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0688\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0696\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0788\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0695\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0693\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0696\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0704\n",
      "Epoch: 10/30... Training loss: 0.0685\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0688\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0802\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0684\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0778\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0786\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0711\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0676\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0703\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0679\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0786\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0675\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0700\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0795\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0804\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0798\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0649\n",
      "Epoch: 10/30... Training loss: 0.0687\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0700\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0794\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0788\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0794\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0687\n",
      "Epoch: 10/30... Training loss: 0.0785\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0831\n",
      "Epoch: 10/30... Training loss: 0.0790\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0791\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0781\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0794\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0685\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0686\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0678\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0666\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0697\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0789\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0689\n",
      "Epoch: 10/30... Training loss: 0.0802\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0804\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0704\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0785\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0678\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0802\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0806\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0778\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0687\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0800\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0809\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0795\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0790\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0703\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0794\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0707\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0817\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0798\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0792\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0801\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0775\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0685\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0790\n",
      "Epoch: 10/30... Training loss: 0.0795\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0700\n",
      "Epoch: 10/30... Training loss: 0.0674\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0711\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0691\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0782\n",
      "Epoch: 10/30... Training loss: 0.0711\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0739\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0792\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0705\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0811\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0781\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0685\n",
      "Epoch: 10/30... Training loss: 0.0667\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0696\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0695\n",
      "Epoch: 10/30... Training loss: 0.0697\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0682\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0667\n",
      "Epoch: 10/30... Training loss: 0.0764\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0788\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0760\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0718\n",
      "Epoch: 10/30... Training loss: 0.0680\n",
      "Epoch: 10/30... Training loss: 0.0671\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0711\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0685\n",
      "Epoch: 10/30... Training loss: 0.0695\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0719\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0800\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0667\n",
      "Epoch: 10/30... Training loss: 0.0703\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0758\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0708\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0783\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0789\n",
      "Epoch: 10/30... Training loss: 0.0805\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0697\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0721\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0725\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0713\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0690\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0686\n",
      "Epoch: 10/30... Training loss: 0.0716\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0801\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0767\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0781\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0715\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0771\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0697\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0717\n",
      "Epoch: 10/30... Training loss: 0.0784\n",
      "Epoch: 10/30... Training loss: 0.0749\n",
      "Epoch: 10/30... Training loss: 0.0782\n",
      "Epoch: 10/30... Training loss: 0.0780\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0735\n",
      "Epoch: 10/30... Training loss: 0.0791\n",
      "Epoch: 10/30... Training loss: 0.0798\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0694\n",
      "Epoch: 10/30... Training loss: 0.0704\n",
      "Epoch: 10/30... Training loss: 0.0754\n",
      "Epoch: 10/30... Training loss: 0.0774\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0768\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0701\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0704\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0730\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0709\n",
      "Epoch: 10/30... Training loss: 0.0698\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0729\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0665\n",
      "Epoch: 10/30... Training loss: 0.0746\n",
      "Epoch: 10/30... Training loss: 0.0736\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0770\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0763\n",
      "Epoch: 10/30... Training loss: 0.0662\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/30... Training loss: 0.0726\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0699\n",
      "Epoch: 10/30... Training loss: 0.0765\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0756\n",
      "Epoch: 10/30... Training loss: 0.0703\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0793\n",
      "Epoch: 10/30... Training loss: 0.0777\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0732\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0778\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0733\n",
      "Epoch: 10/30... Training loss: 0.0779\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0797\n",
      "Epoch: 10/30... Training loss: 0.0675\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0753\n",
      "Epoch: 10/30... Training loss: 0.0714\n",
      "Epoch: 10/30... Training loss: 0.0734\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0742\n",
      "Epoch: 10/30... Training loss: 0.0755\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0678\n",
      "Epoch: 10/30... Training loss: 0.0728\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0747\n",
      "Epoch: 10/30... Training loss: 0.0722\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0769\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0740\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0759\n",
      "Epoch: 10/30... Training loss: 0.0744\n",
      "Epoch: 10/30... Training loss: 0.0761\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0773\n",
      "Epoch: 10/30... Training loss: 0.0752\n",
      "Epoch: 10/30... Training loss: 0.0766\n",
      "Epoch: 10/30... Training loss: 0.0724\n",
      "Epoch: 10/30... Training loss: 0.0703\n",
      "Epoch: 10/30... Training loss: 0.0745\n",
      "Epoch: 10/30... Training loss: 0.0743\n",
      "Epoch: 10/30... Training loss: 0.0710\n",
      "Epoch: 10/30... Training loss: 0.0776\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0750\n",
      "Epoch: 10/30... Training loss: 0.0738\n",
      "Epoch: 10/30... Training loss: 0.0741\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0801\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0797\n",
      "Epoch: 10/30... Training loss: 0.0737\n",
      "Epoch: 10/30... Training loss: 0.0814\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0785\n",
      "Epoch: 10/30... Training loss: 0.0706\n",
      "Epoch: 10/30... Training loss: 0.0712\n",
      "Epoch: 10/30... Training loss: 0.0751\n",
      "Epoch: 10/30... Training loss: 0.0800\n",
      "Epoch: 10/30... Training loss: 0.0702\n",
      "Epoch: 10/30... Training loss: 0.0785\n",
      "Epoch: 10/30... Training loss: 0.0675\n",
      "Epoch: 10/30... Training loss: 0.0731\n",
      "Epoch: 10/30... Training loss: 0.0793\n",
      "Epoch: 10/30... Training loss: 0.0720\n",
      "Epoch: 10/30... Training loss: 0.0800\n",
      "Epoch: 10/30... Training loss: 0.0727\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0782\n",
      "Epoch: 10/30... Training loss: 0.0772\n",
      "Epoch: 10/30... Training loss: 0.0762\n",
      "Epoch: 10/30... Training loss: 0.0748\n",
      "Epoch: 10/30... Training loss: 0.0723\n",
      "Epoch: 10/30... Training loss: 0.0692\n",
      "Epoch: 10/30... Training loss: 0.0757\n",
      "Epoch: 10/30... Training loss: 0.0787\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0700\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0681\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0686\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0697\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0689\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0767\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0684\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0673\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0799\n",
      "Epoch: 11/30... Training loss: 0.0789\n",
      "Epoch: 11/30... Training loss: 0.0793\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0789\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0780\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0704\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0691\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0685\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0792\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0669\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0688\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0795\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0678\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0691\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0686\n",
      "Epoch: 11/30... Training loss: 0.0678\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0825\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0689\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0780\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0789\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0695\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0767\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0700\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0697\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0801\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0785\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0794\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0795\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0767\n",
      "Epoch: 11/30... Training loss: 0.0782\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0793\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0789\n",
      "Epoch: 11/30... Training loss: 0.0685\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0704\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0686\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0677\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0700\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0684\n",
      "Epoch: 11/30... Training loss: 0.0700\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0698\n",
      "Epoch: 11/30... Training loss: 0.0816\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0774\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0789\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0807\n",
      "Epoch: 11/30... Training loss: 0.0805\n",
      "Epoch: 11/30... Training loss: 0.0737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0782\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0784\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0805\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0667\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0783\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0791\n",
      "Epoch: 11/30... Training loss: 0.0680\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0691\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0798\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0807\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0783\n",
      "Epoch: 11/30... Training loss: 0.0796\n",
      "Epoch: 11/30... Training loss: 0.0780\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0686\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0780\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0677\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0689\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0783\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0670\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0785\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0660\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0767\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0682\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0790\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0795\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0767\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0700\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0682\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0695\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0790\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0814\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0689\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0677\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0784\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0829\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0785\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0686\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0792\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0695\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0797\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0794\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0780\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0691\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0678\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0686\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0688\n",
      "Epoch: 11/30... Training loss: 0.0792\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0774\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0782\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0778\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0792\n",
      "Epoch: 11/30... Training loss: 0.0677\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0692\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0682\n",
      "Epoch: 11/30... Training loss: 0.0782\n",
      "Epoch: 11/30... Training loss: 0.0796\n",
      "Epoch: 11/30... Training loss: 0.0753\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0687\n",
      "Epoch: 11/30... Training loss: 0.0834\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0786\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0827\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0803\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0802\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0681\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0700\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0688\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0791\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0668\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0733\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0784\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0678\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0767\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0784\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0666\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0746\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0774\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0663\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0690\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0668\n",
      "Epoch: 11/30... Training loss: 0.0655\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0692\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0805\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0789\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0667\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0707\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0757\n",
      "Epoch: 11/30... Training loss: 0.0795\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0764\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0755\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0715\n",
      "Epoch: 11/30... Training loss: 0.0845\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0769\n",
      "Epoch: 11/30... Training loss: 0.0696\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0770\n",
      "Epoch: 11/30... Training loss: 0.0771\n",
      "Epoch: 11/30... Training loss: 0.0791\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0698\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0766\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0695\n",
      "Epoch: 11/30... Training loss: 0.0805\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0706\n",
      "Epoch: 11/30... Training loss: 0.0782\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0767\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0719\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0791\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0704\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0702\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0779\n",
      "Epoch: 11/30... Training loss: 0.0701\n",
      "Epoch: 11/30... Training loss: 0.0688\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0762\n",
      "Epoch: 11/30... Training loss: 0.0747\n",
      "Epoch: 11/30... Training loss: 0.0777\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0782\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0714\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0775\n",
      "Epoch: 11/30... Training loss: 0.0765\n",
      "Epoch: 11/30... Training loss: 0.0718\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0737\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0758\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0703\n",
      "Epoch: 11/30... Training loss: 0.0808\n",
      "Epoch: 11/30... Training loss: 0.0721\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0794\n",
      "Epoch: 11/30... Training loss: 0.0700\n",
      "Epoch: 11/30... Training loss: 0.0697\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0699\n",
      "Epoch: 11/30... Training loss: 0.0740\n",
      "Epoch: 11/30... Training loss: 0.0781\n",
      "Epoch: 11/30... Training loss: 0.0727\n",
      "Epoch: 11/30... Training loss: 0.0785\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0725\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0692\n",
      "Epoch: 11/30... Training loss: 0.0666\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0788\n",
      "Epoch: 11/30... Training loss: 0.0663\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0724\n",
      "Epoch: 11/30... Training loss: 0.0720\n",
      "Epoch: 11/30... Training loss: 0.0736\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0723\n",
      "Epoch: 11/30... Training loss: 0.0695\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0722\n",
      "Epoch: 11/30... Training loss: 0.0732\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0760\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0734\n",
      "Epoch: 11/30... Training loss: 0.0708\n",
      "Epoch: 11/30... Training loss: 0.0772\n",
      "Epoch: 11/30... Training loss: 0.0700\n",
      "Epoch: 11/30... Training loss: 0.0749\n",
      "Epoch: 11/30... Training loss: 0.0768\n",
      "Epoch: 11/30... Training loss: 0.0759\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0728\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0739\n",
      "Epoch: 11/30... Training loss: 0.0748\n",
      "Epoch: 11/30... Training loss: 0.0752\n",
      "Epoch: 11/30... Training loss: 0.0709\n",
      "Epoch: 11/30... Training loss: 0.0774\n",
      "Epoch: 11/30... Training loss: 0.0814\n",
      "Epoch: 11/30... Training loss: 0.0691\n",
      "Epoch: 11/30... Training loss: 0.0711\n",
      "Epoch: 11/30... Training loss: 0.0717\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0741\n",
      "Epoch: 11/30... Training loss: 0.0730\n",
      "Epoch: 11/30... Training loss: 0.0751\n",
      "Epoch: 11/30... Training loss: 0.0686\n",
      "Epoch: 11/30... Training loss: 0.0743\n",
      "Epoch: 11/30... Training loss: 0.0794\n",
      "Epoch: 11/30... Training loss: 0.0790\n",
      "Epoch: 11/30... Training loss: 0.0773\n",
      "Epoch: 11/30... Training loss: 0.0693\n",
      "Epoch: 11/30... Training loss: 0.0705\n",
      "Epoch: 11/30... Training loss: 0.0776\n",
      "Epoch: 11/30... Training loss: 0.0754\n",
      "Epoch: 11/30... Training loss: 0.0756\n",
      "Epoch: 11/30... Training loss: 0.0744\n",
      "Epoch: 11/30... Training loss: 0.0686\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0729\n",
      "Epoch: 11/30... Training loss: 0.0805\n",
      "Epoch: 11/30... Training loss: 0.0742\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0731\n",
      "Epoch: 11/30... Training loss: 0.0710\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0790\n",
      "Epoch: 11/30... Training loss: 0.0738\n",
      "Epoch: 11/30... Training loss: 0.0774\n",
      "Epoch: 11/30... Training loss: 0.0713\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0761\n",
      "Epoch: 11/30... Training loss: 0.0694\n",
      "Epoch: 11/30... Training loss: 0.0726\n",
      "Epoch: 11/30... Training loss: 0.0735\n",
      "Epoch: 11/30... Training loss: 0.0716\n",
      "Epoch: 11/30... Training loss: 0.0745\n",
      "Epoch: 11/30... Training loss: 0.0750\n",
      "Epoch: 11/30... Training loss: 0.0763\n",
      "Epoch: 11/30... Training loss: 0.0728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/30... Training loss: 0.0712\n",
      "Epoch: 11/30... Training loss: 0.0798\n",
      "Epoch: 11/30... Training loss: 0.0681\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0782\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0695\n",
      "Epoch: 12/30... Training loss: 0.0670\n",
      "Epoch: 12/30... Training loss: 0.0694\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0788\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0782\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0674\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0678\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0687\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0688\n",
      "Epoch: 12/30... Training loss: 0.0786\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0800\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0678\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0785\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0686\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0787\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0684\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0688\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0783\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0791\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0659\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0651\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0675\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0790\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0680\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0810\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0695\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0784\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0796\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0678\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0781\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0784\n",
      "Epoch: 12/30... Training loss: 0.0810\n",
      "Epoch: 12/30... Training loss: 0.0785\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0793\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0782\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0659\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0845\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0681\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0782\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0686\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0689\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0686\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0794\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0678\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0689\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0695\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0683\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0679\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0674\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0794\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0689\n",
      "Epoch: 12/30... Training loss: 0.0641\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0676\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0666\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0683\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0794\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0664\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0801\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0781\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0694\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0690\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0794\n",
      "Epoch: 12/30... Training loss: 0.0788\n",
      "Epoch: 12/30... Training loss: 0.0794\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0783\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0801\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0798\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0786\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0790\n",
      "Epoch: 12/30... Training loss: 0.0781\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0782\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0786\n",
      "Epoch: 12/30... Training loss: 0.0685\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0804\n",
      "Epoch: 12/30... Training loss: 0.0783\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0790\n",
      "Epoch: 12/30... Training loss: 0.0644\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0785\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0802\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0655\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0671\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0660\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0692\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0664\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0781\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0789\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0676\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0794\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0676\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0777\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0666\n",
      "Epoch: 12/30... Training loss: 0.0689\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0694\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0687\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0809\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0698\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0644\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0786\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0799\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0675\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0789\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0797\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0791\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0798\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0790\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0681\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0793\n",
      "Epoch: 12/30... Training loss: 0.0795\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0682\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0798\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0790\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0681\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0791\n",
      "Epoch: 12/30... Training loss: 0.0686\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0682\n",
      "Epoch: 12/30... Training loss: 0.0785\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0684\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0803\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0704\n",
      "Epoch: 12/30... Training loss: 0.0761\n",
      "Epoch: 12/30... Training loss: 0.0743\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0787\n",
      "Epoch: 12/30... Training loss: 0.0772\n",
      "Epoch: 12/30... Training loss: 0.0795\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0681\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0711\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0685\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0774\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0791\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0788\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0807\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0792\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0685\n",
      "Epoch: 12/30... Training loss: 0.0764\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0688\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0725\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0759\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0688\n",
      "Epoch: 12/30... Training loss: 0.0700\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0786\n",
      "Epoch: 12/30... Training loss: 0.0808\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0792\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0736\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0778\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0781\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0754\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0689\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0762\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0800\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0750\n",
      "Epoch: 12/30... Training loss: 0.0802\n",
      "Epoch: 12/30... Training loss: 0.0691\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0746\n",
      "Epoch: 12/30... Training loss: 0.0720\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0795\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0771\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0729\n",
      "Epoch: 12/30... Training loss: 0.0694\n",
      "Epoch: 12/30... Training loss: 0.0791\n",
      "Epoch: 12/30... Training loss: 0.0716\n",
      "Epoch: 12/30... Training loss: 0.0760\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0695\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0785\n",
      "Epoch: 12/30... Training loss: 0.0705\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0707\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0727\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0706\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0752\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0688\n",
      "Epoch: 12/30... Training loss: 0.0732\n",
      "Epoch: 12/30... Training loss: 0.0713\n",
      "Epoch: 12/30... Training loss: 0.0686\n",
      "Epoch: 12/30... Training loss: 0.0709\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0719\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0766\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0718\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0794\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0738\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0739\n",
      "Epoch: 12/30... Training loss: 0.0769\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0708\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0798\n",
      "Epoch: 12/30... Training loss: 0.0675\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0723\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0763\n",
      "Epoch: 12/30... Training loss: 0.0668\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0733\n",
      "Epoch: 12/30... Training loss: 0.0756\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0735\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0701\n",
      "Epoch: 12/30... Training loss: 0.0702\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0779\n",
      "Epoch: 12/30... Training loss: 0.0721\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0724\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0751\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0728\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0710\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0768\n",
      "Epoch: 12/30... Training loss: 0.0758\n",
      "Epoch: 12/30... Training loss: 0.0722\n",
      "Epoch: 12/30... Training loss: 0.0742\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0699\n",
      "Epoch: 12/30... Training loss: 0.0767\n",
      "Epoch: 12/30... Training loss: 0.0679\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0741\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0696\n",
      "Epoch: 12/30... Training loss: 0.0689\n",
      "Epoch: 12/30... Training loss: 0.0734\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0686\n",
      "Epoch: 12/30... Training loss: 0.0697\n",
      "Epoch: 12/30... Training loss: 0.0770\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0747\n",
      "Epoch: 12/30... Training loss: 0.0755\n",
      "Epoch: 12/30... Training loss: 0.0714\n",
      "Epoch: 12/30... Training loss: 0.0744\n",
      "Epoch: 12/30... Training loss: 0.0780\n",
      "Epoch: 12/30... Training loss: 0.0726\n",
      "Epoch: 12/30... Training loss: 0.0749\n",
      "Epoch: 12/30... Training loss: 0.0775\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0773\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0731\n",
      "Epoch: 12/30... Training loss: 0.0730\n",
      "Epoch: 12/30... Training loss: 0.0765\n",
      "Epoch: 12/30... Training loss: 0.0757\n",
      "Epoch: 12/30... Training loss: 0.0776\n",
      "Epoch: 12/30... Training loss: 0.0692\n",
      "Epoch: 12/30... Training loss: 0.0781\n",
      "Epoch: 12/30... Training loss: 0.0688\n",
      "Epoch: 12/30... Training loss: 0.0693\n",
      "Epoch: 12/30... Training loss: 0.0715\n",
      "Epoch: 12/30... Training loss: 0.0717\n",
      "Epoch: 12/30... Training loss: 0.0789\n",
      "Epoch: 12/30... Training loss: 0.0703\n",
      "Epoch: 12/30... Training loss: 0.0748\n",
      "Epoch: 12/30... Training loss: 0.0737\n",
      "Epoch: 12/30... Training loss: 0.0695\n",
      "Epoch: 12/30... Training loss: 0.0753\n",
      "Epoch: 12/30... Training loss: 0.0745\n",
      "Epoch: 12/30... Training loss: 0.0740\n",
      "Epoch: 12/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0685\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0783\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0797\n",
      "Epoch: 13/30... Training loss: 0.0685\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0667\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0783\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0772\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0688\n",
      "Epoch: 13/30... Training loss: 0.0693\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0674\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0668\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0789\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0694\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0779\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0676\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0688\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0683\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0788\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0790\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0783\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0694\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0787\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0772\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0798\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0774\n",
      "Epoch: 13/30... Training loss: 0.0694\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0777\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0799\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0784\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0682\n",
      "Epoch: 13/30... Training loss: 0.0678\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0679\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0786\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0820\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0782\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0686\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0699\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0686\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0680\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0671\n",
      "Epoch: 13/30... Training loss: 0.0795\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0781\n",
      "Epoch: 13/30... Training loss: 0.0684\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0777\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0681\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0792\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0684\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0676\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0789\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0810\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0687\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0787\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0777\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0781\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0779\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0794\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0795\n",
      "Epoch: 13/30... Training loss: 0.0783\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0780\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0668\n",
      "Epoch: 13/30... Training loss: 0.0694\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0810\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0772\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0679\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0665\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0824\n",
      "Epoch: 13/30... Training loss: 0.0782\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0655\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0779\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0778\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0675\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0783\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0688\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0682\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0687\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0801\n",
      "Epoch: 13/30... Training loss: 0.0772\n",
      "Epoch: 13/30... Training loss: 0.0785\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0678\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0684\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0791\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0782\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0780\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0779\n",
      "Epoch: 13/30... Training loss: 0.0671\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0694\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0793\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0788\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0780\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0686\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0785\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0680\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0796\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0777\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0778\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0792\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0777\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0697\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0777\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0685\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0693\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0794\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0784\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0693\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0778\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0693\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0781\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0798\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0796\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0668\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0777\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0675\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0681\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0669\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0775\n",
      "Epoch: 13/30... Training loss: 0.0787\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0682\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0774\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0661\n",
      "Epoch: 13/30... Training loss: 0.0681\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0686\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0708\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0772\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0784\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0780\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0783\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0780\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0664\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0664\n",
      "Epoch: 13/30... Training loss: 0.0673\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0689\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0811\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0788\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0762\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0787\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0688\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0786\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0678\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0694\n",
      "Epoch: 13/30... Training loss: 0.0781\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0679\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0772\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0692\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0668\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0756\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0776\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0742\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0699\n",
      "Epoch: 13/30... Training loss: 0.0683\n",
      "Epoch: 13/30... Training loss: 0.0772\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0799\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0711\n",
      "Epoch: 13/30... Training loss: 0.0785\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0672\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0771\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0801\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0701\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0728\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0741\n",
      "Epoch: 13/30... Training loss: 0.0781\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0770\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0717\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0715\n",
      "Epoch: 13/30... Training loss: 0.0705\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0791\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0779\n",
      "Epoch: 13/30... Training loss: 0.0716\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0767\n",
      "Epoch: 13/30... Training loss: 0.0757\n",
      "Epoch: 13/30... Training loss: 0.0791\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0740\n",
      "Epoch: 13/30... Training loss: 0.0794\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0781\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0704\n",
      "Epoch: 13/30... Training loss: 0.0696\n",
      "Epoch: 13/30... Training loss: 0.0795\n",
      "Epoch: 13/30... Training loss: 0.0673\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0754\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0781\n",
      "Epoch: 13/30... Training loss: 0.0765\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0773\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0774\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0796\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0722\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0710\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0736\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0687\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0723\n",
      "Epoch: 13/30... Training loss: 0.0782\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0695\n",
      "Epoch: 13/30... Training loss: 0.0719\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0733\n",
      "Epoch: 13/30... Training loss: 0.0805\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0693\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0706\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0769\n",
      "Epoch: 13/30... Training loss: 0.0700\n",
      "Epoch: 13/30... Training loss: 0.0788\n",
      "Epoch: 13/30... Training loss: 0.0753\n",
      "Epoch: 13/30... Training loss: 0.0734\n",
      "Epoch: 13/30... Training loss: 0.0763\n",
      "Epoch: 13/30... Training loss: 0.0680\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0703\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0750\n",
      "Epoch: 13/30... Training loss: 0.0727\n",
      "Epoch: 13/30... Training loss: 0.0755\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0725\n",
      "Epoch: 13/30... Training loss: 0.0749\n",
      "Epoch: 13/30... Training loss: 0.0718\n",
      "Epoch: 13/30... Training loss: 0.0786\n",
      "Epoch: 13/30... Training loss: 0.0772\n",
      "Epoch: 13/30... Training loss: 0.0738\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0746\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0744\n",
      "Epoch: 13/30... Training loss: 0.0689\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0764\n",
      "Epoch: 13/30... Training loss: 0.0778\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0761\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0777\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0751\n",
      "Epoch: 13/30... Training loss: 0.0788\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0712\n",
      "Epoch: 13/30... Training loss: 0.0691\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0713\n",
      "Epoch: 13/30... Training loss: 0.0745\n",
      "Epoch: 13/30... Training loss: 0.0720\n",
      "Epoch: 13/30... Training loss: 0.0735\n",
      "Epoch: 13/30... Training loss: 0.0739\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0666\n",
      "Epoch: 13/30... Training loss: 0.0806\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0690\n",
      "Epoch: 13/30... Training loss: 0.0707\n",
      "Epoch: 13/30... Training loss: 0.0724\n",
      "Epoch: 13/30... Training loss: 0.0684\n",
      "Epoch: 13/30... Training loss: 0.0732\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 13/30... Training loss: 0.0801\n",
      "Epoch: 13/30... Training loss: 0.0743\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0748\n",
      "Epoch: 13/30... Training loss: 0.0721\n",
      "Epoch: 13/30... Training loss: 0.0758\n",
      "Epoch: 13/30... Training loss: 0.0729\n",
      "Epoch: 13/30... Training loss: 0.0759\n",
      "Epoch: 13/30... Training loss: 0.0731\n",
      "Epoch: 13/30... Training loss: 0.0777\n",
      "Epoch: 13/30... Training loss: 0.0747\n",
      "Epoch: 13/30... Training loss: 0.0760\n",
      "Epoch: 13/30... Training loss: 0.0787\n",
      "Epoch: 13/30... Training loss: 0.0702\n",
      "Epoch: 13/30... Training loss: 0.0714\n",
      "Epoch: 13/30... Training loss: 0.0709\n",
      "Epoch: 13/30... Training loss: 0.0768\n",
      "Epoch: 13/30... Training loss: 0.0752\n",
      "Epoch: 13/30... Training loss: 0.0766\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0666\n",
      "Epoch: 13/30... Training loss: 0.0698\n",
      "Epoch: 13/30... Training loss: 0.0730\n",
      "Epoch: 13/30... Training loss: 0.0737\n",
      "Epoch: 13/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0801\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0781\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0662\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0793\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0777\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0784\n",
      "Epoch: 14/30... Training loss: 0.0778\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0683\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0685\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0684\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0691\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0678\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0778\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0793\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0692\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0790\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0692\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0794\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0790\n",
      "Epoch: 14/30... Training loss: 0.0776\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0678\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0772\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0782\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0693\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0686\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0788\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0777\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0786\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0776\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0686\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0691\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0679\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0693\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0696\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0782\n",
      "Epoch: 14/30... Training loss: 0.0787\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0688\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0689\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0811\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0810\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0796\n",
      "Epoch: 14/30... Training loss: 0.0688\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0775\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0789\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0783\n",
      "Epoch: 14/30... Training loss: 0.0806\n",
      "Epoch: 14/30... Training loss: 0.0779\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0688\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0687\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0796\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/30... Training loss: 0.0683\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0657\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0784\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0783\n",
      "Epoch: 14/30... Training loss: 0.0798\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0775\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0687\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0696\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0691\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0781\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0672\n",
      "Epoch: 14/30... Training loss: 0.0692\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0680\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0665\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0690\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0776\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0805\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0775\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0795\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0680\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0673\n",
      "Epoch: 14/30... Training loss: 0.0794\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0683\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0684\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0694\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0678\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0779\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0793\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0789\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0775\n",
      "Epoch: 14/30... Training loss: 0.0693\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0671\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0659\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0690\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0791\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0786\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0685\n",
      "Epoch: 14/30... Training loss: 0.0653\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0792\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0809\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0661\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0783\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0687\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0678\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0791\n",
      "Epoch: 14/30... Training loss: 0.0784\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0791\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0797\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0681\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0687\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0812\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0675\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0677\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0772\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0669\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0778\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0780\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0684\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0691\n",
      "Epoch: 14/30... Training loss: 0.0675\n",
      "Epoch: 14/30... Training loss: 0.0766\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0790\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0675\n",
      "Epoch: 14/30... Training loss: 0.0790\n",
      "Epoch: 14/30... Training loss: 0.0776\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0676\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0792\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0781\n",
      "Epoch: 14/30... Training loss: 0.0722\n",
      "Epoch: 14/30... Training loss: 0.0678\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0806\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0778\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0782\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0683\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0669\n",
      "Epoch: 14/30... Training loss: 0.0696\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0726\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0812\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0788\n",
      "Epoch: 14/30... Training loss: 0.0788\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0675\n",
      "Epoch: 14/30... Training loss: 0.0713\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0758\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0787\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0669\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0792\n",
      "Epoch: 14/30... Training loss: 0.0785\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0676\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0760\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0787\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0779\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0687\n",
      "Epoch: 14/30... Training loss: 0.0686\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0782\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0792\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0775\n",
      "Epoch: 14/30... Training loss: 0.0685\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0779\n",
      "Epoch: 14/30... Training loss: 0.0703\n",
      "Epoch: 14/30... Training loss: 0.0798\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0708\n",
      "Epoch: 14/30... Training loss: 0.0690\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0693\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0689\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0791\n",
      "Epoch: 14/30... Training loss: 0.0787\n",
      "Epoch: 14/30... Training loss: 0.0720\n",
      "Epoch: 14/30... Training loss: 0.0723\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0778\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0801\n",
      "Epoch: 14/30... Training loss: 0.0696\n",
      "Epoch: 14/30... Training loss: 0.0699\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0678\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0762\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0732\n",
      "Epoch: 14/30... Training loss: 0.0744\n",
      "Epoch: 14/30... Training loss: 0.0683\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0773\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0728\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0693\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0767\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0765\n",
      "Epoch: 14/30... Training loss: 0.0772\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0783\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0684\n",
      "Epoch: 14/30... Training loss: 0.0730\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0751\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0748\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0698\n",
      "Epoch: 14/30... Training loss: 0.0735\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0749\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0763\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0702\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0740\n",
      "Epoch: 14/30... Training loss: 0.0706\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0729\n",
      "Epoch: 14/30... Training loss: 0.0798\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0701\n",
      "Epoch: 14/30... Training loss: 0.0715\n",
      "Epoch: 14/30... Training loss: 0.0711\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0788\n",
      "Epoch: 14/30... Training loss: 0.0695\n",
      "Epoch: 14/30... Training loss: 0.0774\n",
      "Epoch: 14/30... Training loss: 0.0721\n",
      "Epoch: 14/30... Training loss: 0.0742\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0674\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0745\n",
      "Epoch: 14/30... Training loss: 0.0753\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0741\n",
      "Epoch: 14/30... Training loss: 0.0792\n",
      "Epoch: 14/30... Training loss: 0.0764\n",
      "Epoch: 14/30... Training loss: 0.0719\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0731\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0756\n",
      "Epoch: 14/30... Training loss: 0.0783\n",
      "Epoch: 14/30... Training loss: 0.0769\n",
      "Epoch: 14/30... Training loss: 0.0776\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0779\n",
      "Epoch: 14/30... Training loss: 0.0761\n",
      "Epoch: 14/30... Training loss: 0.0717\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0733\n",
      "Epoch: 14/30... Training loss: 0.0759\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0757\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0738\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0734\n",
      "Epoch: 14/30... Training loss: 0.0787\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0697\n",
      "Epoch: 14/30... Training loss: 0.0750\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0712\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0771\n",
      "Epoch: 14/30... Training loss: 0.0707\n",
      "Epoch: 14/30... Training loss: 0.0788\n",
      "Epoch: 14/30... Training loss: 0.0754\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0737\n",
      "Epoch: 14/30... Training loss: 0.0791\n",
      "Epoch: 14/30... Training loss: 0.0724\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0755\n",
      "Epoch: 14/30... Training loss: 0.0739\n",
      "Epoch: 14/30... Training loss: 0.0727\n",
      "Epoch: 14/30... Training loss: 0.0704\n",
      "Epoch: 14/30... Training loss: 0.0709\n",
      "Epoch: 14/30... Training loss: 0.0705\n",
      "Epoch: 14/30... Training loss: 0.0710\n",
      "Epoch: 14/30... Training loss: 0.0746\n",
      "Epoch: 14/30... Training loss: 0.0747\n",
      "Epoch: 14/30... Training loss: 0.0700\n",
      "Epoch: 14/30... Training loss: 0.0716\n",
      "Epoch: 14/30... Training loss: 0.0743\n",
      "Epoch: 14/30... Training loss: 0.0725\n",
      "Epoch: 14/30... Training loss: 0.0768\n",
      "Epoch: 14/30... Training loss: 0.0752\n",
      "Epoch: 14/30... Training loss: 0.0718\n",
      "Epoch: 14/30... Training loss: 0.0736\n",
      "Epoch: 14/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0775\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0767\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0777\n",
      "Epoch: 15/30... Training loss: 0.0682\n",
      "Epoch: 15/30... Training loss: 0.0813\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0673\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0691\n",
      "Epoch: 15/30... Training loss: 0.0686\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0686\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0776\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0678\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0689\n",
      "Epoch: 15/30... Training loss: 0.0767\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0783\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0658\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0673\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0681\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0783\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0689\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0783\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0779\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0685\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0689\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0672\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0816\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0795\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0775\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0791\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0689\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0790\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0815\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0767\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0785\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0781\n",
      "Epoch: 15/30... Training loss: 0.0786\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0783\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0792\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0686\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0767\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0670\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0778\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0671\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0681\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0677\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0671\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0695\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0785\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0776\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0786\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0784\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0785\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0798\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0674\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0683\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0785\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0794\n",
      "Epoch: 15/30... Training loss: 0.0670\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0792\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0672\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0767\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0777\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0669\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0681\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0781\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0689\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0780\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0775\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0798\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0778\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0677\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0791\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0678\n",
      "Epoch: 15/30... Training loss: 0.0669\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0786\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0677\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0779\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0778\n",
      "Epoch: 15/30... Training loss: 0.0767\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0663\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0809\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0776\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0777\n",
      "Epoch: 15/30... Training loss: 0.0671\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0787\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0783\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0788\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0684\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0706\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0777\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0790\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0788\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0785\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0677\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0680\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0767\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0787\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0685\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0668\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0789\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0685\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0767\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0800\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0782\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0691\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0776\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0707\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0711\n",
      "Epoch: 15/30... Training loss: 0.0689\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0776\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0675\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0724\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0775\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0679\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0802\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0778\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0660\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0785\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0710\n",
      "Epoch: 15/30... Training loss: 0.0685\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0679\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0672\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0691\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0683\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0678\n",
      "Epoch: 15/30... Training loss: 0.0784\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0687\n",
      "Epoch: 15/30... Training loss: 0.0797\n",
      "Epoch: 15/30... Training loss: 0.0740\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0800\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0801\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0684\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0682\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0774\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0688\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0739\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0701\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0778\n",
      "Epoch: 15/30... Training loss: 0.0759\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0772\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0763\n",
      "Epoch: 15/30... Training loss: 0.0713\n",
      "Epoch: 15/30... Training loss: 0.0672\n",
      "Epoch: 15/30... Training loss: 0.0766\n",
      "Epoch: 15/30... Training loss: 0.0691\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0685\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0752\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0748\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0767\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0718\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0785\n",
      "Epoch: 15/30... Training loss: 0.0734\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0694\n",
      "Epoch: 15/30... Training loss: 0.0692\n",
      "Epoch: 15/30... Training loss: 0.0781\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0762\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0683\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0779\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0725\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0720\n",
      "Epoch: 15/30... Training loss: 0.0712\n",
      "Epoch: 15/30... Training loss: 0.0777\n",
      "Epoch: 15/30... Training loss: 0.0757\n",
      "Epoch: 15/30... Training loss: 0.0699\n",
      "Epoch: 15/30... Training loss: 0.0747\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0768\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0773\n",
      "Epoch: 15/30... Training loss: 0.0709\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0684\n",
      "Epoch: 15/30... Training loss: 0.0777\n",
      "Epoch: 15/30... Training loss: 0.0758\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0737\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0770\n",
      "Epoch: 15/30... Training loss: 0.0787\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0691\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0760\n",
      "Epoch: 15/30... Training loss: 0.0727\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0728\n",
      "Epoch: 15/30... Training loss: 0.0741\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0722\n",
      "Epoch: 15/30... Training loss: 0.0784\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0793\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0717\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0736\n",
      "Epoch: 15/30... Training loss: 0.0730\n",
      "Epoch: 15/30... Training loss: 0.0683\n",
      "Epoch: 15/30... Training loss: 0.0705\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0698\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0702\n",
      "Epoch: 15/30... Training loss: 0.0677\n",
      "Epoch: 15/30... Training loss: 0.0784\n",
      "Epoch: 15/30... Training loss: 0.0756\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0696\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0749\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0684\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0690\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0721\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0715\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0777\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0792\n",
      "Epoch: 15/30... Training loss: 0.0799\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0764\n",
      "Epoch: 15/30... Training loss: 0.0723\n",
      "Epoch: 15/30... Training loss: 0.0732\n",
      "Epoch: 15/30... Training loss: 0.0681\n",
      "Epoch: 15/30... Training loss: 0.0769\n",
      "Epoch: 15/30... Training loss: 0.0700\n",
      "Epoch: 15/30... Training loss: 0.0795\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0708\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0731\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0744\n",
      "Epoch: 15/30... Training loss: 0.0750\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0781\n",
      "Epoch: 15/30... Training loss: 0.0735\n",
      "Epoch: 15/30... Training loss: 0.0751\n",
      "Epoch: 15/30... Training loss: 0.0697\n",
      "Epoch: 15/30... Training loss: 0.0771\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 15/30... Training loss: 0.0745\n",
      "Epoch: 15/30... Training loss: 0.0754\n",
      "Epoch: 15/30... Training loss: 0.0733\n",
      "Epoch: 15/30... Training loss: 0.0704\n",
      "Epoch: 15/30... Training loss: 0.0667\n",
      "Epoch: 15/30... Training loss: 0.0761\n",
      "Epoch: 15/30... Training loss: 0.0743\n",
      "Epoch: 15/30... Training loss: 0.0738\n",
      "Epoch: 15/30... Training loss: 0.0726\n",
      "Epoch: 15/30... Training loss: 0.0714\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0755\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0693\n",
      "Epoch: 15/30... Training loss: 0.0753\n",
      "Epoch: 15/30... Training loss: 0.0716\n",
      "Epoch: 15/30... Training loss: 0.0719\n",
      "Epoch: 15/30... Training loss: 0.0729\n",
      "Epoch: 15/30... Training loss: 0.0746\n",
      "Epoch: 15/30... Training loss: 0.0680\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0742\n",
      "Epoch: 15/30... Training loss: 0.0703\n",
      "Epoch: 15/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0788\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0801\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0788\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0676\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0664\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0645\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0779\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0797\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0679\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0785\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0775\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0673\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0689\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0680\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0775\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0673\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0800\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0781\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0689\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0676\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0678\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0676\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0683\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0831\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0778\n",
      "Epoch: 16/30... Training loss: 0.0788\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0668\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0794\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0689\n",
      "Epoch: 16/30... Training loss: 0.0790\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0664\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0694\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0664\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0687\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0681\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0670\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0776\n",
      "Epoch: 16/30... Training loss: 0.0804\n",
      "Epoch: 16/30... Training loss: 0.0680\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0695\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0669\n",
      "Epoch: 16/30... Training loss: 0.0684\n",
      "Epoch: 16/30... Training loss: 0.0660\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0694\n",
      "Epoch: 16/30... Training loss: 0.0785\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0810\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0786\n",
      "Epoch: 16/30... Training loss: 0.0810\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0781\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0679\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0778\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0680\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0694\n",
      "Epoch: 16/30... Training loss: 0.0776\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0775\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0783\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0799\n",
      "Epoch: 16/30... Training loss: 0.0687\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0779\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0672\n",
      "Epoch: 16/30... Training loss: 0.0694\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0679\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0780\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0778\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0676\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0681\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0778\n",
      "Epoch: 16/30... Training loss: 0.0695\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0695\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0693\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0783\n",
      "Epoch: 16/30... Training loss: 0.0792\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0780\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0778\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0682\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0653\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0792\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0791\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0776\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0838\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0677\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0645\n",
      "Epoch: 16/30... Training loss: 0.0784\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0695\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0791\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0668\n",
      "Epoch: 16/30... Training loss: 0.0680\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0667\n",
      "Epoch: 16/30... Training loss: 0.0775\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0782\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0754\n",
      "Epoch: 16/30... Training loss: 0.0799\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0678\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0682\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0690\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0695\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0778\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0776\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0688\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0788\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0783\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0675\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0669\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0682\n",
      "Epoch: 16/30... Training loss: 0.0792\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0677\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0781\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0782\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0683\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0661\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0693\n",
      "Epoch: 16/30... Training loss: 0.0674\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0770\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0646\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0769\n",
      "Epoch: 16/30... Training loss: 0.0694\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0771\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0689\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0783\n",
      "Epoch: 16/30... Training loss: 0.0760\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0802\n",
      "Epoch: 16/30... Training loss: 0.0799\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0671\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0714\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0684\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0798\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0681\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0680\n",
      "Epoch: 16/30... Training loss: 0.0695\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0784\n",
      "Epoch: 16/30... Training loss: 0.0774\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0737\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0678\n",
      "Epoch: 16/30... Training loss: 0.0799\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0717\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0783\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0750\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0694\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0767\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0790\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0709\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/30... Training loss: 0.0808\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0746\n",
      "Epoch: 16/30... Training loss: 0.0807\n",
      "Epoch: 16/30... Training loss: 0.0723\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0683\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0808\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0710\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0700\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0801\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0711\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0704\n",
      "Epoch: 16/30... Training loss: 0.0724\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0718\n",
      "Epoch: 16/30... Training loss: 0.0692\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0719\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0734\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0739\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0740\n",
      "Epoch: 16/30... Training loss: 0.0748\n",
      "Epoch: 16/30... Training loss: 0.0749\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0738\n",
      "Epoch: 16/30... Training loss: 0.0665\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0665\n",
      "Epoch: 16/30... Training loss: 0.0757\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0703\n",
      "Epoch: 16/30... Training loss: 0.0691\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0777\n",
      "Epoch: 16/30... Training loss: 0.0815\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0773\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0728\n",
      "Epoch: 16/30... Training loss: 0.0726\n",
      "Epoch: 16/30... Training loss: 0.0729\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0758\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0730\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0756\n",
      "Epoch: 16/30... Training loss: 0.0764\n",
      "Epoch: 16/30... Training loss: 0.0671\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0768\n",
      "Epoch: 16/30... Training loss: 0.0762\n",
      "Epoch: 16/30... Training loss: 0.0696\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0712\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0720\n",
      "Epoch: 16/30... Training loss: 0.0672\n",
      "Epoch: 16/30... Training loss: 0.0722\n",
      "Epoch: 16/30... Training loss: 0.0685\n",
      "Epoch: 16/30... Training loss: 0.0686\n",
      "Epoch: 16/30... Training loss: 0.0699\n",
      "Epoch: 16/30... Training loss: 0.0735\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0732\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0753\n",
      "Epoch: 16/30... Training loss: 0.0716\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0752\n",
      "Epoch: 16/30... Training loss: 0.0742\n",
      "Epoch: 16/30... Training loss: 0.0759\n",
      "Epoch: 16/30... Training loss: 0.0727\n",
      "Epoch: 16/30... Training loss: 0.0708\n",
      "Epoch: 16/30... Training loss: 0.0779\n",
      "Epoch: 16/30... Training loss: 0.0707\n",
      "Epoch: 16/30... Training loss: 0.0713\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0755\n",
      "Epoch: 16/30... Training loss: 0.0679\n",
      "Epoch: 16/30... Training loss: 0.0701\n",
      "Epoch: 16/30... Training loss: 0.0731\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0702\n",
      "Epoch: 16/30... Training loss: 0.0761\n",
      "Epoch: 16/30... Training loss: 0.0772\n",
      "Epoch: 16/30... Training loss: 0.0715\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0697\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0743\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0741\n",
      "Epoch: 16/30... Training loss: 0.0744\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0736\n",
      "Epoch: 16/30... Training loss: 0.0706\n",
      "Epoch: 16/30... Training loss: 0.0751\n",
      "Epoch: 16/30... Training loss: 0.0794\n",
      "Epoch: 16/30... Training loss: 0.0673\n",
      "Epoch: 16/30... Training loss: 0.0733\n",
      "Epoch: 16/30... Training loss: 0.0721\n",
      "Epoch: 16/30... Training loss: 0.0745\n",
      "Epoch: 16/30... Training loss: 0.0786\n",
      "Epoch: 16/30... Training loss: 0.0698\n",
      "Epoch: 16/30... Training loss: 0.0747\n",
      "Epoch: 16/30... Training loss: 0.0763\n",
      "Epoch: 16/30... Training loss: 0.0791\n",
      "Epoch: 16/30... Training loss: 0.0766\n",
      "Epoch: 16/30... Training loss: 0.0705\n",
      "Epoch: 16/30... Training loss: 0.0687\n",
      "Epoch: 16/30... Training loss: 0.0725\n",
      "Epoch: 16/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0795\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0782\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0678\n",
      "Epoch: 17/30... Training loss: 0.0687\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0813\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0658\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0663\n",
      "Epoch: 17/30... Training loss: 0.0778\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0832\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0679\n",
      "Epoch: 17/30... Training loss: 0.0688\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0794\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0691\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0682\n",
      "Epoch: 17/30... Training loss: 0.0681\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0684\n",
      "Epoch: 17/30... Training loss: 0.0783\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0785\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0691\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0687\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0676\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0686\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0791\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0787\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0677\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0667\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0665\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0691\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0790\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0677\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0683\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0682\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0777\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0803\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0689\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0670\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0684\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0681\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0784\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0689\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0681\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0786\n",
      "Epoch: 17/30... Training loss: 0.0779\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0669\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0680\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0667\n",
      "Epoch: 17/30... Training loss: 0.0781\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0669\n",
      "Epoch: 17/30... Training loss: 0.0729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0795\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0663\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0804\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0803\n",
      "Epoch: 17/30... Training loss: 0.0673\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0673\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0680\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0800\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0699\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0683\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0782\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0790\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0775\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0684\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0678\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0672\n",
      "Epoch: 17/30... Training loss: 0.0684\n",
      "Epoch: 17/30... Training loss: 0.0797\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0820\n",
      "Epoch: 17/30... Training loss: 0.0684\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0798\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0828\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0781\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0661\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0789\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0683\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0684\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0790\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0678\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0682\n",
      "Epoch: 17/30... Training loss: 0.0818\n",
      "Epoch: 17/30... Training loss: 0.0651\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/30... Training loss: 0.0791\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0812\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0664\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0853\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0780\n",
      "Epoch: 17/30... Training loss: 0.0793\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0779\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0684\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0793\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0658\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0765\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0678\n",
      "Epoch: 17/30... Training loss: 0.0802\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0791\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0699\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0649\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0775\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0691\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0792\n",
      "Epoch: 17/30... Training loss: 0.0781\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0786\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0764\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0819\n",
      "Epoch: 17/30... Training loss: 0.0786\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0787\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0678\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0691\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0773\n",
      "Epoch: 17/30... Training loss: 0.0781\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0665\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0687\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0688\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0787\n",
      "Epoch: 17/30... Training loss: 0.0689\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0696\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0686\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0660\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0809\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0796\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0677\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0665\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0796\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0689\n",
      "Epoch: 17/30... Training loss: 0.0786\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0763\n",
      "Epoch: 17/30... Training loss: 0.0680\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0730\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0701\n",
      "Epoch: 17/30... Training loss: 0.0788\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0692\n",
      "Epoch: 17/30... Training loss: 0.0680\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0687\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0678\n",
      "Epoch: 17/30... Training loss: 0.0746\n",
      "Epoch: 17/30... Training loss: 0.0685\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0709\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0668\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0781\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0729\n",
      "Epoch: 17/30... Training loss: 0.0722\n",
      "Epoch: 17/30... Training loss: 0.0786\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0776\n",
      "Epoch: 17/30... Training loss: 0.0807\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0749\n",
      "Epoch: 17/30... Training loss: 0.0690\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0699\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0704\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0771\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0737\n",
      "Epoch: 17/30... Training loss: 0.0735\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0702\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0673\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0767\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0718\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0741\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0752\n",
      "Epoch: 17/30... Training loss: 0.0673\n",
      "Epoch: 17/30... Training loss: 0.0739\n",
      "Epoch: 17/30... Training loss: 0.0790\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0756\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0734\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0717\n",
      "Epoch: 17/30... Training loss: 0.0708\n",
      "Epoch: 17/30... Training loss: 0.0724\n",
      "Epoch: 17/30... Training loss: 0.0699\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0755\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0695\n",
      "Epoch: 17/30... Training loss: 0.0738\n",
      "Epoch: 17/30... Training loss: 0.0710\n",
      "Epoch: 17/30... Training loss: 0.0797\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0713\n",
      "Epoch: 17/30... Training loss: 0.0774\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0744\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0698\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0714\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0775\n",
      "Epoch: 17/30... Training loss: 0.0748\n",
      "Epoch: 17/30... Training loss: 0.0761\n",
      "Epoch: 17/30... Training loss: 0.0754\n",
      "Epoch: 17/30... Training loss: 0.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/30... Training loss: 0.0699\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0769\n",
      "Epoch: 17/30... Training loss: 0.0723\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0751\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0757\n",
      "Epoch: 17/30... Training loss: 0.0770\n",
      "Epoch: 17/30... Training loss: 0.0689\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0743\n",
      "Epoch: 17/30... Training loss: 0.0703\n",
      "Epoch: 17/30... Training loss: 0.0705\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0727\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0760\n",
      "Epoch: 17/30... Training loss: 0.0728\n",
      "Epoch: 17/30... Training loss: 0.0716\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0779\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0725\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0693\n",
      "Epoch: 17/30... Training loss: 0.0711\n",
      "Epoch: 17/30... Training loss: 0.0745\n",
      "Epoch: 17/30... Training loss: 0.0700\n",
      "Epoch: 17/30... Training loss: 0.0747\n",
      "Epoch: 17/30... Training loss: 0.0719\n",
      "Epoch: 17/30... Training loss: 0.0720\n",
      "Epoch: 17/30... Training loss: 0.0776\n",
      "Epoch: 17/30... Training loss: 0.0726\n",
      "Epoch: 17/30... Training loss: 0.0750\n",
      "Epoch: 17/30... Training loss: 0.0742\n",
      "Epoch: 17/30... Training loss: 0.0740\n",
      "Epoch: 17/30... Training loss: 0.0715\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0707\n",
      "Epoch: 17/30... Training loss: 0.0732\n",
      "Epoch: 17/30... Training loss: 0.0775\n",
      "Epoch: 17/30... Training loss: 0.0694\n",
      "Epoch: 17/30... Training loss: 0.0766\n",
      "Epoch: 17/30... Training loss: 0.0753\n",
      "Epoch: 17/30... Training loss: 0.0706\n",
      "Epoch: 17/30... Training loss: 0.0736\n",
      "Epoch: 17/30... Training loss: 0.0731\n",
      "Epoch: 17/30... Training loss: 0.0677\n",
      "Epoch: 17/30... Training loss: 0.0762\n",
      "Epoch: 17/30... Training loss: 0.0733\n",
      "Epoch: 17/30... Training loss: 0.0772\n",
      "Epoch: 17/30... Training loss: 0.0758\n",
      "Epoch: 17/30... Training loss: 0.0679\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0768\n",
      "Epoch: 17/30... Training loss: 0.0759\n",
      "Epoch: 17/30... Training loss: 0.0721\n",
      "Epoch: 17/30... Training loss: 0.0712\n",
      "Epoch: 17/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0645\n",
      "Epoch: 18/30... Training loss: 0.0675\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0791\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0769\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0784\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0664\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0784\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0779\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0810\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0683\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0788\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0692\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0772\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0775\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0667\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0633\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0780\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0684\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0671\n",
      "Epoch: 18/30... Training loss: 0.0676\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0692\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0769\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0793\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0790\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0683\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0771\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0684\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0773\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0689\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0773\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0780\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0793\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0686\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0666\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0669\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0775\n",
      "Epoch: 18/30... Training loss: 0.0810\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0688\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0688\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0773\n",
      "Epoch: 18/30... Training loss: 0.0681\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0655\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0682\n",
      "Epoch: 18/30... Training loss: 0.0778\n",
      "Epoch: 18/30... Training loss: 0.0783\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0690\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0692\n",
      "Epoch: 18/30... Training loss: 0.0779\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0658\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0790\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0669\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0786\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0784\n",
      "Epoch: 18/30... Training loss: 0.0769\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0787\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0681\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0671\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0772\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0802\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0776\n",
      "Epoch: 18/30... Training loss: 0.0667\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0791\n",
      "Epoch: 18/30... Training loss: 0.0652\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0779\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0674\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0805\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0666\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0787\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0682\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0675\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0686\n",
      "Epoch: 18/30... Training loss: 0.0769\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0683\n",
      "Epoch: 18/30... Training loss: 0.0783\n",
      "Epoch: 18/30... Training loss: 0.0790\n",
      "Epoch: 18/30... Training loss: 0.0684\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0772\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0681\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0779\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0661\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0684\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0692\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0683\n",
      "Epoch: 18/30... Training loss: 0.0780\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0778\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0783\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0803\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0691\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0668\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0686\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0676\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0686\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0656\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0675\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0669\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0781\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0683\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0664\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0806\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0789\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0686\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0782\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0680\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0798\n",
      "Epoch: 18/30... Training loss: 0.0686\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0664\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0785\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0756\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0791\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0778\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0657\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0797\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0691\n",
      "Epoch: 18/30... Training loss: 0.0660\n",
      "Epoch: 18/30... Training loss: 0.0649\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0741\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0785\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0771\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0678\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0785\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0775\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0775\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0691\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0685\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0685\n",
      "Epoch: 18/30... Training loss: 0.0772\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0786\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0786\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0771\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0782\n",
      "Epoch: 18/30... Training loss: 0.0721\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0709\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0694\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0785\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0744\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0762\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0680\n",
      "Epoch: 18/30... Training loss: 0.0773\n",
      "Epoch: 18/30... Training loss: 0.0699\n",
      "Epoch: 18/30... Training loss: 0.0689\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0679\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0680\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0697\n",
      "Epoch: 18/30... Training loss: 0.0754\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0710\n",
      "Epoch: 18/30... Training loss: 0.0681\n",
      "Epoch: 18/30... Training loss: 0.0746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0690\n",
      "Epoch: 18/30... Training loss: 0.0771\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0753\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0711\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0688\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0687\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0684\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0662\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0676\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0705\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0683\n",
      "Epoch: 18/30... Training loss: 0.0748\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0682\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0779\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0760\n",
      "Epoch: 18/30... Training loss: 0.0735\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0771\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0764\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0714\n",
      "Epoch: 18/30... Training loss: 0.0740\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0767\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0733\n",
      "Epoch: 18/30... Training loss: 0.0787\n",
      "Epoch: 18/30... Training loss: 0.0766\n",
      "Epoch: 18/30... Training loss: 0.0777\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0715\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0771\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0771\n",
      "Epoch: 18/30... Training loss: 0.0669\n",
      "Epoch: 18/30... Training loss: 0.0727\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0716\n",
      "Epoch: 18/30... Training loss: 0.0751\n",
      "Epoch: 18/30... Training loss: 0.0806\n",
      "Epoch: 18/30... Training loss: 0.0684\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0758\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0794\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0670\n",
      "Epoch: 18/30... Training loss: 0.0698\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0808\n",
      "Epoch: 18/30... Training loss: 0.0747\n",
      "Epoch: 18/30... Training loss: 0.0720\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0746\n",
      "Epoch: 18/30... Training loss: 0.0755\n",
      "Epoch: 18/30... Training loss: 0.0786\n",
      "Epoch: 18/30... Training loss: 0.0734\n",
      "Epoch: 18/30... Training loss: 0.0693\n",
      "Epoch: 18/30... Training loss: 0.0704\n",
      "Epoch: 18/30... Training loss: 0.0783\n",
      "Epoch: 18/30... Training loss: 0.0759\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0689\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0792\n",
      "Epoch: 18/30... Training loss: 0.0742\n",
      "Epoch: 18/30... Training loss: 0.0707\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0779\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0712\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0708\n",
      "Epoch: 18/30... Training loss: 0.0812\n",
      "Epoch: 18/30... Training loss: 0.0725\n",
      "Epoch: 18/30... Training loss: 0.0702\n",
      "Epoch: 18/30... Training loss: 0.0787\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0797\n",
      "Epoch: 18/30... Training loss: 0.0681\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0701\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0695\n",
      "Epoch: 18/30... Training loss: 0.0726\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0737\n",
      "Epoch: 18/30... Training loss: 0.0700\n",
      "Epoch: 18/30... Training loss: 0.0739\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0728\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0696\n",
      "Epoch: 18/30... Training loss: 0.0717\n",
      "Epoch: 18/30... Training loss: 0.0722\n",
      "Epoch: 18/30... Training loss: 0.0680\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0723\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0773\n",
      "Epoch: 18/30... Training loss: 0.0703\n",
      "Epoch: 18/30... Training loss: 0.0736\n",
      "Epoch: 18/30... Training loss: 0.0719\n",
      "Epoch: 18/30... Training loss: 0.0761\n",
      "Epoch: 18/30... Training loss: 0.0780\n",
      "Epoch: 18/30... Training loss: 0.0729\n",
      "Epoch: 18/30... Training loss: 0.0825\n",
      "Epoch: 18/30... Training loss: 0.0743\n",
      "Epoch: 18/30... Training loss: 0.0706\n",
      "Epoch: 18/30... Training loss: 0.0768\n",
      "Epoch: 18/30... Training loss: 0.0770\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0677\n",
      "Epoch: 18/30... Training loss: 0.0730\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0763\n",
      "Epoch: 18/30... Training loss: 0.0689\n",
      "Epoch: 18/30... Training loss: 0.0774\n",
      "Epoch: 18/30... Training loss: 0.0731\n",
      "Epoch: 18/30... Training loss: 0.0718\n",
      "Epoch: 18/30... Training loss: 0.0773\n",
      "Epoch: 18/30... Training loss: 0.0752\n",
      "Epoch: 18/30... Training loss: 0.0750\n",
      "Epoch: 18/30... Training loss: 0.0816\n",
      "Epoch: 18/30... Training loss: 0.0732\n",
      "Epoch: 18/30... Training loss: 0.0749\n",
      "Epoch: 18/30... Training loss: 0.0765\n",
      "Epoch: 18/30... Training loss: 0.0713\n",
      "Epoch: 18/30... Training loss: 0.0686\n",
      "Epoch: 18/30... Training loss: 0.0738\n",
      "Epoch: 18/30... Training loss: 0.0724\n",
      "Epoch: 18/30... Training loss: 0.0757\n",
      "Epoch: 18/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0681\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0685\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0661\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0785\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0786\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0652\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0780\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0801\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0784\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0625\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0774\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0693\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0682\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0772\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0662\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0685\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0776\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0675\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0809\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0784\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0690\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0792\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0678\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0642\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0776\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0791\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0766\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0783\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0771\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0777\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0682\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0657\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0781\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0786\n",
      "Epoch: 19/30... Training loss: 0.0783\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0777\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0766\n",
      "Epoch: 19/30... Training loss: 0.0693\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0799\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0784\n",
      "Epoch: 19/30... Training loss: 0.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0689\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0778\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0772\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0777\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0826\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0680\n",
      "Epoch: 19/30... Training loss: 0.0779\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0771\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0681\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0810\n",
      "Epoch: 19/30... Training loss: 0.0782\n",
      "Epoch: 19/30... Training loss: 0.0797\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0682\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0685\n",
      "Epoch: 19/30... Training loss: 0.0766\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0673\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0676\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0781\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0774\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0766\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0656\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0829\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0675\n",
      "Epoch: 19/30... Training loss: 0.0693\n",
      "Epoch: 19/30... Training loss: 0.0772\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0662\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0786\n",
      "Epoch: 19/30... Training loss: 0.0687\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0785\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0774\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0651\n",
      "Epoch: 19/30... Training loss: 0.0674\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0673\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0670\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0782\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0671\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0679\n",
      "Epoch: 19/30... Training loss: 0.0690\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0810\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0689\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0673\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0779\n",
      "Epoch: 19/30... Training loss: 0.0754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0788\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0655\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0777\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0800\n",
      "Epoch: 19/30... Training loss: 0.0778\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0684\n",
      "Epoch: 19/30... Training loss: 0.0788\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0793\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0662\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0766\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0783\n",
      "Epoch: 19/30... Training loss: 0.0684\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0795\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0777\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0781\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0774\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0678\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0781\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0689\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0694\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0776\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0685\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0693\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0770\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0800\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0690\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0643\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0786\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0692\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0672\n",
      "Epoch: 19/30... Training loss: 0.0682\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0700\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0798\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0812\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0664\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0771\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0776\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0772\n",
      "Epoch: 19/30... Training loss: 0.0780\n",
      "Epoch: 19/30... Training loss: 0.0654\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0669\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0664\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0683\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0772\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0662\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0678\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0776\n",
      "Epoch: 19/30... Training loss: 0.0696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/30... Training loss: 0.0750\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0764\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0781\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0793\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0668\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0681\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0802\n",
      "Epoch: 19/30... Training loss: 0.0780\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0691\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0770\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0782\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0689\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0680\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0788\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0786\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0779\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0775\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0749\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0772\n",
      "Epoch: 19/30... Training loss: 0.0721\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0780\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0733\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0787\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0767\n",
      "Epoch: 19/30... Training loss: 0.0779\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0646\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0778\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0718\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0778\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0688\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0751\n",
      "Epoch: 19/30... Training loss: 0.0678\n",
      "Epoch: 19/30... Training loss: 0.0685\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0656\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0790\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0695\n",
      "Epoch: 19/30... Training loss: 0.0763\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0687\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0738\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0671\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0699\n",
      "Epoch: 19/30... Training loss: 0.0757\n",
      "Epoch: 19/30... Training loss: 0.0673\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0708\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0698\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0687\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0675\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0783\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0716\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0756\n",
      "Epoch: 19/30... Training loss: 0.0705\n",
      "Epoch: 19/30... Training loss: 0.0752\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0697\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0744\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0783\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0690\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0677\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0740\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0743\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0709\n",
      "Epoch: 19/30... Training loss: 0.0677\n",
      "Epoch: 19/30... Training loss: 0.0701\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0693\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0717\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0769\n",
      "Epoch: 19/30... Training loss: 0.0711\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0784\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0753\n",
      "Epoch: 19/30... Training loss: 0.0755\n",
      "Epoch: 19/30... Training loss: 0.0770\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0706\n",
      "Epoch: 19/30... Training loss: 0.0761\n",
      "Epoch: 19/30... Training loss: 0.0726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0768\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0713\n",
      "Epoch: 19/30... Training loss: 0.0754\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0759\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0758\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0680\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0732\n",
      "Epoch: 19/30... Training loss: 0.0723\n",
      "Epoch: 19/30... Training loss: 0.0822\n",
      "Epoch: 19/30... Training loss: 0.0704\n",
      "Epoch: 19/30... Training loss: 0.0748\n",
      "Epoch: 19/30... Training loss: 0.0728\n",
      "Epoch: 19/30... Training loss: 0.0774\n",
      "Epoch: 19/30... Training loss: 0.0760\n",
      "Epoch: 19/30... Training loss: 0.0773\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0741\n",
      "Epoch: 19/30... Training loss: 0.0686\n",
      "Epoch: 19/30... Training loss: 0.0765\n",
      "Epoch: 19/30... Training loss: 0.0747\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0737\n",
      "Epoch: 19/30... Training loss: 0.0739\n",
      "Epoch: 19/30... Training loss: 0.0745\n",
      "Epoch: 19/30... Training loss: 0.0734\n",
      "Epoch: 19/30... Training loss: 0.0710\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0712\n",
      "Epoch: 19/30... Training loss: 0.0797\n",
      "Epoch: 19/30... Training loss: 0.0742\n",
      "Epoch: 19/30... Training loss: 0.0652\n",
      "Epoch: 19/30... Training loss: 0.0762\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0696\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0725\n",
      "Epoch: 19/30... Training loss: 0.0731\n",
      "Epoch: 19/30... Training loss: 0.0680\n",
      "Epoch: 19/30... Training loss: 0.0726\n",
      "Epoch: 19/30... Training loss: 0.0653\n",
      "Epoch: 19/30... Training loss: 0.0746\n",
      "Epoch: 19/30... Training loss: 0.0703\n",
      "Epoch: 19/30... Training loss: 0.0702\n",
      "Epoch: 19/30... Training loss: 0.0722\n",
      "Epoch: 19/30... Training loss: 0.0724\n",
      "Epoch: 19/30... Training loss: 0.0786\n",
      "Epoch: 19/30... Training loss: 0.0729\n",
      "Epoch: 19/30... Training loss: 0.0707\n",
      "Epoch: 19/30... Training loss: 0.0667\n",
      "Epoch: 19/30... Training loss: 0.0730\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0727\n",
      "Epoch: 19/30... Training loss: 0.0735\n",
      "Epoch: 19/30... Training loss: 0.0736\n",
      "Epoch: 19/30... Training loss: 0.0714\n",
      "Epoch: 19/30... Training loss: 0.0720\n",
      "Epoch: 19/30... Training loss: 0.0715\n",
      "Epoch: 19/30... Training loss: 0.0719\n",
      "Epoch: 19/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0677\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0686\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0677\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0791\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0688\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0686\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0771\n",
      "Epoch: 20/30... Training loss: 0.0687\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0643\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0798\n",
      "Epoch: 20/30... Training loss: 0.0677\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0786\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0687\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0673\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0670\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0666\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0816\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0791\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0779\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0678\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0776\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0772\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0780\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0658\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0776\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0780\n",
      "Epoch: 20/30... Training loss: 0.0667\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0775\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0682\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0677\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0682\n",
      "Epoch: 20/30... Training loss: 0.0684\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0673\n",
      "Epoch: 20/30... Training loss: 0.0684\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0669\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0674\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0670\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0779\n",
      "Epoch: 20/30... Training loss: 0.0679\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0766\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0789\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0803\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0766\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0800\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0679\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0684\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0690\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0641\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0687\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0678\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0788\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0673\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0772\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0690\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0779\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0664\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0786\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0777\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0668\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0766\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0785\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0784\n",
      "Epoch: 20/30... Training loss: 0.0657\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0652\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0695\n",
      "Epoch: 20/30... Training loss: 0.0749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0825\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0650\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0679\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0781\n",
      "Epoch: 20/30... Training loss: 0.0788\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0676\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0668\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0683\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0777\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0776\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0690\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0671\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0683\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0792\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0821\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0783\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0659\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0779\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0766\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0778\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0799\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0790\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0782\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0780\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0660\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0662\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0798\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0681\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0687\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0790\n",
      "Epoch: 20/30... Training loss: 0.0682\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0682\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0674\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0679\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0662\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0674\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0807\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0788\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0688\n",
      "Epoch: 20/30... Training loss: 0.0796\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0811\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0681\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0782\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0669\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0675\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0794\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0691\n",
      "Epoch: 20/30... Training loss: 0.0690\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0690\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0728\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0684\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0658\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0683\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0773\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0786\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0803\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0787\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0778\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0666\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0780\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0772\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0749\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0748\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0777\n",
      "Epoch: 20/30... Training loss: 0.0683\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0780\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0783\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0771\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0683\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0780\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0689\n",
      "Epoch: 20/30... Training loss: 0.0685\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0709\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0705\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0787\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0687\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0740\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0670\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0675\n",
      "Epoch: 20/30... Training loss: 0.0764\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0698\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0770\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0707\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0719\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0666\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0690\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0722\n",
      "Epoch: 20/30... Training loss: 0.0711\n",
      "Epoch: 20/30... Training loss: 0.0697\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0739\n",
      "Epoch: 20/30... Training loss: 0.0763\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0776\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0677\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0700\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0720\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0758\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0745\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0729\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0755\n",
      "Epoch: 20/30... Training loss: 0.0688\n",
      "Epoch: 20/30... Training loss: 0.0715\n",
      "Epoch: 20/30... Training loss: 0.0682\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0687\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0744\n",
      "Epoch: 20/30... Training loss: 0.0734\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0704\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0757\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0789\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0743\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0730\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0751\n",
      "Epoch: 20/30... Training loss: 0.0753\n",
      "Epoch: 20/30... Training loss: 0.0765\n",
      "Epoch: 20/30... Training loss: 0.0701\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0732\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0703\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0682\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0777\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0718\n",
      "Epoch: 20/30... Training loss: 0.0746\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0680\n",
      "Epoch: 20/30... Training loss: 0.0712\n",
      "Epoch: 20/30... Training loss: 0.0710\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 20/30... Training loss: 0.0759\n",
      "Epoch: 20/30... Training loss: 0.0714\n",
      "Epoch: 20/30... Training loss: 0.0762\n",
      "Epoch: 20/30... Training loss: 0.0774\n",
      "Epoch: 20/30... Training loss: 0.0800\n",
      "Epoch: 20/30... Training loss: 0.0752\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0724\n",
      "Epoch: 20/30... Training loss: 0.0766\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0776\n",
      "Epoch: 20/30... Training loss: 0.0738\n",
      "Epoch: 20/30... Training loss: 0.0708\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0721\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0713\n",
      "Epoch: 20/30... Training loss: 0.0725\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0735\n",
      "Epoch: 20/30... Training loss: 0.0768\n",
      "Epoch: 20/30... Training loss: 0.0775\n",
      "Epoch: 20/30... Training loss: 0.0731\n",
      "Epoch: 20/30... Training loss: 0.0736\n",
      "Epoch: 20/30... Training loss: 0.0706\n",
      "Epoch: 20/30... Training loss: 0.0737\n",
      "Epoch: 20/30... Training loss: 0.0733\n",
      "Epoch: 20/30... Training loss: 0.0699\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0716\n",
      "Epoch: 20/30... Training loss: 0.0811\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0747\n",
      "Epoch: 20/30... Training loss: 0.0696\n",
      "Epoch: 20/30... Training loss: 0.0777\n",
      "Epoch: 20/30... Training loss: 0.0693\n",
      "Epoch: 20/30... Training loss: 0.0702\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0741\n",
      "Epoch: 20/30... Training loss: 0.0717\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0754\n",
      "Epoch: 20/30... Training loss: 0.0742\n",
      "Epoch: 20/30... Training loss: 0.0756\n",
      "Epoch: 20/30... Training loss: 0.0727\n",
      "Epoch: 20/30... Training loss: 0.0761\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0767\n",
      "Epoch: 20/30... Training loss: 0.0760\n",
      "Epoch: 20/30... Training loss: 0.0726\n",
      "Epoch: 20/30... Training loss: 0.0694\n",
      "Epoch: 20/30... Training loss: 0.0692\n",
      "Epoch: 20/30... Training loss: 0.0723\n",
      "Epoch: 20/30... Training loss: 0.0750\n",
      "Epoch: 20/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0680\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0681\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0764\n",
      "Epoch: 21/30... Training loss: 0.0683\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0790\n",
      "Epoch: 21/30... Training loss: 0.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0655\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0782\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0819\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0687\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0764\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0621\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0776\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0687\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0797\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0687\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0672\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0779\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0687\n",
      "Epoch: 21/30... Training loss: 0.0674\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0683\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0685\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0782\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0781\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0778\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0777\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0775\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0662\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0686\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 21/30... Training loss: 0.0786\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0677\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0797\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0683\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0781\n",
      "Epoch: 21/30... Training loss: 0.0778\n",
      "Epoch: 21/30... Training loss: 0.0666\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0686\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0797\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0667\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0660\n",
      "Epoch: 21/30... Training loss: 0.0772\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0666\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0667\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0686\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0764\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0641\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0778\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0797\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0793\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0665\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0788\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0687\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0686\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0674\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0673\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0666\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0686\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0794\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0679\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0677\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0779\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0673\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0793\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0666\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0791\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0788\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0770\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0685\n",
      "Epoch: 21/30... Training loss: 0.0659\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0786\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0776\n",
      "Epoch: 21/30... Training loss: 0.0779\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0772\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0784\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0681\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0678\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0775\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0781\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0790\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0772\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0770\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0680\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0764\n",
      "Epoch: 21/30... Training loss: 0.0770\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0678\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0760\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0794\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0781\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0662\n",
      "Epoch: 21/30... Training loss: 0.0775\n",
      "Epoch: 21/30... Training loss: 0.0670\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0758\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0780\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0784\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0709\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0761\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0738\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0785\n",
      "Epoch: 21/30... Training loss: 0.0768\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0707\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0799\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0780\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0681\n",
      "Epoch: 21/30... Training loss: 0.0762\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0740\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0682\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0775\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0650\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0689\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0711\n",
      "Epoch: 21/30... Training loss: 0.0700\n",
      "Epoch: 21/30... Training loss: 0.0728\n",
      "Epoch: 21/30... Training loss: 0.0780\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0672\n",
      "Epoch: 21/30... Training loss: 0.0721\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0685\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0766\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0701\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0811\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0727\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0664\n",
      "Epoch: 21/30... Training loss: 0.0748\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0767\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0706\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0695\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0735\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0686\n",
      "Epoch: 21/30... Training loss: 0.0703\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0779\n",
      "Epoch: 21/30... Training loss: 0.0771\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0756\n",
      "Epoch: 21/30... Training loss: 0.0796\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0754\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0710\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0717\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/30... Training loss: 0.0712\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0778\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0763\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0698\n",
      "Epoch: 21/30... Training loss: 0.0690\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0752\n",
      "Epoch: 21/30... Training loss: 0.0699\n",
      "Epoch: 21/30... Training loss: 0.0705\n",
      "Epoch: 21/30... Training loss: 0.0776\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0684\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0696\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0732\n",
      "Epoch: 21/30... Training loss: 0.0685\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0713\n",
      "Epoch: 21/30... Training loss: 0.0724\n",
      "Epoch: 21/30... Training loss: 0.0779\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0747\n",
      "Epoch: 21/30... Training loss: 0.0746\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0693\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0780\n",
      "Epoch: 21/30... Training loss: 0.0647\n",
      "Epoch: 21/30... Training loss: 0.0691\n",
      "Epoch: 21/30... Training loss: 0.0722\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0729\n",
      "Epoch: 21/30... Training loss: 0.0769\n",
      "Epoch: 21/30... Training loss: 0.0716\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0779\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0682\n",
      "Epoch: 21/30... Training loss: 0.0777\n",
      "Epoch: 21/30... Training loss: 0.0745\n",
      "Epoch: 21/30... Training loss: 0.0692\n",
      "Epoch: 21/30... Training loss: 0.0671\n",
      "Epoch: 21/30... Training loss: 0.0682\n",
      "Epoch: 21/30... Training loss: 0.0770\n",
      "Epoch: 21/30... Training loss: 0.0773\n",
      "Epoch: 21/30... Training loss: 0.0664\n",
      "Epoch: 21/30... Training loss: 0.0744\n",
      "Epoch: 21/30... Training loss: 0.0697\n",
      "Epoch: 21/30... Training loss: 0.0668\n",
      "Epoch: 21/30... Training loss: 0.0723\n",
      "Epoch: 21/30... Training loss: 0.0733\n",
      "Epoch: 21/30... Training loss: 0.0737\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0742\n",
      "Epoch: 21/30... Training loss: 0.0681\n",
      "Epoch: 21/30... Training loss: 0.0739\n",
      "Epoch: 21/30... Training loss: 0.0743\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0678\n",
      "Epoch: 21/30... Training loss: 0.0749\n",
      "Epoch: 21/30... Training loss: 0.0757\n",
      "Epoch: 21/30... Training loss: 0.0755\n",
      "Epoch: 21/30... Training loss: 0.0741\n",
      "Epoch: 21/30... Training loss: 0.0759\n",
      "Epoch: 21/30... Training loss: 0.0702\n",
      "Epoch: 21/30... Training loss: 0.0725\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0736\n",
      "Epoch: 21/30... Training loss: 0.0765\n",
      "Epoch: 21/30... Training loss: 0.0719\n",
      "Epoch: 21/30... Training loss: 0.0718\n",
      "Epoch: 21/30... Training loss: 0.0704\n",
      "Epoch: 21/30... Training loss: 0.0751\n",
      "Epoch: 21/30... Training loss: 0.0688\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0774\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0708\n",
      "Epoch: 21/30... Training loss: 0.0750\n",
      "Epoch: 21/30... Training loss: 0.0753\n",
      "Epoch: 21/30... Training loss: 0.0720\n",
      "Epoch: 21/30... Training loss: 0.0726\n",
      "Epoch: 21/30... Training loss: 0.0731\n",
      "Epoch: 21/30... Training loss: 0.0734\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0715\n",
      "Epoch: 21/30... Training loss: 0.0714\n",
      "Epoch: 21/30... Training loss: 0.0730\n",
      "Epoch: 21/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0663\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0804\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0681\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0773\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0669\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0779\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0686\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0644\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0684\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0775\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0693\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0824\n",
      "Epoch: 22/30... Training loss: 0.0690\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0773\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0677\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/30... Training loss: 0.0772\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0819\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0790\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0799\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0788\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0676\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0773\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0668\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0788\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0775\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0787\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0770\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0770\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0664\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0776\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0772\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0772\n",
      "Epoch: 22/30... Training loss: 0.0768\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0680\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0651\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0789\n",
      "Epoch: 22/30... Training loss: 0.0693\n",
      "Epoch: 22/30... Training loss: 0.0689\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0783\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0686\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0774\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0791\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0809\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0774\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0778\n",
      "Epoch: 22/30... Training loss: 0.0686\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0770\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0681\n",
      "Epoch: 22/30... Training loss: 0.0789\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0690\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0676\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0781\n",
      "Epoch: 22/30... Training loss: 0.0792\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0775\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0675\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0798\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0779\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0775\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0783\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0777\n",
      "Epoch: 22/30... Training loss: 0.0782\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0768\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0688\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0646\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0648\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0792\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0664\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0790\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0775\n",
      "Epoch: 22/30... Training loss: 0.0781\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0770\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0791\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0668\n",
      "Epoch: 22/30... Training loss: 0.0773\n",
      "Epoch: 22/30... Training loss: 0.0807\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0784\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0676\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0723\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0788\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0770\n",
      "Epoch: 22/30... Training loss: 0.0671\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0680\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0782\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0683\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0789\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0795\n",
      "Epoch: 22/30... Training loss: 0.0780\n",
      "Epoch: 22/30... Training loss: 0.0784\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0675\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0811\n",
      "Epoch: 22/30... Training loss: 0.0774\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0792\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0656\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0679\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0785\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0786\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0782\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0702\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0677\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0776\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0673\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0627\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0693\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0675\n",
      "Epoch: 22/30... Training loss: 0.0817\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0772\n",
      "Epoch: 22/30... Training loss: 0.0776\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0770\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0669\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0758\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0781\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0666\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0660\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0784\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0789\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0764\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0686\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0679\n",
      "Epoch: 22/30... Training loss: 0.0678\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0674\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0666\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0751\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0777\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0768\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0692\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0763\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0778\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0740\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0695\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0779\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0710\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0731\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0691\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0678\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0696\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0730\n",
      "Epoch: 22/30... Training loss: 0.0686\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0800\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0765\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0769\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0706\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0699\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0719\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0718\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0749\n",
      "Epoch: 22/30... Training loss: 0.0672\n",
      "Epoch: 22/30... Training loss: 0.0722\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0757\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0767\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0774\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0714\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0715\n",
      "Epoch: 22/30... Training loss: 0.0734\n",
      "Epoch: 22/30... Training loss: 0.0704\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0759\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0658\n",
      "Epoch: 22/30... Training loss: 0.0746\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0708\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0716\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0774\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0768\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0700\n",
      "Epoch: 22/30... Training loss: 0.0712\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0676\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0768\n",
      "Epoch: 22/30... Training loss: 0.0738\n",
      "Epoch: 22/30... Training loss: 0.0793\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0686\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0762\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0736\n",
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0733\n",
      "Epoch: 22/30... Training loss: 0.0727\n",
      "Epoch: 22/30... Training loss: 0.0783\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0694\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0766\n",
      "Epoch: 22/30... Training loss: 0.0761\n",
      "Epoch: 22/30... Training loss: 0.0732\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0788\n",
      "Epoch: 22/30... Training loss: 0.0682\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0760\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0717\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0697\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0784\n",
      "Epoch: 22/30... Training loss: 0.0698\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0685\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0709\n",
      "Epoch: 22/30... Training loss: 0.0752\n",
      "Epoch: 22/30... Training loss: 0.0748\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0754\n",
      "Epoch: 22/30... Training loss: 0.0687\n",
      "Epoch: 22/30... Training loss: 0.0688\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0711\n",
      "Epoch: 22/30... Training loss: 0.0747\n",
      "Epoch: 22/30... Training loss: 0.0705\n",
      "Epoch: 22/30... Training loss: 0.0693\n",
      "Epoch: 22/30... Training loss: 0.0771\n",
      "Epoch: 22/30... Training loss: 0.0756\n",
      "Epoch: 22/30... Training loss: 0.0739\n",
      "Epoch: 22/30... Training loss: 0.0768\n",
      "Epoch: 22/30... Training loss: 0.0743\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0701\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0726\n",
      "Epoch: 22/30... Training loss: 0.0744\n",
      "Epoch: 22/30... Training loss: 0.0703\n",
      "Epoch: 22/30... Training loss: 0.0745\n",
      "Epoch: 22/30... Training loss: 0.0735\n",
      "Epoch: 22/30... Training loss: 0.0728\n",
      "Epoch: 22/30... Training loss: 0.0729\n",
      "Epoch: 22/30... Training loss: 0.0755\n",
      "Epoch: 22/30... Training loss: 0.0742\n",
      "Epoch: 22/30... Training loss: 0.0707\n",
      "Epoch: 22/30... Training loss: 0.0785\n",
      "Epoch: 22/30... Training loss: 0.0741\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/30... Training loss: 0.0724\n",
      "Epoch: 22/30... Training loss: 0.0750\n",
      "Epoch: 22/30... Training loss: 0.0713\n",
      "Epoch: 22/30... Training loss: 0.0725\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0753\n",
      "Epoch: 22/30... Training loss: 0.0721\n",
      "Epoch: 22/30... Training loss: 0.0720\n",
      "Epoch: 22/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0683\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0678\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0681\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0778\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0672\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0779\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0683\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0690\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0693\n",
      "Epoch: 23/30... Training loss: 0.0777\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0767\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0784\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0778\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0681\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0778\n",
      "Epoch: 23/30... Training loss: 0.0658\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0782\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0783\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0693\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0805\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0680\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0685\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0767\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0787\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0693\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/30... Training loss: 0.0651\n",
      "Epoch: 23/30... Training loss: 0.0781\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0665\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0793\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0693\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0682\n",
      "Epoch: 23/30... Training loss: 0.0775\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0796\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0693\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0779\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0691\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0682\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0798\n",
      "Epoch: 23/30... Training loss: 0.0782\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0771\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0800\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0780\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0678\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0638\n",
      "Epoch: 23/30... Training loss: 0.0781\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0773\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0775\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0775\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0670\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0668\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0811\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0767\n",
      "Epoch: 23/30... Training loss: 0.0682\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0650\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0687\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0677\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0687\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0681\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0687\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0793\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0670\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0779\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0685\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0823\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0784\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0771\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0783\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0775\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0770\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0675\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0667\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0803\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0785\n",
      "Epoch: 23/30... Training loss: 0.0682\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0682\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0782\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0779\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0687\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0669\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0663\n",
      "Epoch: 23/30... Training loss: 0.0797\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0771\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0685\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0687\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0656\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0789\n",
      "Epoch: 23/30... Training loss: 0.0776\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0771\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0680\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0782\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0690\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0690\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0663\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0787\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0660\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0680\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0687\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0665\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0757\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0805\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0776\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0679\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0685\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0781\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0673\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0668\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0678\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0761\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0776\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0682\n",
      "Epoch: 23/30... Training loss: 0.0690\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0776\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0773\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0688\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0783\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0673\n",
      "Epoch: 23/30... Training loss: 0.0698\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0686\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0793\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0668\n",
      "Epoch: 23/30... Training loss: 0.0772\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0738\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0666\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0796\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0790\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0767\n",
      "Epoch: 23/30... Training loss: 0.0666\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0806\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0776\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0795\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0676\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0779\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0682\n",
      "Epoch: 23/30... Training loss: 0.0782\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0681\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0794\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0760\n",
      "Epoch: 23/30... Training loss: 0.0661\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0722\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0767\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0773\n",
      "Epoch: 23/30... Training loss: 0.0779\n",
      "Epoch: 23/30... Training loss: 0.0765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0711\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0778\n",
      "Epoch: 23/30... Training loss: 0.0753\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0795\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0759\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0710\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0706\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0694\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0777\n",
      "Epoch: 23/30... Training loss: 0.0774\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0693\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0777\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0741\n",
      "Epoch: 23/30... Training loss: 0.0782\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0703\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0678\n",
      "Epoch: 23/30... Training loss: 0.0795\n",
      "Epoch: 23/30... Training loss: 0.0783\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0707\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0682\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0685\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0776\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0689\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0739\n",
      "Epoch: 23/30... Training loss: 0.0769\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0660\n",
      "Epoch: 23/30... Training loss: 0.0691\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0684\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0681\n",
      "Epoch: 23/30... Training loss: 0.0752\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0754\n",
      "Epoch: 23/30... Training loss: 0.0764\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0715\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0746\n",
      "Epoch: 23/30... Training loss: 0.0720\n",
      "Epoch: 23/30... Training loss: 0.0778\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0749\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0736\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0729\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0677\n",
      "Epoch: 23/30... Training loss: 0.0765\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0691\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0681\n",
      "Epoch: 23/30... Training loss: 0.0751\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0680\n",
      "Epoch: 23/30... Training loss: 0.0664\n",
      "Epoch: 23/30... Training loss: 0.0750\n",
      "Epoch: 23/30... Training loss: 0.0695\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0699\n",
      "Epoch: 23/30... Training loss: 0.0708\n",
      "Epoch: 23/30... Training loss: 0.0745\n",
      "Epoch: 23/30... Training loss: 0.0766\n",
      "Epoch: 23/30... Training loss: 0.0685\n",
      "Epoch: 23/30... Training loss: 0.0748\n",
      "Epoch: 23/30... Training loss: 0.0712\n",
      "Epoch: 23/30... Training loss: 0.0725\n",
      "Epoch: 23/30... Training loss: 0.0687\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0768\n",
      "Epoch: 23/30... Training loss: 0.0677\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0755\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0756\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0762\n",
      "Epoch: 23/30... Training loss: 0.0740\n",
      "Epoch: 23/30... Training loss: 0.0735\n",
      "Epoch: 23/30... Training loss: 0.0778\n",
      "Epoch: 23/30... Training loss: 0.0723\n",
      "Epoch: 23/30... Training loss: 0.0713\n",
      "Epoch: 23/30... Training loss: 0.0734\n",
      "Epoch: 23/30... Training loss: 0.0702\n",
      "Epoch: 23/30... Training loss: 0.0758\n",
      "Epoch: 23/30... Training loss: 0.0737\n",
      "Epoch: 23/30... Training loss: 0.0744\n",
      "Epoch: 23/30... Training loss: 0.0692\n",
      "Epoch: 23/30... Training loss: 0.0743\n",
      "Epoch: 23/30... Training loss: 0.0718\n",
      "Epoch: 23/30... Training loss: 0.0691\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0724\n",
      "Epoch: 23/30... Training loss: 0.0721\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0682\n",
      "Epoch: 23/30... Training loss: 0.0701\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0728\n",
      "Epoch: 23/30... Training loss: 0.0716\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0747\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 23/30... Training loss: 0.0730\n",
      "Epoch: 23/30... Training loss: 0.0733\n",
      "Epoch: 23/30... Training loss: 0.0714\n",
      "Epoch: 23/30... Training loss: 0.0780\n",
      "Epoch: 23/30... Training loss: 0.0727\n",
      "Epoch: 23/30... Training loss: 0.0767\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0700\n",
      "Epoch: 23/30... Training loss: 0.0763\n",
      "Epoch: 23/30... Training loss: 0.0717\n",
      "Epoch: 23/30... Training loss: 0.0705\n",
      "Epoch: 23/30... Training loss: 0.0697\n",
      "Epoch: 23/30... Training loss: 0.0726\n",
      "Epoch: 23/30... Training loss: 0.0719\n",
      "Epoch: 23/30... Training loss: 0.0679\n",
      "Epoch: 23/30... Training loss: 0.0742\n",
      "Epoch: 23/30... Training loss: 0.0732\n",
      "Epoch: 23/30... Training loss: 0.0731\n",
      "Epoch: 23/30... Training loss: 0.0696\n",
      "Epoch: 23/30... Training loss: 0.0704\n",
      "Epoch: 23/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0792\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0804\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0688\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0765\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0774\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0780\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0774\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0776\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0663\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0675\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0775\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0666\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0784\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0777\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0774\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0771\n",
      "Epoch: 24/30... Training loss: 0.0768\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0805\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0682\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0794\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0776\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0782\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0682\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0686\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0679\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0671\n",
      "Epoch: 24/30... Training loss: 0.0671\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0791\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0687\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0785\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0775\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0770\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0670\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0687\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0802\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0778\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0777\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0687\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0787\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0770\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0782\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0678\n",
      "Epoch: 24/30... Training loss: 0.0687\n",
      "Epoch: 24/30... Training loss: 0.0770\n",
      "Epoch: 24/30... Training loss: 0.0771\n",
      "Epoch: 24/30... Training loss: 0.0777\n",
      "Epoch: 24/30... Training loss: 0.0778\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0687\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0688\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0669\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0780\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0667\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0765\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0676\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0768\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0665\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0794\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0770\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0669\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0674\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0799\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0768\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0788\n",
      "Epoch: 24/30... Training loss: 0.0674\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0790\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0668\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0682\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0686\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0796\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0669\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0679\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0667\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0686\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0775\n",
      "Epoch: 24/30... Training loss: 0.0798\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0687\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0671\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0688\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0793\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0682\n",
      "Epoch: 24/30... Training loss: 0.0734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0776\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0677\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0783\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0760\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0675\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0687\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0668\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0772\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0782\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0661\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0791\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0797\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0788\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0670\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0670\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0675\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0688\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0745\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0665\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0661\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0772\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0682\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0683\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0658\n",
      "Epoch: 24/30... Training loss: 0.0765\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0694\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0765\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0800\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0789\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0797\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0768\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0776\n",
      "Epoch: 24/30... Training loss: 0.0779\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0668\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0666\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0669\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0780\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0680\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0673\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0772\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0680\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0678\n",
      "Epoch: 24/30... Training loss: 0.0688\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0777\n",
      "Epoch: 24/30... Training loss: 0.0660\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0765\n",
      "Epoch: 24/30... Training loss: 0.0714\n",
      "Epoch: 24/30... Training loss: 0.0794\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0675\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0686\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0691\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0672\n",
      "Epoch: 24/30... Training loss: 0.0786\n",
      "Epoch: 24/30... Training loss: 0.0688\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0791\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0779\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0768\n",
      "Epoch: 24/30... Training loss: 0.0777\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0778\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0725\n",
      "Epoch: 24/30... Training loss: 0.0765\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0730\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0759\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0748\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0700\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0712\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0707\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0790\n",
      "Epoch: 24/30... Training loss: 0.0763\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0685\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0710\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0778\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0771\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0715\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0739\n",
      "Epoch: 24/30... Training loss: 0.0699\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0778\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0774\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0716\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0761\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0780\n",
      "Epoch: 24/30... Training loss: 0.0780\n",
      "Epoch: 24/30... Training loss: 0.0702\n",
      "Epoch: 24/30... Training loss: 0.0705\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0729\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0786\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0709\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0723\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0744\n",
      "Epoch: 24/30... Training loss: 0.0703\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0732\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0756\n",
      "Epoch: 24/30... Training loss: 0.0704\n",
      "Epoch: 24/30... Training loss: 0.0803\n",
      "Epoch: 24/30... Training loss: 0.0742\n",
      "Epoch: 24/30... Training loss: 0.0717\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0790\n",
      "Epoch: 24/30... Training loss: 0.0783\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0766\n",
      "Epoch: 24/30... Training loss: 0.0792\n",
      "Epoch: 24/30... Training loss: 0.0768\n",
      "Epoch: 24/30... Training loss: 0.0781\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0746\n",
      "Epoch: 24/30... Training loss: 0.0737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0773\n",
      "Epoch: 24/30... Training loss: 0.0690\n",
      "Epoch: 24/30... Training loss: 0.0768\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0660\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0726\n",
      "Epoch: 24/30... Training loss: 0.0679\n",
      "Epoch: 24/30... Training loss: 0.0670\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0781\n",
      "Epoch: 24/30... Training loss: 0.0762\n",
      "Epoch: 24/30... Training loss: 0.0743\n",
      "Epoch: 24/30... Training loss: 0.0713\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0734\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0684\n",
      "Epoch: 24/30... Training loss: 0.0687\n",
      "Epoch: 24/30... Training loss: 0.0750\n",
      "Epoch: 24/30... Training loss: 0.0706\n",
      "Epoch: 24/30... Training loss: 0.0747\n",
      "Epoch: 24/30... Training loss: 0.0754\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0720\n",
      "Epoch: 24/30... Training loss: 0.0695\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0767\n",
      "Epoch: 24/30... Training loss: 0.0753\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0681\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0764\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0701\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0735\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0708\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0689\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0769\n",
      "Epoch: 24/30... Training loss: 0.0681\n",
      "Epoch: 24/30... Training loss: 0.0724\n",
      "Epoch: 24/30... Training loss: 0.0719\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0681\n",
      "Epoch: 24/30... Training loss: 0.0728\n",
      "Epoch: 24/30... Training loss: 0.0751\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0731\n",
      "Epoch: 24/30... Training loss: 0.0738\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0752\n",
      "Epoch: 24/30... Training loss: 0.0696\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0737\n",
      "Epoch: 24/30... Training loss: 0.0727\n",
      "Epoch: 24/30... Training loss: 0.0711\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0721\n",
      "Epoch: 24/30... Training loss: 0.0692\n",
      "Epoch: 24/30... Training loss: 0.0697\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0749\n",
      "Epoch: 24/30... Training loss: 0.0733\n",
      "Epoch: 24/30... Training loss: 0.0755\n",
      "Epoch: 24/30... Training loss: 0.0758\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 24/30... Training loss: 0.0693\n",
      "Epoch: 24/30... Training loss: 0.0736\n",
      "Epoch: 24/30... Training loss: 0.0741\n",
      "Epoch: 24/30... Training loss: 0.0698\n",
      "Epoch: 24/30... Training loss: 0.0722\n",
      "Epoch: 24/30... Training loss: 0.0740\n",
      "Epoch: 24/30... Training loss: 0.0718\n",
      "Epoch: 24/30... Training loss: 0.0789\n",
      "Epoch: 24/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0678\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0691\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0684\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0675\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0777\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0786\n",
      "Epoch: 25/30... Training loss: 0.0656\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0786\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0670\n",
      "Epoch: 25/30... Training loss: 0.0790\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0675\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0775\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0777\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0662\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0673\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0775\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0791\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0658\n",
      "Epoch: 25/30... Training loss: 0.0693\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0691\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0657\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0678\n",
      "Epoch: 25/30... Training loss: 0.0679\n",
      "Epoch: 25/30... Training loss: 0.0732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0817\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0792\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0688\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0774\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0679\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0677\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0797\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0682\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0659\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0774\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0666\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0656\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0768\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0626\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0670\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0790\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0678\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0784\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0654\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0780\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0675\n",
      "Epoch: 25/30... Training loss: 0.0780\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0794\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0684\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0776\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0795\n",
      "Epoch: 25/30... Training loss: 0.0774\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0771\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0670\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0677\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0778\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0682\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0672\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0668\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0672\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0807\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0688\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0786\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0768\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0678\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0662\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0693\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0771\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0675\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0666\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0680\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0679\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0682\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0778\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0681\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0808\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0650\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0792\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0786\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0658\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0679\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0681\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0787\n",
      "Epoch: 25/30... Training loss: 0.0673\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0770\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0780\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0669\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0669\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0662\n",
      "Epoch: 25/30... Training loss: 0.0726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0657\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0768\n",
      "Epoch: 25/30... Training loss: 0.0772\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0787\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0673\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0784\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0668\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0681\n",
      "Epoch: 25/30... Training loss: 0.0778\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0663\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0771\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0800\n",
      "Epoch: 25/30... Training loss: 0.0680\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0664\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0775\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0657\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0658\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0732\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0777\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0773\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0794\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0783\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0777\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0770\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0775\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0771\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0777\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0680\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0792\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0674\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0788\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0705\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0786\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0782\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0788\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0777\n",
      "Epoch: 25/30... Training loss: 0.0690\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0677\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0811\n",
      "Epoch: 25/30... Training loss: 0.0776\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0772\n",
      "Epoch: 25/30... Training loss: 0.0693\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0687\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0679\n",
      "Epoch: 25/30... Training loss: 0.0677\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0680\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/30... Training loss: 0.0668\n",
      "Epoch: 25/30... Training loss: 0.0665\n",
      "Epoch: 25/30... Training loss: 0.0776\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0759\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0785\n",
      "Epoch: 25/30... Training loss: 0.0797\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0671\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0679\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0754\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0785\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0700\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0750\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0685\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0768\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0785\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0801\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0787\n",
      "Epoch: 25/30... Training loss: 0.0679\n",
      "Epoch: 25/30... Training loss: 0.0659\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0736\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0775\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0756\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0781\n",
      "Epoch: 25/30... Training loss: 0.0733\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0777\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0765\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0758\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0673\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0650\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0775\n",
      "Epoch: 25/30... Training loss: 0.0726\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0769\n",
      "Epoch: 25/30... Training loss: 0.0697\n",
      "Epoch: 25/30... Training loss: 0.0779\n",
      "Epoch: 25/30... Training loss: 0.0739\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0696\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0766\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0668\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0688\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0725\n",
      "Epoch: 25/30... Training loss: 0.0787\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0804\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0692\n",
      "Epoch: 25/30... Training loss: 0.0801\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0724\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0738\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0728\n",
      "Epoch: 25/30... Training loss: 0.0680\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0782\n",
      "Epoch: 25/30... Training loss: 0.0761\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0651\n",
      "Epoch: 25/30... Training loss: 0.0745\n",
      "Epoch: 25/30... Training loss: 0.0666\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0776\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0719\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0763\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0716\n",
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0767\n",
      "Epoch: 25/30... Training loss: 0.0722\n",
      "Epoch: 25/30... Training loss: 0.0788\n",
      "Epoch: 25/30... Training loss: 0.0702\n",
      "Epoch: 25/30... Training loss: 0.0712\n",
      "Epoch: 25/30... Training loss: 0.0711\n",
      "Epoch: 25/30... Training loss: 0.0675\n",
      "Epoch: 25/30... Training loss: 0.0730\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0742\n",
      "Epoch: 25/30... Training loss: 0.0706\n",
      "Epoch: 25/30... Training loss: 0.0699\n",
      "Epoch: 25/30... Training loss: 0.0753\n",
      "Epoch: 25/30... Training loss: 0.0684\n",
      "Epoch: 25/30... Training loss: 0.0771\n",
      "Epoch: 25/30... Training loss: 0.0720\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0741\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0740\n",
      "Epoch: 25/30... Training loss: 0.0683\n",
      "Epoch: 25/30... Training loss: 0.0744\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0747\n",
      "Epoch: 25/30... Training loss: 0.0704\n",
      "Epoch: 25/30... Training loss: 0.0752\n",
      "Epoch: 25/30... Training loss: 0.0703\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0729\n",
      "Epoch: 25/30... Training loss: 0.0757\n",
      "Epoch: 25/30... Training loss: 0.0686\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0735\n",
      "Epoch: 25/30... Training loss: 0.0737\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0721\n",
      "Epoch: 25/30... Training loss: 0.0796\n",
      "Epoch: 25/30... Training loss: 0.0755\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0760\n",
      "Epoch: 25/30... Training loss: 0.0762\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0694\n",
      "Epoch: 25/30... Training loss: 0.0751\n",
      "Epoch: 25/30... Training loss: 0.0723\n",
      "Epoch: 25/30... Training loss: 0.0708\n",
      "Epoch: 25/30... Training loss: 0.0707\n",
      "Epoch: 25/30... Training loss: 0.0734\n",
      "Epoch: 25/30... Training loss: 0.0715\n",
      "Epoch: 25/30... Training loss: 0.0731\n",
      "Epoch: 25/30... Training loss: 0.0764\n",
      "Epoch: 25/30... Training loss: 0.0709\n",
      "Epoch: 25/30... Training loss: 0.0689\n",
      "Epoch: 25/30... Training loss: 0.0717\n",
      "Epoch: 25/30... Training loss: 0.0749\n",
      "Epoch: 25/30... Training loss: 0.0710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/30... Training loss: 0.0718\n",
      "Epoch: 25/30... Training loss: 0.0710\n",
      "Epoch: 25/30... Training loss: 0.0780\n",
      "Epoch: 25/30... Training loss: 0.0713\n",
      "Epoch: 25/30... Training loss: 0.0727\n",
      "Epoch: 25/30... Training loss: 0.0748\n",
      "Epoch: 25/30... Training loss: 0.0714\n",
      "Epoch: 25/30... Training loss: 0.0698\n",
      "Epoch: 25/30... Training loss: 0.0781\n",
      "Epoch: 25/30... Training loss: 0.0701\n",
      "Epoch: 25/30... Training loss: 0.0743\n",
      "Epoch: 25/30... Training loss: 0.0746\n",
      "Epoch: 25/30... Training loss: 0.0667\n",
      "Epoch: 25/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0671\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0683\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0657\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0785\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0683\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0783\n",
      "Epoch: 26/30... Training loss: 0.0663\n",
      "Epoch: 26/30... Training loss: 0.0773\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0683\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0780\n",
      "Epoch: 26/30... Training loss: 0.0649\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0771\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0680\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0771\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0777\n",
      "Epoch: 26/30... Training loss: 0.0768\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0782\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0796\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0816\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0777\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0675\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0775\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0786\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0782\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0669\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0657\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0788\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0787\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0680\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0772\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0777\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0782\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0676\n",
      "Epoch: 26/30... Training loss: 0.0768\n",
      "Epoch: 26/30... Training loss: 0.0786\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0679\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0662\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0673\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0660\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0673\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0768\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0798\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0677\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0800\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0820\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0686\n",
      "Epoch: 26/30... Training loss: 0.0790\n",
      "Epoch: 26/30... Training loss: 0.0786\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0682\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0646\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0668\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0685\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0781\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0677\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0784\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0768\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0670\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0780\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0772\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0771\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0682\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0686\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0804\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0775\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0664\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0779\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0798\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0686\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0674\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0634\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0664\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0678\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0777\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0812\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0773\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0677\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0796\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0683\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0665\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0781\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0655\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0680\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0682\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0688\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0683\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0794\n",
      "Epoch: 26/30... Training loss: 0.0781\n",
      "Epoch: 26/30... Training loss: 0.0676\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0773\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0633\n",
      "Epoch: 26/30... Training loss: 0.0674\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0771\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0689\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0678\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0775\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0685\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0808\n",
      "Epoch: 26/30... Training loss: 0.0661\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/30... Training loss: 0.0686\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0774\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0676\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0686\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0678\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0819\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0648\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0792\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0784\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0669\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0671\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0777\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0770\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0771\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0683\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0775\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0790\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0661\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0671\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0670\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0686\n",
      "Epoch: 26/30... Training loss: 0.0808\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0675\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0787\n",
      "Epoch: 26/30... Training loss: 0.0789\n",
      "Epoch: 26/30... Training loss: 0.0781\n",
      "Epoch: 26/30... Training loss: 0.0834\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0783\n",
      "Epoch: 26/30... Training loss: 0.0705\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0674\n",
      "Epoch: 26/30... Training loss: 0.0671\n",
      "Epoch: 26/30... Training loss: 0.0671\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0774\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0771\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0748\n",
      "Epoch: 26/30... Training loss: 0.0646\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0760\n",
      "Epoch: 26/30... Training loss: 0.0797\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0716\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0689\n",
      "Epoch: 26/30... Training loss: 0.0687\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0799\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0675\n",
      "Epoch: 26/30... Training loss: 0.0662\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0682\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0728\n",
      "Epoch: 26/30... Training loss: 0.0666\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0659\n",
      "Epoch: 26/30... Training loss: 0.0686\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0685\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0790\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0719\n",
      "Epoch: 26/30... Training loss: 0.0706\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0731\n",
      "Epoch: 26/30... Training loss: 0.0773\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0713\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0687\n",
      "Epoch: 26/30... Training loss: 0.0722\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0766\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0734\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0680\n",
      "Epoch: 26/30... Training loss: 0.0676\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0700\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0767\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0762\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0675\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0645\n",
      "Epoch: 26/30... Training loss: 0.0688\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0674\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0712\n",
      "Epoch: 26/30... Training loss: 0.0751\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0697\n",
      "Epoch: 26/30... Training loss: 0.0727\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0636\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0721\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0674\n",
      "Epoch: 26/30... Training loss: 0.0759\n",
      "Epoch: 26/30... Training loss: 0.0771\n",
      "Epoch: 26/30... Training loss: 0.0681\n",
      "Epoch: 26/30... Training loss: 0.0732\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0690\n",
      "Epoch: 26/30... Training loss: 0.0791\n",
      "Epoch: 26/30... Training loss: 0.0701\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0758\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0707\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0720\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0724\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0723\n",
      "Epoch: 26/30... Training loss: 0.0672\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0792\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0735\n",
      "Epoch: 26/30... Training loss: 0.0709\n",
      "Epoch: 26/30... Training loss: 0.0742\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0765\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0694\n",
      "Epoch: 26/30... Training loss: 0.0698\n",
      "Epoch: 26/30... Training loss: 0.0769\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0757\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0686\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0746\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0679\n",
      "Epoch: 26/30... Training loss: 0.0747\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0763\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0708\n",
      "Epoch: 26/30... Training loss: 0.0764\n",
      "Epoch: 26/30... Training loss: 0.0752\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0730\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0693\n",
      "Epoch: 26/30... Training loss: 0.0702\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0754\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0670\n",
      "Epoch: 26/30... Training loss: 0.0755\n",
      "Epoch: 26/30... Training loss: 0.0775\n",
      "Epoch: 26/30... Training loss: 0.0715\n",
      "Epoch: 26/30... Training loss: 0.0753\n",
      "Epoch: 26/30... Training loss: 0.0738\n",
      "Epoch: 26/30... Training loss: 0.0691\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0692\n",
      "Epoch: 26/30... Training loss: 0.0745\n",
      "Epoch: 26/30... Training loss: 0.0739\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0726\n",
      "Epoch: 26/30... Training loss: 0.0695\n",
      "Epoch: 26/30... Training loss: 0.0743\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0699\n",
      "Epoch: 26/30... Training loss: 0.0710\n",
      "Epoch: 26/30... Training loss: 0.0703\n",
      "Epoch: 26/30... Training loss: 0.0741\n",
      "Epoch: 26/30... Training loss: 0.0714\n",
      "Epoch: 26/30... Training loss: 0.0718\n",
      "Epoch: 26/30... Training loss: 0.0733\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0725\n",
      "Epoch: 26/30... Training loss: 0.0711\n",
      "Epoch: 26/30... Training loss: 0.0761\n",
      "Epoch: 26/30... Training loss: 0.0736\n",
      "Epoch: 26/30... Training loss: 0.0717\n",
      "Epoch: 26/30... Training loss: 0.0778\n",
      "Epoch: 26/30... Training loss: 0.0729\n",
      "Epoch: 26/30... Training loss: 0.0696\n",
      "Epoch: 26/30... Training loss: 0.0704\n",
      "Epoch: 26/30... Training loss: 0.0744\n",
      "Epoch: 26/30... Training loss: 0.0750\n",
      "Epoch: 26/30... Training loss: 0.0740\n",
      "Epoch: 26/30... Training loss: 0.0756\n",
      "Epoch: 26/30... Training loss: 0.0749\n",
      "Epoch: 26/30... Training loss: 0.0737\n",
      "Epoch: 26/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0778\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0688\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0680\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0774\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0676\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0678\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0680\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0792\n",
      "Epoch: 27/30... Training loss: 0.0671\n",
      "Epoch: 27/30... Training loss: 0.0676\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0794\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0655\n",
      "Epoch: 27/30... Training loss: 0.0789\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0669\n",
      "Epoch: 27/30... Training loss: 0.0680\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0810\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0680\n",
      "Epoch: 27/30... Training loss: 0.0691\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0784\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0670\n",
      "Epoch: 27/30... Training loss: 0.0677\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0774\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0691\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0687\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0770\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0790\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0780\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0777\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0681\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0677\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0796\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0770\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0777\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0771\n",
      "Epoch: 27/30... Training loss: 0.0779\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0673\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0672\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0676\n",
      "Epoch: 27/30... Training loss: 0.0781\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0691\n",
      "Epoch: 27/30... Training loss: 0.0774\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0792\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0650\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0679\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0771\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0661\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/30... Training loss: 0.0797\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0776\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0770\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0672\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0785\n",
      "Epoch: 27/30... Training loss: 0.0686\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0765\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0688\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0691\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0676\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0686\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0778\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0678\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0665\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0679\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0661\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0665\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0770\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0659\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0777\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0671\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0630\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0681\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0680\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0774\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0662\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0782\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0675\n",
      "Epoch: 27/30... Training loss: 0.0688\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0778\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0672\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0779\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0773\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0681\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0799\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0691\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0669\n",
      "Epoch: 27/30... Training loss: 0.0780\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0672\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0778\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0788\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0680\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0688\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0675\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0673\n",
      "Epoch: 27/30... Training loss: 0.0784\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0660\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0783\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0680\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0691\n",
      "Epoch: 27/30... Training loss: 0.0681\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0668\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0785\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0677\n",
      "Epoch: 27/30... Training loss: 0.0660\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0786\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0765\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0773\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0683\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0671\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0702\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0676\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0694\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0778\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0690\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0786\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0779\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0681\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0686\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0684\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0688\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0783\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0790\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0768\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0775\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0694\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0753\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0778\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0765\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0687\n",
      "Epoch: 27/30... Training loss: 0.0688\n",
      "Epoch: 27/30... Training loss: 0.0686\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0785\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0678\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0765\n",
      "Epoch: 27/30... Training loss: 0.0694\n",
      "Epoch: 27/30... Training loss: 0.0784\n",
      "Epoch: 27/30... Training loss: 0.0771\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0760\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0799\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0696\n",
      "Epoch: 27/30... Training loss: 0.0776\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0687\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0765\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0781\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0681\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0787\n",
      "Epoch: 27/30... Training loss: 0.0771\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0691\n",
      "Epoch: 27/30... Training loss: 0.0676\n",
      "Epoch: 27/30... Training loss: 0.0661\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0778\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0690\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0676\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0660\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0757\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0769\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0674\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0690\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0725\n",
      "Epoch: 27/30... Training loss: 0.0667\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0679\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0728\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0731\n",
      "Epoch: 27/30... Training loss: 0.0773\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0721\n",
      "Epoch: 27/30... Training loss: 0.0689\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0717\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0658\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0716\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0701\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0758\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0762\n",
      "Epoch: 27/30... Training loss: 0.0779\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0791\n",
      "Epoch: 27/30... Training loss: 0.0682\n",
      "Epoch: 27/30... Training loss: 0.0704\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0788\n",
      "Epoch: 27/30... Training loss: 0.0711\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0730\n",
      "Epoch: 27/30... Training loss: 0.0748\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0743\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0707\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0772\n",
      "Epoch: 27/30... Training loss: 0.0703\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0740\n",
      "Epoch: 27/30... Training loss: 0.0800\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0719\n",
      "Epoch: 27/30... Training loss: 0.0767\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0693\n",
      "Epoch: 27/30... Training loss: 0.0750\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0739\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0679\n",
      "Epoch: 27/30... Training loss: 0.0665\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0756\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0764\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0794\n",
      "Epoch: 27/30... Training loss: 0.0699\n",
      "Epoch: 27/30... Training loss: 0.0676\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0681\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0697\n",
      "Epoch: 27/30... Training loss: 0.0705\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0745\n",
      "Epoch: 27/30... Training loss: 0.0695\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0726\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0763\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0735\n",
      "Epoch: 27/30... Training loss: 0.0700\n",
      "Epoch: 27/30... Training loss: 0.0663\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0747\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0761\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0737\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0766\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0655\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0777\n",
      "Epoch: 27/30... Training loss: 0.0733\n",
      "Epoch: 27/30... Training loss: 0.0752\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0678\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0718\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0754\n",
      "Epoch: 27/30... Training loss: 0.0727\n",
      "Epoch: 27/30... Training loss: 0.0722\n",
      "Epoch: 27/30... Training loss: 0.0710\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0738\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0741\n",
      "Epoch: 27/30... Training loss: 0.0759\n",
      "Epoch: 27/30... Training loss: 0.0685\n",
      "Epoch: 27/30... Training loss: 0.0732\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0723\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0755\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0746\n",
      "Epoch: 27/30... Training loss: 0.0720\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0713\n",
      "Epoch: 27/30... Training loss: 0.0787\n",
      "Epoch: 27/30... Training loss: 0.0744\n",
      "Epoch: 27/30... Training loss: 0.0773\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0780\n",
      "Epoch: 27/30... Training loss: 0.0736\n",
      "Epoch: 27/30... Training loss: 0.0729\n",
      "Epoch: 27/30... Training loss: 0.0708\n",
      "Epoch: 27/30... Training loss: 0.0692\n",
      "Epoch: 27/30... Training loss: 0.0714\n",
      "Epoch: 27/30... Training loss: 0.0706\n",
      "Epoch: 27/30... Training loss: 0.0791\n",
      "Epoch: 27/30... Training loss: 0.0749\n",
      "Epoch: 27/30... Training loss: 0.0751\n",
      "Epoch: 27/30... Training loss: 0.0742\n",
      "Epoch: 27/30... Training loss: 0.0715\n",
      "Epoch: 27/30... Training loss: 0.0712\n",
      "Epoch: 27/30... Training loss: 0.0784\n",
      "Epoch: 27/30... Training loss: 0.0734\n",
      "Epoch: 27/30... Training loss: 0.0709\n",
      "Epoch: 27/30... Training loss: 0.0724\n",
      "Epoch: 27/30... Training loss: 0.0670\n",
      "Epoch: 27/30... Training loss: 0.0698\n",
      "Epoch: 27/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0688\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0682\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0682\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0660\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0671\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0797\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0803\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0788\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0671\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0776\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0772\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0787\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0801\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0789\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0775\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0663\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0777\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0677\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0676\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0771\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0682\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0650\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0804\n",
      "Epoch: 28/30... Training loss: 0.0796\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0790\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0782\n",
      "Epoch: 28/30... Training loss: 0.0666\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0795\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0775\n",
      "Epoch: 28/30... Training loss: 0.0675\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0674\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0782\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0779\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0673\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0677\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0778\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0771\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0809\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0775\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0679\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0674\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0675\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0775\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0788\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0817\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0686\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0775\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0677\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0681\n",
      "Epoch: 28/30... Training loss: 0.0772\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0807\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0802\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0679\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0775\n",
      "Epoch: 28/30... Training loss: 0.0803\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0778\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0682\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0787\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0774\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0672\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0771\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0659\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0682\n",
      "Epoch: 28/30... Training loss: 0.0769\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0660\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0792\n",
      "Epoch: 28/30... Training loss: 0.0652\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0686\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0836\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0675\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0655\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0688\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0775\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0778\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0772\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0781\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0675\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0774\n",
      "Epoch: 28/30... Training loss: 0.0771\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0625\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0680\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0683\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0683\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0672\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0784\n",
      "Epoch: 28/30... Training loss: 0.0778\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0689\n",
      "Epoch: 28/30... Training loss: 0.0771\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0686\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0764\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0669\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0780\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0652\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0687\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0702\n",
      "Epoch: 28/30... Training loss: 0.0791\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0672\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0750\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0700\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0787\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0684\n",
      "Epoch: 28/30... Training loss: 0.0760\n",
      "Epoch: 28/30... Training loss: 0.0686\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0772\n",
      "Epoch: 28/30... Training loss: 0.0676\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0781\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0690\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0678\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0666\n",
      "Epoch: 28/30... Training loss: 0.0677\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0679\n",
      "Epoch: 28/30... Training loss: 0.0720\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0762\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0756\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0734\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0677\n",
      "Epoch: 28/30... Training loss: 0.0778\n",
      "Epoch: 28/30... Training loss: 0.0679\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0698\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0693\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0681\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0659\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0801\n",
      "Epoch: 28/30... Training loss: 0.0739\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0754\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0784\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0751\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0677\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0666\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0697\n",
      "Epoch: 28/30... Training loss: 0.0782\n",
      "Epoch: 28/30... Training loss: 0.0770\n",
      "Epoch: 28/30... Training loss: 0.0703\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0761\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0724\n",
      "Epoch: 28/30... Training loss: 0.0809\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0704\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0757\n",
      "Epoch: 28/30... Training loss: 0.0740\n",
      "Epoch: 28/30... Training loss: 0.0771\n",
      "Epoch: 28/30... Training loss: 0.0688\n",
      "Epoch: 28/30... Training loss: 0.0691\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0729\n",
      "Epoch: 28/30... Training loss: 0.0727\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0769\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0695\n",
      "Epoch: 28/30... Training loss: 0.0745\n",
      "Epoch: 28/30... Training loss: 0.0736\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0679\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0753\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0744\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0710\n",
      "Epoch: 28/30... Training loss: 0.0725\n",
      "Epoch: 28/30... Training loss: 0.0717\n",
      "Epoch: 28/30... Training loss: 0.0758\n",
      "Epoch: 28/30... Training loss: 0.0711\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0686\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0713\n",
      "Epoch: 28/30... Training loss: 0.0743\n",
      "Epoch: 28/30... Training loss: 0.0730\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0715\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0696\n",
      "Epoch: 28/30... Training loss: 0.0726\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0719\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0679\n",
      "Epoch: 28/30... Training loss: 0.0769\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0728\n",
      "Epoch: 28/30... Training loss: 0.0749\n",
      "Epoch: 28/30... Training loss: 0.0777\n",
      "Epoch: 28/30... Training loss: 0.0771\n",
      "Epoch: 28/30... Training loss: 0.0721\n",
      "Epoch: 28/30... Training loss: 0.0767\n",
      "Epoch: 28/30... Training loss: 0.0778\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0708\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0741\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0723\n",
      "Epoch: 28/30... Training loss: 0.0766\n",
      "Epoch: 28/30... Training loss: 0.0738\n",
      "Epoch: 28/30... Training loss: 0.0692\n",
      "Epoch: 28/30... Training loss: 0.0746\n",
      "Epoch: 28/30... Training loss: 0.0737\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0712\n",
      "Epoch: 28/30... Training loss: 0.0718\n",
      "Epoch: 28/30... Training loss: 0.0685\n",
      "Epoch: 28/30... Training loss: 0.0699\n",
      "Epoch: 28/30... Training loss: 0.0755\n",
      "Epoch: 28/30... Training loss: 0.0694\n",
      "Epoch: 28/30... Training loss: 0.0782\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0683\n",
      "Epoch: 28/30... Training loss: 0.0765\n",
      "Epoch: 28/30... Training loss: 0.0742\n",
      "Epoch: 28/30... Training loss: 0.0748\n",
      "Epoch: 28/30... Training loss: 0.0707\n",
      "Epoch: 28/30... Training loss: 0.0735\n",
      "Epoch: 28/30... Training loss: 0.0768\n",
      "Epoch: 28/30... Training loss: 0.0731\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0705\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0716\n",
      "Epoch: 28/30... Training loss: 0.0733\n",
      "Epoch: 28/30... Training loss: 0.0747\n",
      "Epoch: 28/30... Training loss: 0.0709\n",
      "Epoch: 28/30... Training loss: 0.0812\n",
      "Epoch: 28/30... Training loss: 0.0732\n",
      "Epoch: 28/30... Training loss: 0.0771\n",
      "Epoch: 28/30... Training loss: 0.0759\n",
      "Epoch: 28/30... Training loss: 0.0797\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0722\n",
      "Epoch: 28/30... Training loss: 0.0763\n",
      "Epoch: 28/30... Training loss: 0.0701\n",
      "Epoch: 28/30... Training loss: 0.0752\n",
      "Epoch: 28/30... Training loss: 0.0706\n",
      "Epoch: 28/30... Training loss: 0.0714\n",
      "Epoch: 28/30... Training loss: 0.0773\n",
      "Epoch: 28/30... Training loss: 0.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0776\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0677\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0767\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0778\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0781\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0790\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0685\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0798\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0790\n",
      "Epoch: 29/30... Training loss: 0.0679\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0774\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0773\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0664\n",
      "Epoch: 29/30... Training loss: 0.0772\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0767\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0671\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0670\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0672\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0773\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0678\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0677\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0782\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0678\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0644\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0786\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0642\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0779\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0777\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0679\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0672\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0773\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0779\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0685\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0789\n",
      "Epoch: 29/30... Training loss: 0.0676\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0676\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0776\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0782\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0780\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0767\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0799\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/30... Training loss: 0.0778\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0779\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0791\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0668\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0672\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0776\n",
      "Epoch: 29/30... Training loss: 0.0683\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0793\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0683\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0773\n",
      "Epoch: 29/30... Training loss: 0.0788\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0684\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0641\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0675\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0783\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0675\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0776\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0772\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0777\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0663\n",
      "Epoch: 29/30... Training loss: 0.0677\n",
      "Epoch: 29/30... Training loss: 0.0783\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0778\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0782\n",
      "Epoch: 29/30... Training loss: 0.0784\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0777\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0778\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0669\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0779\n",
      "Epoch: 29/30... Training loss: 0.0672\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0785\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0785\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0775\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0807\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0665\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0683\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0770\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0770\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0675\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0774\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0684\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0675\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0784\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0667\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0677\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0632\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0680\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0674\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0798\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0774\n",
      "Epoch: 29/30... Training loss: 0.0803\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0770\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0765\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0789\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0665\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0768\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0707\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0776\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0651\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0778\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0775\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0778\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0684\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0689\n",
      "Epoch: 29/30... Training loss: 0.0786\n",
      "Epoch: 29/30... Training loss: 0.0787\n",
      "Epoch: 29/30... Training loss: 0.0684\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0786\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0785\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0701\n",
      "Epoch: 29/30... Training loss: 0.0684\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0685\n",
      "Epoch: 29/30... Training loss: 0.0673\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0800\n",
      "Epoch: 29/30... Training loss: 0.0805\n",
      "Epoch: 29/30... Training loss: 0.0763\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0718\n",
      "Epoch: 29/30... Training loss: 0.0766\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0776\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0683\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0784\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0680\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0679\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0775\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0768\n",
      "Epoch: 29/30... Training loss: 0.0676\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0689\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0696\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0767\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0773\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0777\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0731\n",
      "Epoch: 29/30... Training loss: 0.0783\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0772\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0674\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0678\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0773\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0729\n",
      "Epoch: 29/30... Training loss: 0.0685\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0666\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0802\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0773\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0780\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0786\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0686\n",
      "Epoch: 29/30... Training loss: 0.0670\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0683\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0741\n",
      "Epoch: 29/30... Training loss: 0.0772\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0687\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0771\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0699\n",
      "Epoch: 29/30... Training loss: 0.0728\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0705\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0725\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0726\n",
      "Epoch: 29/30... Training loss: 0.0674\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0691\n",
      "Epoch: 29/30... Training loss: 0.0670\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0711\n",
      "Epoch: 29/30... Training loss: 0.0694\n",
      "Epoch: 29/30... Training loss: 0.0743\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0775\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0695\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0742\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0768\n",
      "Epoch: 29/30... Training loss: 0.0689\n",
      "Epoch: 29/30... Training loss: 0.0706\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0764\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0784\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0744\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0750\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0719\n",
      "Epoch: 29/30... Training loss: 0.0680\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0775\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0737\n",
      "Epoch: 29/30... Training loss: 0.0758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/30... Training loss: 0.0685\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0717\n",
      "Epoch: 29/30... Training loss: 0.0747\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0690\n",
      "Epoch: 29/30... Training loss: 0.0761\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0669\n",
      "Epoch: 29/30... Training loss: 0.0769\n",
      "Epoch: 29/30... Training loss: 0.0786\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0665\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0796\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0709\n",
      "Epoch: 29/30... Training loss: 0.0722\n",
      "Epoch: 29/30... Training loss: 0.0759\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0757\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0700\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0762\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0710\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0675\n",
      "Epoch: 29/30... Training loss: 0.0681\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0777\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0768\n",
      "Epoch: 29/30... Training loss: 0.0682\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0685\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0754\n",
      "Epoch: 29/30... Training loss: 0.0720\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0753\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0723\n",
      "Epoch: 29/30... Training loss: 0.0688\n",
      "Epoch: 29/30... Training loss: 0.0736\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0724\n",
      "Epoch: 29/30... Training loss: 0.0708\n",
      "Epoch: 29/30... Training loss: 0.0738\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0756\n",
      "Epoch: 29/30... Training loss: 0.0746\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0752\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0745\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 29/30... Training loss: 0.0634\n",
      "Epoch: 29/30... Training loss: 0.0663\n",
      "Epoch: 29/30... Training loss: 0.0727\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0689\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0749\n",
      "Epoch: 29/30... Training loss: 0.0735\n",
      "Epoch: 29/30... Training loss: 0.0792\n",
      "Epoch: 29/30... Training loss: 0.0697\n",
      "Epoch: 29/30... Training loss: 0.0713\n",
      "Epoch: 29/30... Training loss: 0.0715\n",
      "Epoch: 29/30... Training loss: 0.0733\n",
      "Epoch: 29/30... Training loss: 0.0785\n",
      "Epoch: 29/30... Training loss: 0.0716\n",
      "Epoch: 29/30... Training loss: 0.0712\n",
      "Epoch: 29/30... Training loss: 0.0702\n",
      "Epoch: 29/30... Training loss: 0.0693\n",
      "Epoch: 29/30... Training loss: 0.0672\n",
      "Epoch: 29/30... Training loss: 0.0739\n",
      "Epoch: 29/30... Training loss: 0.0740\n",
      "Epoch: 29/30... Training loss: 0.0698\n",
      "Epoch: 29/30... Training loss: 0.0721\n",
      "Epoch: 29/30... Training loss: 0.0730\n",
      "Epoch: 29/30... Training loss: 0.0755\n",
      "Epoch: 29/30... Training loss: 0.0704\n",
      "Epoch: 29/30... Training loss: 0.0748\n",
      "Epoch: 29/30... Training loss: 0.0714\n",
      "Epoch: 29/30... Training loss: 0.0751\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0758\n",
      "Epoch: 29/30... Training loss: 0.0734\n",
      "Epoch: 29/30... Training loss: 0.0692\n",
      "Epoch: 29/30... Training loss: 0.0703\n",
      "Epoch: 29/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0783\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0798\n",
      "Epoch: 30/30... Training loss: 0.0803\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0802\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0675\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0812\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0653\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0776\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0659\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0681\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0661\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0809\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0779\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0674\n",
      "Epoch: 30/30... Training loss: 0.0756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0669\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0683\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0787\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0683\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0791\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0683\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0680\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0774\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0770\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0666\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0666\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0657\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0784\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0775\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0778\n",
      "Epoch: 30/30... Training loss: 0.0788\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0777\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0785\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0686\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0683\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0676\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0680\n",
      "Epoch: 30/30... Training loss: 0.0681\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0655\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0783\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0780\n",
      "Epoch: 30/30... Training loss: 0.0779\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0784\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0776\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0682\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0679\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0781\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0789\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0775\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0779\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0653\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0683\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0795\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0685\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0794\n",
      "Epoch: 30/30... Training loss: 0.0670\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0775\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0784\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0686\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0670\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0772\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0784\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0674\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0682\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0669\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0777\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0672\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0786\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0671\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0783\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0667\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0784\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0682\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0782\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/30... Training loss: 0.0655\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0783\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0682\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0797\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0775\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0778\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0681\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0776\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0775\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0670\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0685\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0686\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0681\n",
      "Epoch: 30/30... Training loss: 0.0677\n",
      "Epoch: 30/30... Training loss: 0.0686\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0677\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0676\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0779\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0672\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0666\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0683\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0656\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0797\n",
      "Epoch: 30/30... Training loss: 0.0683\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0785\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0656\n",
      "Epoch: 30/30... Training loss: 0.0734\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0686\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0796\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0682\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0681\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0725\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0770\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0810\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0683\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0751\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0674\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0770\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0661\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0671\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0702\n",
      "Epoch: 30/30... Training loss: 0.0767\n",
      "Epoch: 30/30... Training loss: 0.0775\n",
      "Epoch: 30/30... Training loss: 0.0705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0659\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0778\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0770\n",
      "Epoch: 30/30... Training loss: 0.0795\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0675\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0768\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0674\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0795\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0771\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0675\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0696\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0689\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0678\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0722\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0684\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0773\n",
      "Epoch: 30/30... Training loss: 0.0711\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0688\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0795\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0683\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0699\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0692\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0777\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0716\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0700\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0701\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0666\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0713\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0772\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0759\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0695\n",
      "Epoch: 30/30... Training loss: 0.0764\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0745\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0748\n",
      "Epoch: 30/30... Training loss: 0.0757\n",
      "Epoch: 30/30... Training loss: 0.0709\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0755\n",
      "Epoch: 30/30... Training loss: 0.0690\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0738\n",
      "Epoch: 30/30... Training loss: 0.0677\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0715\n",
      "Epoch: 30/30... Training loss: 0.0769\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0679\n",
      "Epoch: 30/30... Training loss: 0.0728\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0652\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0782\n",
      "Epoch: 30/30... Training loss: 0.0698\n",
      "Epoch: 30/30... Training loss: 0.0780\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0727\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0735\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0744\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0705\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0679\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0694\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0756\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0736\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0765\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0719\n",
      "Epoch: 30/30... Training loss: 0.0677\n",
      "Epoch: 30/30... Training loss: 0.0671\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0739\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0691\n",
      "Epoch: 30/30... Training loss: 0.0718\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0687\n",
      "Epoch: 30/30... Training loss: 0.0770\n",
      "Epoch: 30/30... Training loss: 0.0763\n",
      "Epoch: 30/30... Training loss: 0.0707\n",
      "Epoch: 30/30... Training loss: 0.0742\n",
      "Epoch: 30/30... Training loss: 0.0682\n",
      "Epoch: 30/30... Training loss: 0.0760\n",
      "Epoch: 30/30... Training loss: 0.0746\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0729\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0731\n",
      "Epoch: 30/30... Training loss: 0.0708\n",
      "Epoch: 30/30... Training loss: 0.0747\n",
      "Epoch: 30/30... Training loss: 0.0714\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0737\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0762\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0784\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0721\n",
      "Epoch: 30/30... Training loss: 0.0703\n",
      "Epoch: 30/30... Training loss: 0.0668\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0706\n",
      "Epoch: 30/30... Training loss: 0.0752\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0758\n",
      "Epoch: 30/30... Training loss: 0.0741\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0733\n",
      "Epoch: 30/30... Training loss: 0.0761\n",
      "Epoch: 30/30... Training loss: 0.0730\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0726\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0724\n",
      "Epoch: 30/30... Training loss: 0.0712\n",
      "Epoch: 30/30... Training loss: 0.0717\n",
      "Epoch: 30/30... Training loss: 0.0777\n",
      "Epoch: 30/30... Training loss: 0.0697\n",
      "Epoch: 30/30... Training loss: 0.0753\n",
      "Epoch: 30/30... Training loss: 0.0749\n",
      "Epoch: 30/30... Training loss: 0.0766\n",
      "Epoch: 30/30... Training loss: 0.0704\n",
      "Epoch: 30/30... Training loss: 0.0693\n",
      "Epoch: 30/30... Training loss: 0.0723\n",
      "Epoch: 30/30... Training loss: 0.0710\n",
      "Epoch: 30/30... Training loss: 0.0669\n",
      "Epoch: 30/30... Training loss: 0.0658\n",
      "Epoch: 30/30... Training loss: 0.0740\n",
      "Epoch: 30/30... Training loss: 0.0754\n",
      "Epoch: 30/30... Training loss: 0.0732\n",
      "Epoch: 30/30... Training loss: 0.0683\n",
      "Epoch: 30/30... Training loss: 0.0720\n",
      "Epoch: 30/30... Training loss: 0.0743\n",
      "Epoch: 30/30... Training loss: 0.0750\n",
      "Epoch: 30/30... Training loss: 0.0668\n"
     ]
    }
   ],
   "source": [
    "info = {'losses':[]}\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):\n",
    "    mini_batches = prepare_mini_batches(images_for_autoencoder, \n",
    "                                        images_for_autoencoder_labels, \n",
    "                                        batch_size)\n",
    "\n",
    "    epoch_losses = []\n",
    "    while mini_batches:\n",
    "        data_inputs, data_labels = mini_batches.pop()\n",
    "        \n",
    "        # target for net is to decrease image size (encode) \n",
    "        # and return the same image as inserted (decode)\n",
    "        session.run(optimizer, feed_dict={inputs_: data_inputs, \n",
    "                                          targets_: data_inputs, \n",
    "                                          learning_rate_: learning_rate})\n",
    "        \n",
    "        batch_loss = session.run(cost_value, feed_dict={inputs_: data_inputs, \n",
    "                                                        targets_: data_inputs})\n",
    "        epoch_losses.append(batch_loss)\n",
    "    \n",
    "        print(\"Epoch: {}/{}...\".format(epoch + 1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_loss))\n",
    "        \n",
    "    info['losses'].extend(epoch_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results - image encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# picking test image which autoencoder haven't seen yet\n",
    "test_index = 123\n",
    "random_test_image = test_images[test_index]\n",
    "random_test_image_label = test_images_labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following 64 numbers:\n",
      "\n",
      "[  5.75574684   6.62885427  14.43285942   4.13562393   1.29604983\n",
      "   7.43110991   3.63029194   5.63317442   8.62694836   7.09006786\n",
      "   4.07881975   4.06688118   5.37700272   4.73379469   9.53277969\n",
      "   7.02862597   9.5177002    7.9204936    5.98649025   9.51074886\n",
      "   4.77861881   6.81946945   6.92254543   2.17433214   7.08597755\n",
      "  11.05838871  11.83332443   9.40194988   5.34436321   0.33687806\n",
      "   3.78617525   5.15237045   4.56567383   7.22619963   3.99176002\n",
      "   2.72120714   5.2136364    8.34004974   6.38794708   2.68318582\n",
      "   9.9825592    1.09425628   8.07583904   6.81430674  15.13267994\n",
      "   9.36961365   3.17193699   7.94427013   8.12602043   5.24046326\n",
      "   3.76466179   7.38884163   3.82453418   6.10837507   5.2041831\n",
      "   3.2201097    7.64097691   6.01061058   5.54388237   4.1491642\n",
      "   3.27384329  11.30130959   6.77349329   9.44119072]\n",
      "\n",
      "Represents an image: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzIBddTGpyYsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bd12ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We can use encoding to pass it to trained model and decode data: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c0c8b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encoding image into `encoding size` values\n",
    "encoded_test_image = session.run([encoded], feed_dict={inputs_: [random_test_image]})\n",
    "\n",
    "# encoding presentation\n",
    "print(\"Following \" + str(len(encoded_test_image[0][0])) + \" numbers:\\n\")\n",
    "print(encoded_test_image[0][0])\n",
    "print(\"\\nRepresents an image: \")\n",
    "plt.imshow(random_test_image.reshape(28, 28), cmap=\"gray_r\")\n",
    "plt.show()\n",
    "\n",
    "# decoding -> recreating image from `encoding size` numbers array\n",
    "print(\"\\nWe can use encoding to pass it to trained model and decode data: \")\n",
    "decoded_test_image = session.run([decoded], feed_dict={encoded: [encoded_test_image[0][0]]})\n",
    "\n",
    "# decoding presentation\n",
    "plt.imshow(decoded_test_image[0][0].reshape((28, 28)), cmap=\"gray_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More results: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHhkkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c379278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c1c7f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAGLgfwFT/rPd6j3oZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114216898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAgAP8HXJVH8mL02i4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114942cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xe8lNW1+P+N0nvv1YIQQFRCu6J4Ayoq5IKgSFESQAho\niBiQiAIS7IVIhIixoUkQLpFgyY1SpHgT9V6qdFQEQgeld/B8//j9su9aS+ZhZpg5Z/acz/uvtV9r\nzjNbZp9nnvP4rLUL5OTkOAAAAAAAAGS2C/J6AgAAAAAAADg3buIAAAAAAAAEgJs4AAAAAAAAAeAm\nDgAAAAAAQAC4iQMAAAAAABAAbuIAAAAAAAAEgJs4AAAAAAAAAeAmDgAAAAAAQAC4iQMAAAAAABCA\ngom8uGLFijl169ZN01SQV5YsWbI3JyenUrqOz7rJXqwdJIN1g2SxdpAM1g2SxdpBMlg3SFa8ayeh\nmzh169Z1ixcvTn5WyEgFChTYnM7js26yF2sHyWDdIFmsHSSDdYNksXaQDNYNkhXv2qGcCgAAAAAA\nIADcxAEAAAAAAAgAN3EAAAAAAAACwE0cAAAAAACAAHATBwAAAAAAIADcxAEAAAAAAAgAN3EAAAAA\nAAACwE0cAAAAAACAAHATBwAAAAAAIADcxAEAAAAAAAgAN3EAAAAAAAACwE0cAAAAAACAABTM6wkA\nmWj//v1qXLp0aR9fcAH3PgHkni+//FKN33rrLR9/9NFHKrdt2zY1/uKLL+J6D3mOs8dt1qxZXMcA\nAOBfli5d6uMnn3xS5WbMmKHGH3/8sY/btGmT3okhKPY6p1+/fmq8aNEiH9eqVStX5pQJ+GsUAAAA\nAAAgANzEAQAAAAAACAA3cQAAAAAAAAKQFT1xXn31VTXu379/Use59NJLYx6jU6dOatywYcOk3gNh\nuO2229S4RIkSPrZro2PHjrkyp3js3r1bjcuXL+/jggWz4tcdyBdkH5pVq1ap3KlTp+I+ToECBeJ6\n3aFDh9S4devWPi5TpozK7dmzJ+73BxAGeQ6wfbCKFSvm4xdeeEHlrr322vRODBlN9my7++67Ve6z\nzz7z8bFjxyKP89xzz/mYnjjYvHmzj20PnE2bNqnxa6+95uMHHnhA5eS5K9vwJA4AAAAAAEAAuIkD\nAAAAAAAQgGDrK2R505w5c1JyTLkV64gRI1Ru586dajx+/PiUvCcy01VXXaXGTz/9tI/btm2b29OJ\n2/PPP6/GsuzimWeeye3pZJWaNWv6uFy5cio3cuRIH/fo0SMt779kyRIfz549O+brXnzxRTXeunWr\njytXrqxyc+fO9XHjxo3Pd4pI0LRp03w8cOBAlTt69KiPz5w5o3JyC82uXbuq3J133qnGskw4yh/+\n8Ac1vueee3z8zTffqNyECRN8/Itf/CKu4wPIbEWKFPGx/L5zzrmFCxf6+LHHHlM5yqmyn/wOmjdv\nnsp169bNx7Yst2LFij4uVaqUytny/xMnTpz3PJE9vvrqKx/b8inrkUce8fGKFStUbubMmamcVkbh\nSRwAAAAAAIAAcBMHAAAAAAAgANzEAQAAAAAACEAwPXEWLFigxrIm09ZRXn755T6uU6dOzGM+9NBD\naiy3cbXbSE+cOFGNZc+U3r17x3wPhEn2nMh0sieU7dUkfzfoiXN+3nrrLR/feuutKveTn/zEx4MG\nDUrJ++Xk5Kix7G+USO243GLabg29bNkyH9MTJ/3eeOMNNR49erSPbS+B7t27+7hFixYqJ7fbLF26\ndErmZns5/e53v/Px6tWrVe7kyZMpeU9oH3/8sRpPmTLFx3ab1KuvvtrHRYsWVbn333/fx3Lr1URd\ndtllZ30/Ox/ZP8k55xo2bJj0eyLvFC5c2MeVKlWK+botW7aosT0fyOMgTLt27VLjPn36+PjDDz9U\nuZIlS/r4lVdeUbkOHTr4+O2331Y5+qkhyrPPPpvXU8h4PIkDAAAAAAAQAG7iAAAAAAAABCCYcqom\nTZqocefOnX188OBBlXv55Zd9XK1atbjfwx5HkqUMzjm3b9++uI+L8MhSgkw3f/58H9syG7tVOpJ3\nzTXX+HjGjBkq99RTT/k4avvvRNhyKlkWhXD88Y9/9PF9992ncgcOHPCx3KbVOV3+aLf7TYeyZcuq\nsVzvtpwKqbN9+3YfDxkyROWWL1/uY/v7H/UdJcurbFmMLJHasGFD5Nzkdc7UqVNVTn7X2O3p169f\n7+OqVatGvgfCIz9f55z75JNP1Lht27a5OR2kyN69e3180003qdzatWt9/Oqrr6qcLJmqXr160u9f\nt27dpH8W+Bd7LZPNeBIHAAAAAAAgANzEAQAAAAAACAA3cQAAAAAAAAIQTE+cChUqqLGtz063QoUK\nqXGqtnVF5pBbzMs+BZlu7ty5MXNjxozJxZnkH9ddd50aN2/e3Mdbt26N+XO279aaNWt83KpVq6Tn\n07FjRx9v3Lgx5utatmypxrVr1076PXF2dkvngQMH+rhevXoqJ/tZNWrUSOXsdw6y07Bhw3y8YsWK\npI4ht6p3TvcMvOKKK5KbmCH78zjn3I9//GMf23PewoULfdy9e/eUvD+A9JI9cQYMGKBysmdbxYoV\n0/L+w4cPT8txkf3kNvfyOzXb8SQOAAAAAABAALiJAwAAAAAAEIBgyqnS4dChQ2pstw2WBg8erMZ9\n+vRJy5yQd+Q2mXLrX6tEiRK5MZ2Y7Dbip06d8nGxYsVU7tprr82VOeV3ck3ILXzPRZZhJeL9999X\n4x07dsR8bePGjX3817/+VeXKlSuX1PsjNlsyd+bMGR/b75FUlbqkwrFjx9RYluXJR5Wdc65fv365\nMqdscfr0aR/ffvvtKvfee+/F/Dl5XvnVr36lcoMGDfKx/T2+4ILU//85u1ajvgfbt2+f8vdH7mrT\npo0ay+vjnJwclXvxxRfVmC3Gw9SgQYOzxulSqVIlNbblxshfbCuAZcuWxf2zssXBD37wg1RNKePx\nJA4AAAAAAEAAuIkDAAAAAAAQAG7iAAAAAAAABCDf9cSRfU86dOigcraXgWS35kX4Dh8+rMbPPfdc\nzNd26dLFx3brxdz2zjvvqLHc+tXOrWzZsrkyJ+Suzz//XI1tPxOpePHiPqYHTvr17t1bjdu1a+fj\n3OgzkKx//OMfajx79mwfly5dWuXKly+fK3PKFo888oiPZ82aFfN1nTp1UuNHH33Ux02aNEn5vBJh\nzzn//Oc/82gmyA12vRUoUCCPZoKQbdq0yce2d5Lcthx4+eWX1Xjnzp1x/2zVqlVTPZ0g8CQOAAAA\nAABAALiJAwAAAAAAEICsLKc6efKkj+3jeyNGjPCx3apZqlGjhhpn0lawSI2hQ4eq8fr162O+dsyY\nMemeTtxee+21vJ4C8sAbb7zh48cffzzun6tcuXI6poMYKlasGDnOJNu2bfNxjx49VK5w4cI+fuKJ\nJ3JtTtmoYMH/u9S6+uqrVU5uFd6zZ89cm1OiHnroITU+cuSIjwcOHKhyFSpUyJU5IX3kmrXjU6dO\nqdyaNWvUWK6NqK3okf1+//vf+7hMmTIql8h1DLLT0aNHfSzbnSSqf//+qZhOcHgSBwAAAAAAIADc\nxAEAAAAAAAgAN3EAAAAAAAACkBU9cTZv3qzGrVu39vGOHTuSOqbsFeCcczfffLMayx4Bd9xxR1Lv\ngdz37rvv+njGjBkxX1e3bl01vuyyy9I1pbgcOHDAx7t27crDmSC3HDp0SI2HDBni46gtxW3/Jrvt\nPPKvVatWqfH48eN9vHfvXpUbOXKkj2XfFiRObjEu40x3/PhxH7///vsqJ3ukdO7cOdfmhNzRpk0b\nNa5fv76PV69erXJ2LPtc0BMnf7HfI6+//rqPu3fvrnJly5bNlTkhc23cuNHHCxcuzMOZhIkncQAA\nAAAAAALATRwAAAAAAIAAZEU51enTp9U42RKqKJs2bVJjuRXoU089pXLy8UG2Js9bBw8eVONx48b5\nWJYoWX/5y1/UuGjRoqmdWIK+/vprHy9fvjzm6/r165cb00EayNIF55y78cYb1fjw4cMxf7ZQoUI+\n7tixo8pVrVo1BbNDqOR2v7IkzznnFixY4ONmzZqpHCVU6Nu3b8zcbbfd5uMOHTrkxnQAZLhf//rX\naizLwjlPIFXKly+vxqVLl86jmeQtnsQBAAAAAAAIADdxAAAAAAAAAsBNHAAAAAAAgABkRU+cIkWK\nqHG8fWhGjRqlxlE1dY8//rgaz58/38e2R0mnTp18PGvWLJWzfQeQXrt371bjxYsXx3xtly5dfNyk\nSZO0zSmdKlSokNdTQAJkH5z27dur3KeffqrGBQoUiHmc3/72tz6+6qqrUjQ7hEj2wHFO98GRPXCc\n09+do0ePVrkaNWqkfnLIaF988YUaz5w5M+Zrf/WrX6V7OsggOTk5Z42B/fv3+/izzz5Tufvuu8/H\n9MRBqti/pRs2bJhHM8lbPIkDAAAAAAAQAG7iAAAAAAAABICbOAAAAAAAAAHIip44NWvWVONly5al\n/D2KFy+uxrIHxfTp01Vu69atPr711ltVbt68eT6+5JJLUjlF/P8+/PBDH48cOTLm6y699FI1njRp\nko8vvPBClZM14LbnRJRChQqp8alTp2K+tkSJEj6O6n9iyV4+F110Udw/h9x36NAhNb7xxht9bHvg\nRPUd6NOnjxoPGDAgBbNDiKJ64Djn3Ouvv+7jH/7whyone73ZnkzIf9atW6fGJ0+e9HG3bt1Uzn5/\nIrvJaxJ7fZLI9Qqyz7333uvjHTt2qNzdd9+dq3Ox34cTJkzw8Z///GeVk9+NTZs2Te/EkFL9+/fP\n6ylkBJ7EAQAAAAAACAA3cQAAAAAAAAKQFeVUueHf/u3f1Lhly5Y+PnbsmMq9++67Pt6yZYvKyS2v\nKadKj3feecfHS5cujfm6EydOqPFjjz0W87Vnzpzx8eTJk+Oey5VXXqnGUaV+f/rTn3wst6l3zrnZ\ns2fH/LmyZcv6mMeaM8++fft8LEv2nNPbcZ7rs5P5Vq1apWh2CJF8ZDyqfMo5XW48btw4laOEKn/7\n5ptv1Piuu+5SY1nSOWPGjFyZE4DMJq+xndPXrmPGjFG5OnXqpPz9Dxw4oMZz5szx8cMPP6xyGzdu\n9PHgwYNV7uKLL0753JAezZs3V+Nbbrklj2aSWXgSBwAAAAAAIADcxAEAAAAAAAgAN3EAAAAAAAAC\nQE+cJMktqG19qNxW/C9/+YvK9erVy8e2zwlbdqbG22+/HdfrbL8i268kFQ4fPqzGtWvX9nHp0qVV\nTq4NuxXwnj17Yr7HoEGDzmeKSLO//e1vPrb14omQ2/+ylXyY7DlH9tqyJk6c6GPZS80553bt2uXj\nuXPnqpzsgWPz9evXj3+yyErfffedj+W5ybnv95qQfbgaNmwY93vUq1fPx//1X/+V6BSRgRo3buzj\n1atX5+FMkBdkD8lHHnlE5WrUqOFjeR17Pvbu3avGzz77rI9feuklldu/f/9Z5+Kc7pfTtm3blMwN\nqVOpUiUfN2jQQOXkNe/KlStVbtq0aWrcr1+/NMwu8/EkDgAAAAAAQAC4iQMAAAAAABAAyqnS4IYb\nbvCxLafatGmTj9evX69ylFOlxqhRo3z885//PObr7NaHVapU8XGJEiVi/tyPfvQjNbZb30ktWrRQ\n46NHj/q4YsWKKrdo0SIfv/DCCyq3ePFiH19xxRUqR4lEZpFbijv3/c8yFvm4unPffzxUbod5wQXc\nf89UtoRSPs595513qpw8H6TK1q1b1fjee+/18bBhw1SuadOmPpbnP8uWcz344IM+7ty5s8p16tQp\n/ski7ew24nI9TJ8+Pe7jyEfbndOlVlZUDmFatWpVXk8BeUiWUC1fvlzl5s2b5+NE/o753//9XzUe\nMWKEj+fPnx/z51q3bq3GXbp08fHw4cPjfn/kvdOnT/v4+PHjMV9nc/a7i3IqAAAAAAAAZCxu4gAA\nAAAAAASAmzgAAAAAAAABoCdOCqxdu1aNH3300TyaCZxz7mc/+5mPW7ZsGfN11apVU+Py5cv7uHjx\n4qmfmHOuXLlyMXPXX3+9j+229ZKtBy5Tpsz5Twzn5dtvv/Vx3759Ve5//ud/Yv5coUKFfCz7jDjn\n3B133JGi2SHdZs2a5ePnnntO5f7+97+f9/ELFy6sxqVLl/Zx+/btVW7mzJlqLLcYt9uRy+P07NlT\n5WRvmw8//FDlZB+w6tWrR84deevmm29WY9uHIor8TrLrrGvXrj6230EXXnhhIlNEAHJycs4aIzvt\n2bNHjadMmeLjm266SeVkn0jZ99M53RPu7bffVjnb90Zed3fs2FHl5Pmmd+/eKlewIH/Khqpo0aI+\n5m+ZxPEkDgAAAAAAQAC4iQMAAAAAABAAnkGLwW4Tu2TJEjWW5S4zZsxQuW3btsU8btmyZX1coUKF\n85kiYpCPVkZt/53JxowZo8ZDhw71sS0DQ+6z24hPnTrVx++9917cx7nnnnt8TPlUOE6cOKHG8rM7\nefJkSt6jZMmSPn7qqadUbtCgQTF/buLEiWo8cuRIH9vvtYMHD/p48uTJKicfn7/99ttVTpasIrPd\neuutaiy3Cn7yySdVbuXKlWo8adIkH19yySWpnxyCIbdxXrNmjcqxpXz2kb/7zjm3c+dOH8vSJuf0\nOcV+j+zatcvHtuxJlmE559yoUaN83KZNm8QmjCDJLcbtdRXOjSdxAAAAAAAAAsBNHAAAAAAAgABw\nEwcAAAAAACAA+a4njtwO3G6T+Pzzz/t43bp1Kvfxxx8n9X6XXnqpGsvtx+1W0cC/VKpUKXKMvDVg\nwAA1tts6x1KxYkU1vvfee1M2J+SepUuXqvF3332X1HGKFCni4/vuu0/l7r//fh8n8vtv11T37t19\nLPvcOOfcRx99FPM4TzzxhI+vuOKKuN8fmWXEiBFqPGvWLB8vWrRI5Ro0aKDG9MHBv9CLL/vJ/iRv\nvvlmzNf1798/7mO2bdvWx7I/m3PO3XDDDQnMDtlI/h2e7HVUfsaTOAAAAAAAAAHgJg4AAAAAAEAA\nsqKc6syZM2q8fft2H48ePVrl5COCqXp0q3Llymo8btw4H/fo0UPlSpUqlZL3BJC7jh496uPPP/88\nqWP07t1bjevVq3dec0LesKWwY8eO9bH9Plq8eLGPGzZsqHKy1KVs2bKpnKInS7GGDx+ucnaM7Ldh\nwwYf262hmzZtmtvTAZAhlixZ4uOvv/465uvs1uDdunXzsb2mueaaa3xcokSJ850iskzVqlV9PHDg\nQJX75S9/GfPn5LrKz3gSBwAAAAAAIADcxAEAAAAAAAgAN3EAAAAAAAACkBU9cQ4dOqTG06dP9/HW\nrVtVLt4+ODVq1FBju/3rhRde6OOhQ4fGdUwA4XrnnXd8HFUvbtWpU8fHdmtyZIcHH3wwr6cAnLdm\nzZrl9RSQoe644w4fv/TSSypnr5fLlSuXK3NCarVs2dLHcutnIDfcf//9kWN8H0/iAAAAAAAABICb\nOAAAAAAAAAHIinIquzXrsGHDzhoDQLJ69Ojh43Hjxqmc3VZaevrpp3182WWXpX5iAACkUfny5X28\nYsWKPJwJAMA5nsQBAAAAAAAIAjdxAAAAAAAAAsBNHAAAAAAAgABkRU8cAMhNa9asyespAEDCLr/8\nch9fc801Kte1a9fcng4AAEgCT+IAAAAAAAAEgJs4AAAAAAAAAaCcCgAAIB/o0KHDWWMAABAOnsQB\nAAAAAAAIADdxAAAAAAAAAsBNHAAAAAAAgAAUyMnJif/FBQrscc5tTt90kEfq5OTkVErXwVk3WY21\ng2SwbpAs1g6SwbpBslg7SAbrBsmKa+0kdBMHAAAAAAAAeYNyKgAAAAAAgABwEwcAAAAAACAA3MQB\nAAAAAAAIADdxAAAAAAAAAsBNHAAAAAAAgABwEwcAAAAAACAA3MQBAAAAAAAIADdxAAAAAAAAAsBN\nHAAAAAAAgABwEwcAAAAAACAA3MQBAAAAAAAIADdxAAAAAAAAAsBNHAAAAAAAgABwEwcAAAAAACAA\n3MQBAAAAAAAIADdxAAAAAAAAAsBNHAAAAAAAgAAUTOTFFStWzKlbt26apoK8smTJkr05OTmV0nV8\n1k32Yu0gGawbJIu1g2SwbpAs1g6SwbpBsuJdOwndxKlbt65bvHhx8rNCRipQoMDmdB6fdZO9WDtI\nBusGyWLtIBmsGySLtYNksG6QrHjXDuVUAAAAAAAAAeAmDgAAAAAAQAASKqcC8H2nTp3ycYECBVSu\nYEF+xQAAAAAAqcGTOAAAAAAAAAHgJg4AAAAAAEAAqPUAzlOhQoXyegpxycnJUWNb+gUAAAAAyGw8\niQMAAAAAABAAbuIAAAAAAAAEgJs4AAAAAAAAAaAnDpBP0AMHyD7fffedGtvfczm2r5UuuID/pwMA\nSI/Tp0+rsf3O4TsISAy/MQAAAAAAAAHgJg4AAAAAAEAAKKcC4iDLEOwjoYULFz7vY1o8Vgrkbzk5\nOT7+6quvVO6JJ57w8bx581TuxIkTanz48GEfnzp1KuZ7lC1bVuVGjhzp43vuuUflChbk0iFU8jOn\nxBaxHD9+XI3luilatKjKJbuO5DHP5zjIHHbdTJ482cfPP/+8ypUpUybma1u0aKFyF154YaqmiEDI\n65UFCxao3JIlS9T4P/7jP3xcv359lcvmtcNfigAAAAAAAAHgJg4AAAAAAEAAuIkDAAAAAAAQgGAL\n23ft2uXjl19+WeVeeeWVs77OOefOnDnj4+LFi6tctWrVfDxw4ECV69OnjxrL/gFRdby25lf2QbE/\nRx+UzGHrep988kkf23rLbt26+fhc/XHk52/7UxQqVCjheTpHj4O8YPsiyc/A1t/m9e+1nJs9H0l5\nPc/8SJ4PbN+b22+/3cerV69WOXnusL/z9jwi8/bzl+Pdu3er3NChQ308ZcoUlZs/f76PbS8dZDa+\nIxCL7Kc1depUlZs2bZqPH3jgAZVr166dGrPGspv9HpHfT3fddZfKLV++PObPWQMGDPDxZ599pnL2\n77VU4No5sx08eNDH9pyzbt06NX799dd9/Pe//13lKlasmIbZZQau2gEAAAAAAALATRwAAAAAAIAA\nZHQ5lXzUbc+ePSr305/+1Mdz5sxROVvqEMvRo0fVeNOmTT5+8MEHVc4+Tj537lwfJ/Kolnx8nvKF\nzCLX23vvvadyL730ko9bt26tcl26dEnqPezjm/E+zmkfSZXr3W4vXLJkybjnBs3+O+/bt8/Hs2bN\nUrmdO3f6+Morr1S5mjVr+rhevXoqJ0tf7HnryJEjarx3714ff/vttyonHx/9/e9/r3L79+/3ccuW\nLVXud7/7nY/r1q3rkHpyHW3evFnlZMmSLFFyTj9KbJUuXdrH/fr1U7n+/furcfXq1X1cpEgRlZNr\nSm7R6ZxzK1eu9LF9dHn8+PE+HjNmjMpl83aeoYgq25Ul5bb8N1WfXSIl5vH+HNJPXj/88Y9/VLlP\nPvnEx998843KLVq0SI1LlCgR8z3OVVITD7m+ndPrhjWUGvbfeMeOHT5+9dVXVU7+fSSvk5xzrmDB\n//sz056L7Gclt6637x8l3pLxZK+5kRj7GST7t83GjRt9vHbtWpWzf+vI186cOVPl5DVRtv3dnV3/\nNQAAAAAAAFmKmzgAAAAAAAAB4CYOAAAAAABAADK6J46s3T506JDKyT4Ptt5O1mDKbcOdc+7ee+/1\ncYsWLVTuzTff9PFbb72lcnb718WLF/u4Q4cOZ/8POMfcqMfMLLJH0sSJE1VOrjfbqySqxjJqi/lk\n2WP+85//9PHs2bNVTm5/ns3b7KWDPP84p7fRtP0CVqxY4eOTJ0+qnPw9t2tF9sGx9eJ2rcixPI/Y\nn42qCZe9vJxz7osvvvBxnTp1Ys4byVu1apWP5e+jc7oPm1WmTBkfy+8t53TPtmLFisU9F/uZ1qpV\ny8d2S9dOnTrFzH399dc+tuuWnjiJieqZJHtN2D5Y8vqlUqVKKie3h164cKHKHThw4Kzv7dz3PzvZ\nU61JkyYq16hRIx/LrYGd0+vKbnkvJds7AekhP3/b20R+r8lrDue+358i3p44yX7erJv0OH78uI9t\nX5FHH33Ux8eOHVM52QdwyJAhKif7sI0bN07l5PbjzumeOPb6K1n0S8p78f7O22te2WvLXldb8lra\nriuZs33gYs3zXHPNFDyJAwAAAAAAEABu4gAAAAAAAAQgo8up5KOdVapUUTm5rancXtc551q1auXj\n9u3bq5x8lMo+OiUfJbTlVDLnnH4k2T4CJksmQnw8K5tE/fvbnNw2U5ZAOKc/Y1nm4Jx+7PNc22fK\nNR1VahVVkmAfM/3Tn/7k4+nTp6vcli1bfPz4449Hzg2a/QxkOYHdjlmWOtiSCPm52vNI1HqxJVOy\nbMZuFb179+64jikfV3bOuQYNGviYc1Nq2O8DuR3r9u3bVU5+Hva7asKECT62ZcFR5wf7/vE+SmzX\n2yWXXOLjJUuWqJyct/05JEZev9jSbFm6a38/ZclKuXLlYh7flqLL749zlcLJ7zpZTuqccwsWLPDx\nnDlzVE6WbZYvXz7m3DjnZBZ5fqhcuXLM18nSc+ec27p1qxpHfeapKKeyZcmso+TYawVZsiJLrZ3T\n1xzNmzdXuUmTJvnYltLJ9xg8eLDK2dKrGjVq+NiWYca7brJtC+lsEO+27/Zvmw0bNsT9HvJzt6W/\n8Z4fQjyPsNoBAAAAAAACwE0cAAAAAACAAHATBwAAAAAAIAAZXcwu6+iKFy+ucu3atTtr7Jyu606k\nxu2DDz7wsd3OrFSpUmost9SzZE+CEGvssknUv7/NyT5HdgtFuRbr168f85hR/ZHsONntx6N6+dj/\nJtkfComx/5ayP8SgQYNU7s477/Sx3QpYriW5xpzTfW7sVtGlS5dWY9mvwG5NLd//yy+/VDm55q67\n7jqVs1sT4/zZHiSff/65j2vWrKlyY8eO9XHnzp1VLpGtmSVbVy7nU7ZsWZWT35W2X9NHH33kY9mb\nxTndE4fvuMTs2bNHjWUfHPvvLNl/Z/k9NHDgQJVr2bKlj6tWrapy8rOzvU1sPwu5Bu1W5bIvmO0h\nt2bNGh8NZr7nAAAU4ElEQVS3adPGIQzyu0L2J7HsupFbATune1LYdZuKniWcc1LD/jvKv3OGDh2q\ncl27dvVxnTp1VK5kyZIx30Ne165fv17lbG+/G264IWYuqp8lMksif3dJ9tpF9vQ812cur23kOnIu\nu/v28SQOAAAAAABAALiJAwAAAAAAEICMfsYo6rHLVDySabd7nTZtWszj9+3bV40vuugiH/NoZ3ZY\nvny5j21pkyyl6dOnj8pFlRYksjbiXdNRc6tVq5bKRW0TisTIz9Ju1Sy3VI3aXtWKd+tF+1pblrV/\n//6Yx5HzGTlypMpFlewgfvKz2bVrl8r94Ac/8PHw4cNV7vrrr/exfeRXHjOqTNOuE3sc+ZixPcfI\n95CPLjunyzTtOvnRj37k46jtzvMru3X3tm3bfHzTTTepXFQJlSxvePjhh1VObtdry83j/S6R3x3n\nctVVV6mxXDv2MXhbjozUS8VW3ZY8Tu3atWO+n/3eWrdunRrL85U9P1AWk7nkZ2PLueX3WCLrTZ4L\nZWmxc98vL27fvr2Po85hdt2k428weU7jO+78xPv52OvYJUuWxP0ejRo18nH16tWTev8Q8SQOAAAA\nAABAALiJAwAAAAAAEABu4gAAAAAAAAQgo3vipMLp06fVWNZk3nXXXSonewDIPifOOde/f381zuYt\ny/IL27fgmWee8bHtQdGrVy8fX3zxxSqXbH+mZOt6bd3op59+6mPbi6BChQpJzQ25I5FaXbkmR40a\npXK7d++O+XOyL5Lc+tW51PQWg2a3bR82bJiPq1WrpnJR3yPJ9rywr42q55fvIbcUd06vjWbNmqlc\n27Zt455PfmQ/A9kLyfZMkn1v5Nbgzjn35ptv+thuFZ6KOv9EvoPsvOVrbU+eyy+//Lznhmjp6PMg\nj9m6dWuVk33gTpw4oXJr165V43j7iWRzr4psE++1gj2n7N2718dffPGFyjVv3lyN5bVKVE9A+x6p\nuI6xx6QPTu6Q5wrZl9Y55/bt2xfz5+xnLrcVtz0rsxlX8AAAAAAAAAHgJg4AAAAAAEAAsrImaOvW\nrT6+//77Ve6DDz7w8aFDh2Ie4+TJk2pstzpr0KCBjylJCId8ZHL69Okqt2rVKh/bLXUffPBBH0d9\n3nar1ajHhRN5lF2Wfo0fP17lFi9e7GO7pbh8rDA3tmVEYtumJlIys2bNGh+//fbbMV9n1+fYsWN9\nXKxYMZVjDaSG/He02zbLcplEHtGWn2PUmjqf3+ujR4/6eOXKlSpXt25dHz/00EMqJ7ctx/fZMjn5\n/VGjRg2V69Gjh48bN26sciVKlIjr/RI558jvKPt9VaRIkZjHffbZZ1VOrrOuXbuqXMWKFeOeDzKH\n/Ezllr3O6bVoy6k2bNigxvK8kp9KG/IreZ6wfzvJv7ns+aZnz55qHLVW5Huk428uroXyxvHjx308\nZcoUlbPtUCS7Vlq1auXj/PQ3ef75LwUAAAAAAAgYN3EAAAAAAAACwE0cAAAAAACAAGRFTxzb26Zj\nx44+lluKOxd/7bit63zggQfUWG7d3K5dO5WTtXrUWWYWucXhz372M5WTa6NkyZIqV7p06ZjHtNuR\nS1Gfv81FvfbIkSM+tr18Dh48GNfcWIvpE7X9pZTsZ+6c7p0RVStst3++5ZZbfJyfaoXziv03jre3\nTZRE1lTUzx44cEDlfvnLX/rYbjHepUsXH19zzTUqxzpKzBVXXOFj2U/POd2nKlXn6Hi/d87Vr2T3\n7t0+njFjRszX9evXT42j1kcifcBw/pLtmWWveeQ28t9++63KHT58WI2jvp+isDYyRyLfOfK127dv\nV7mPP/7Yx1dffbXKNW3aVI3j/a5kbWSP/fv3+3jnzp1x/1zRokXV+OKLL07ZnELClRgAAAAAAEAA\nuIkDAAAAAAAQgKwop7LbG65fv97HUY/k2W2k5aPFx44dU7m9e/eqsdxSs3nz5ir31FNP+bhly5Yq\nx2Poucs+9nvrrbf62JaryEc0J0yYoHJ269VYP5cbn6/dvlZuW9ywYUOVk2V/SJ2o80oia0Aex5bF\n9erVS43lFuNWzZo1fWy3H49au8hdUY+hW/E+Tn6uR8vld1f79u1VTq4pW0L6k5/8xMf2uxKJkecE\nWZaSKomUF0Rtc29Lg2+77TYf22uiOnXq+Nhe51DuED57nWHLFyR7rjp16lRS78m6yVtRZeFR1zXy\n8166dKnKlStXzseJbCmeKvK/w57f5H8Tay9vyG3nbRuTKLbcM+r8lM24owAAAAAAABAAbuIAAAAA\nAAAEgJs4AAAAAAAAAciKnjiyNts5vZ2n7ZdTv359Hz/55JMqJ2s3582bp3K//e1v1XjLli0+/u//\n/m+Vk1uOL1myROVszxKk3okTJ3wst9B1TvdLsjWw1157rY/vuOMOlUtVrxtZ/2mPGVWTK3tSdOrU\nSeV27Njh4/Hjx6tc1NboSEwqtry0x/jmm2983L17d5WbP39+zJ+1teSvvPKKj8uWLRvXXJBZEtkK\nOConz3/OOde/f38fR/VVuueee9RYboVNv4C8l6otd6OOs2fPHjWW/S3sOeeDDz6ImYvCWspb8W7j\nbXsnHT9+POZr5XWNc9/vPYLMlKrefnKbaPv3kOzJd+mll6pcVI+4RHryxDqGc84dPXo05jGKFSsW\n1zGRPvLckch5o1mzZmos/37PT98xPIkDAAAAAAAQAG7iAAAAAAAABICbOAAAAAAAAAHIip44FSpU\nUGPZS+LQoUMqJ/tFyD4jVuPGjdW4Z8+eanz33Xf7+G9/+5vKHTt2zMc33nijyq1bt87HxYsXj/n+\nSN7KlSt9PHXqVJU7ffq0j+3nP2TIEB/bmkpZqyk/X+ecO3nypI9l/a9zzm3cuFGNZR8B23enevXq\nZ30/55z7+uuvfSxrP51zrm/fvj6uVq2aQ3ok2/dGjo8cOaJyvXr18nFUDxz7/m3btlW5Nm3axDU3\nZBb5mSbb18SuqdGjR6ux7FEgzzHOOffXv/7Vx40aNYo5t6j3T7Z3AVIn6lwR1WfA/tycOXPUWPa6\nGTBggMpddtllCc8T4bBrI6rvkT1XFC1aNC1zQnrF+x106tQpNX7ppZd8/NFHH6nc2LFjfVyyZMnI\n95NrLpHvEXmO27p1q8rt3r3bx3Xr1lU5uU6j5pKfeqykW7K93ezfViNHjozMx/v+oX+2XG0BAAAA\nAAAEgJs4AAAAAAAAAciKcqqoRzmTfazTPspXuXJlNZ42bZqPx4wZo3ITJ0708c6dO1Xutdde8/Hg\nwYMj3xPJkY92ylIny26LKT+3zZs3q9yMGTN8/NVXX6mcLOezZXh2u0VZ3ie3b3XOubvuusvHkyZN\nUrlVq1b5+PLLL1c5uY06ayjzyBK+mTNnqtyCBQt8HPWYqXPO1atXz8eTJ09WOUozw3SuzzzW6+RW\n0LbMxZbEVKpUycf2nGNLkeMl52PLdZItEUO0ZP8tE9mO/s0331Rjee6y11IHDx6MedyCBf/v0tL+\nnN26GpkpkfVmP9Nkt4PmfJG7Evn3luf5N954Q+V+85vf+Lh169Yqd/PNN/s4kd/9qLJ0e+6R33n2\nmvvf//3ffWyvz6OwFtPD/rvKMs2oFiclSpRQ49q1a0ceN7/gLz4AAAAAAIAAcBMHAAAAAAAgANzE\nAQAAAAAACEBG98RJdiuyZI+RyGtlD4pf//rXKvf+++/7+Msvv1S5Z555xsedO3dWuZo1a8Z8f8Rm\nezLYLXfj/blPPvnExwsXLoz5WrsWZN+dUqVKqZzdllNuAW7fX26Zt2bNGpWTa9OuE/qhZBZ7Htm1\na5ePhw0bpnJRPZuqVq2qxn/+8599bLfKTMf5EMmxvbbk77n9vI8fP+5jW+e/ceNGH8+ePVvl/vM/\n/9PH27Zti3z/GjVq+NjWlaeCXTeso8xiPw/ZB8f285s3b54ay/OF7HvhnHMvv/yyj23fm7Zt2/r4\nueeeU7kqVarEM22kSCLXuVE/F9Wvwm45new5gG2dM5e8Jn344YdVTl73Tp06VeWitqa3a/HYsWM+\n3rBhg8q99957Pp4/f77KHT582MeNGjVSuebNm8ecS9QaYy3mDvlvG9VLy/5dt2zZMjW+/vrr4zpO\ntn2WPIkDAAAAAAAQAG7iAAAAAAAABCCjy6mkeB8BTfS1sX4ukUeu7KPE8tFCuUWnc87t2LHDx3Pn\nzlW5Pn36JPX++Z39t+rQoYOP7Xa78rHLIkWKqJwsXzl69KjKycc8L774YpUbMWJEzFzJkiXVuGzZ\nsj62j/y9+OKLPn722WdVTpZI3HnnnSrHWsl78txh10737t19vHfv3pjHsGtFlmU6p7eWZyv5zHLo\n0CEfr169WuXkY+ivvPKKyq1du9bH8tzknP6dt7/j8vO3OXtek+VcixYtUrkmTZr4uEyZMi4WW/oZ\n77agyBvyfGS3EZfl37ZEyn7OUQ4cOOBj+6i7vM5hS/Ew2c8tqhTTlnCm4pqE7cfzlrzmdU6XSdmS\npQkTJvhYXuNatuxu6dKlajxlyhQfy/YGzumydPseP/7xj338i1/8QuVkC4NE1hDrLXfIdhD2b2nJ\nlqJ/8MEHatyuXTsf56fr4/zzXwoAAAAAABAwbuIAAAAAAAAEgJs4AAAAAAAAAcjonjiyJjFqm8RE\neuDEu/VYIseUteHOObdu3bqYr5W1w3YLYWowk2P/3bp16+ZjuxWz7FdUq1YtlZM13/bzl5+b3aYw\nqidEItvvyu2n69Wrp3L79u3z8e233x73MZE7ZL3u4MGDVe7TTz+N+XOyf8mrr76qck2bNlXjVNT5\nJrvdLDTb9+iZZ57x8VtvvaVyO3fu9LHtexMv25+ifPnyZ43P9lq5Bbnsz+Sc7pdie+nIHkyjR49W\nuZYtW/o4agtZ5A35e719+3aVk70tbM8+S16jyN5vzjlXsOD/XT7a84jsUVGuXLk4ZoxMl8hW0clu\nY862znlL/vt/9tlnKrd8+XIf296P8nfc9seSvW3stZG8rnVOn2+aNWumcg0bNvTx1VdfrXI//OEP\nfRzVVwXpE/U7H/W7LL9Hoq5x7fHtFuOJ9HPLJjyJAwAAAAAAEABu4gAAAAAAAAQgo8upokQ9npXs\nY5iyZMY+Lr9582Y1/sc//uHjhx56SOXkdrNW7dq1fdy2bduk5olocss6+9hl1Na8eU2WZcmSMOei\ny7mQ++zv+GOPPeZjW04jHwO1j4uOHTvWx127dlW5RB4tTXYtZ9rvQChsyewf/vAHH2/ZskXl4n3M\n134W8rtizJgxKnfdddf52JZz2vK9xx9/3Mdym1bn9JavdvtXec6xW7oWK1bse/NH5pDnjtKlS6tc\nlSpVfGzXQ4UKFdRYbklvS5PTcQ2G+MVbepSqktkyZcrEzNn3t1uOx4t1k7fktuIvvPCCyq1cudLH\na9asUTk53rp1q8rJcmL7+V555ZVqPHnyZB/Xr19f5eT3nC0ZRu6LKqFMdiv3REqibBuT/Hru4Ekc\nAAAAAACAAHATBwAAAAAAIADcxAEAAAAAAAhAsD1xpKhtCm2dv+xlIbdedc65F1980cczZ85UuW+/\n/VaNZc1vVH+KGjVqqNzChQt9TF+B9EtV7Wyy9Z7J9i6R2+6dbYz0s5+d7JNlt1yeNGmSj6O27bV9\nJX7+85/7+Fxrle3A85b8XFetWqVyx48f97H9HGWdt/39L1mypI+ffvpplevbt6+Pbd8beZyo7Z2d\nc+6iiy7y8ZAhQ1Ru48aNPm7RooXK/eY3v/FxrVq1VI6eBOEoVaqUGsvP2fb6k72WnNOfe1SPLuS+\nZPvgxHsNYl8ne5TMmTNH5ez54PDhwz62fZaQOew6kX/n7NixQ+X279/vY/t3lex7Y88TcvvxRx99\nVOV69+6txkWKFIln2sgA6eiJdj6fP1uMAwAAAAAAIGNxEwcAAAAAACAAWVGjYR+jko8B2sf3pk2b\n5uODBw9GHieKfFzMbr141VVX+fi1115TObltLDKX3SJTrg1b2iTXgi2lsWtK/iyPp2c2+9nJbTTf\neOMNlbOPF0tyffz0pz9VuaJFi8Y9n/y6hWKmkJ+xfETcOeeuvfZaH69YsULl5OfWqlUrlRs+fLiP\nGzZsGPPnotjXFS5cWI3l99GCBQtUTp6vKOHMPMmW8Ur254oXL+7jI0eOqNzq1avVWK4PW9KHzJWO\n74pKlSr52JZP2WsZ2bYg2ZJypJ+9xpEtHoYOHapyU6dO9fH27dtVTn4f9ujRQ+Vuu+22sx7fOdZC\nNkn2s5TXKz179lQ5WWJuzzl9+vRR4/z6/cRfkQAAAAAAAAHgJg4AAAAAAEAAuIkDAAAAAAAQgKwo\nerc1t8uWLfOxrM11Ttff2Ro6eRy59atzzrVv316N77vvPh83atRI5WTNOVuxhsnWeMtxVO0nfW6y\nh/0sq1Sp4uNE+oXIn7NbalITHg5Zz3/LLbeo3M033+xj+5lm0jmBvjdhScX5wV7n9OrVy8e2Z9/R\no0fVmOuX/Muet2Q/t08++UTl5Hecc85ddNFFPuY7LnPZ32+5HbzsZWPHqdjCHnBOfz+NGjVK5UaO\nHOlju1b5bvr/ZM7VJQAAAAAAAGLiJg4AAAAAAEAAsuJZavtYVceOHc8an4vcbi+THoFH7kv2kdCo\nMiyETW63W7lyZZWTZZuynNI552bMmOHjOnXqqByPHoeJ32tkkqjyBuvLL7/08cmTJ1WuadOmaky5\nHf6lZs2aPn733XdVzl6D872W3fh8kQ6UTCWOK1EAAAAAAIAAcBMHAAAAAAAgANzEAQAAAAAACAAF\nzwJ9DgD8i637ltumrlq1SuVkPy37c9SPA0inRM4x1113nY+HDx+ucoMHD1ZjrolwNvRKAoC8xzc0\nAAAAAABAALiJAwAAAAAAEACeiQSA80TZAYAQlC9f3scPP/xwHs4EAAAki788AAAAAAAAAsBNHAAA\nAAAAgABwEwcAAAAAACAABXJycuJ/cYECe5xzm9M3HeSROjk5OZXSdXDWTVZj7SAZrBski7WDZLBu\nkCzWDpLBukGy4lo7Cd3EAQAAAAAAQN6gnAoAAAAAACAA3MQBAAAAAAAIADdxAAAAAAAAAsBNHAAA\nAAAAgABwEwcAAAAAACAA3MQBAAAAAAAIADdxAAAAAAAAAsBNHAAAAAAAgABwEwcAAAAAACAA/w+J\nno5NjaZwoQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115051c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wFMD0d+dme9RAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114cd6b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_rows_to_show = 6\n",
    "\n",
    "print(\"More results: \")\n",
    "for i in range(example_rows_to_show):\n",
    "    figure, axes = plt.subplots(nrows=2, ncols=8, sharex=True, sharey=True, figsize=(20,4))\n",
    "    images = test_images[(i*8):(i+1)*8]\n",
    "    encodings, decodings = session.run([encoded, decoded], feed_dict={inputs_: images})\n",
    "    \n",
    "    for images_and_decodings, plot_row in zip([images, decodings], axes):\n",
    "        for img, ax in zip(images_and_decodings, plot_row):\n",
    "            ax.imshow(img.reshape((28, 28)), cmap='gray_r')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
